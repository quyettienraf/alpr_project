{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OtgYzfAaJMCb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 30 06:44:49 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 950M         On | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P8               N/A /  N/A|      0MiB /  2048MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        23      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5jFrfraVDVIe"
   },
   "outputs": [],
   "source": [
    "# # Cloning DeepSORT\n",
    "# !git clone https://github.com/nwojke/deep_sort.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ_xmWa3mUsX"
   },
   "source": [
    "The original DeepSORT repo uses a deprecated sklearn function called `linear_assignment`, which needs to be replaced for error free execution of code with scipy.\n",
    "\n",
    "\n",
    "\n",
    "1.   Open ./deep_sort/deep_sort/linear_assignment.py\n",
    "2.   Replace `from sklearn.utils.linear_assignment_ import linear_assignment` in line 4 with `from scipy.optimize import linear_sum_assignment`.\n",
    "\n",
    "3.   Replace `indices = linear_assignment(cost_matrix)` in line 58 with the following lines of code:\n",
    "```\n",
    "  indices = linear_sum_assignment(cost_matrix)\n",
    "  indices = np.asarray(indices)\n",
    "  indices = np.transpose(indices)\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JtIEFrCoyNc"
   },
   "source": [
    "Also, rename ./deep_sort/tools as ./deep_sort/tools_deepsort to avoid any name overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/BKHN/alpr_project/learnopencv/deep_sort\n"
     ]
    }
   ],
   "source": [
    "# DeepSORT imports.\n",
    "%cd ./deep_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kitn5vISMnFc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 06:44:54.105284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-30 06:44:54.162838: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-30 06:44:54.164562: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 06:44:55.193042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from application_util import preprocessing\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools_deepsort import generate_detections as gdet\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-NNkCyMLDIh"
   },
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpMIk5cmlZt9"
   },
   "source": [
    "##Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_sFAdI85qDFx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/BKHN/alpr_project/learnopencv\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mALPR_inference.ipynb\u001b[0m*                  \u001b[01;32mbus.jpg\u001b[0m*     \u001b[01;32mtest1.py\u001b[0m*    \u001b[34;42myolov8\u001b[0m/\n",
      "\u001b[01;32mLicense_plate_detection_YOLOv4.ipynb\u001b[0m*  \u001b[34;42mdeep_sort\u001b[0m/   \u001b[01;32mtest2.py\u001b[0m*\n",
      "\u001b[01;32mOCR_comparison.ipynb\u001b[0m*                  \u001b[34;42mmodel_data\u001b[0m/  \u001b[34;42mtest_image\u001b[0m/\n",
      "\u001b[34;42mPaddleOCR\u001b[0m/                             \u001b[34;42mresults\u001b[0m/     \u001b[34;42mtest_video\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uTiYwfZIUB0x"
   },
   "outputs": [],
   "source": [
    "# # No need to install if already installed requirements.txt\n",
    "# !pip install paddlepaddle-gpu\n",
    "# !pip install \"paddleocr>=2.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHbxzrx4ljde"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p2XTYkQ0Hejw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/09/30 06:45:00] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='CRNN', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR(lang='en',rec_algorithm='CRNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4dcCivKR1g6"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48sYDjF5K7t6"
   },
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnl2k6MGtr72"
   },
   "source": [
    "Continuing process from License plate detection [notebook](https://colab.research.google.com/github/sanyam83/learnopencv/blob/master/ALPR/License_plate_detection_YOLOv4.ipynb). (Assuming the files and weights are now created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/BKHN/alpr_project/learnopencv\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mALPR_inference.ipynb\u001b[0m*                  \u001b[01;32mbus.jpg\u001b[0m*     \u001b[01;32mtest1.py\u001b[0m*    \u001b[34;42myolov8\u001b[0m/\n",
      "\u001b[01;32mLicense_plate_detection_YOLOv4.ipynb\u001b[0m*  \u001b[34;42mdeep_sort\u001b[0m/   \u001b[01;32mtest2.py\u001b[0m*\n",
      "\u001b[01;32mOCR_comparison.ipynb\u001b[0m*                  \u001b[34;42mmodel_data\u001b[0m/  \u001b[34;42mtest_image\u001b[0m/\n",
      "\u001b[34;42mPaddleOCR\u001b[0m/                             \u001b[34;42mresults\u001b[0m/     \u001b[34;42mtest_video\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gS1-J_w7WG_2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Variables storing colors and fonts.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "blue_color = (255,0,0)\n",
    "white_color = (255,255,255)\n",
    "black_color = (0,0,0)\n",
    "green_color = (0,255,0)\n",
    "yellow_color = (178, 247, 218)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zaUUuVXR-7E"
   },
   "source": [
    "\n",
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Se2fpL4PWFDG"
   },
   "outputs": [],
   "source": [
    "def crop(image, coord):\n",
    "  # Cropping is done by -> image[y1:y2, x1:x2].\n",
    "  cr_img = image[int(coord[1]):int(coord[3]), int(coord[0]):int(coord[2])]\n",
    "  return cr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cuIBZK8Klffb"
   },
   "outputs": [],
   "source": [
    "def resize_bbox(detections, out_size, in_size):\n",
    "  coord = []\n",
    "  scores = []\n",
    "\n",
    "  # Scaling the bounding boxes to the different size\n",
    "  for det in detections:\n",
    "    points = list(det[2])\n",
    "    conf = det[1]\n",
    "    xmin, ymin, xmax, ymax = darknet.bbox2points(points)\n",
    "    y_scale = float(out_size[0]) / in_size[0]\n",
    "    x_scale = float(out_size[1]) / in_size[1]\n",
    "    ymin = int(y_scale * ymin)\n",
    "    ymax = int(y_scale * ymax)\n",
    "    xmin = int(x_scale * xmin) if int(x_scale * xmin) > 0 else 0\n",
    "    xmax = int(x_scale * xmax)\n",
    "    final_points = [xmin, ymin, xmax-xmin, ymax-ymin]\n",
    "    scores.append(conf)\n",
    "    coord.append(final_points)\n",
    "  return coord, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rx7H0jy9NBd0"
   },
   "outputs": [],
   "source": [
    "def get_best_ocr(preds, rec_conf, ocr_res, track_id):\n",
    "  for info in preds:\n",
    "    # Check if it is current track id\n",
    "    if info['track_id'] == track_id:\n",
    "      # Check if the ocr confidenence is maximum or not\n",
    "      if info['ocr_conf'] < rec_conf:\n",
    "        info['ocr_conf'] = rec_conf\n",
    "        info['ocr_txt'] = ocr_res\n",
    "      else:\n",
    "        rec_conf = info['ocr_conf']\n",
    "        ocr_res = info['ocr_txt']\n",
    "      break\n",
    "  return preds, rec_conf, ocr_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48pYyTxHLVb6"
   },
   "source": [
    "#Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScLiRLarwMWT"
   },
   "source": [
    "## Fucntion for inferencing on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mALPR_inference.ipynb\u001b[0m*                  \u001b[01;32mbus.jpg\u001b[0m*     \u001b[01;32mtest1.py\u001b[0m*    \u001b[34;42myolov8\u001b[0m/\n",
      "\u001b[01;32mLicense_plate_detection_YOLOv4.ipynb\u001b[0m*  \u001b[34;42mdeep_sort\u001b[0m/   \u001b[01;32mtest2.py\u001b[0m*\n",
      "\u001b[01;32mOCR_comparison.ipynb\u001b[0m*                  \u001b[34;42mmodel_data\u001b[0m/  \u001b[34;42mtest_image\u001b[0m/\n",
      "\u001b[34;42mPaddleOCR\u001b[0m/                             \u001b[34;42mresults\u001b[0m/     \u001b[34;42mtest_video\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/test_image/Cars187.png: 384x640 1 plate, 41.0ms\n",
      "Speed: 5.2ms preprocess, 41.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results: [ultralytics.yolo.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.yolo.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'plate'}\n",
      "orig_img: array([[[180, 198, 220],\n",
      "        [180, 198, 220],\n",
      "        [179, 197, 220],\n",
      "        ...,\n",
      "        [253, 230, 239],\n",
      "        [254, 230, 239],\n",
      "        [253, 230, 239]],\n",
      "\n",
      "       [[179, 198, 220],\n",
      "        [179, 198, 220],\n",
      "        [178, 197, 219],\n",
      "        ...,\n",
      "        [254, 230, 239],\n",
      "        [254, 230, 239],\n",
      "        [254, 230, 239]],\n",
      "\n",
      "       [[177, 195, 217],\n",
      "        [177, 195, 217],\n",
      "        [175, 194, 215],\n",
      "        ...,\n",
      "        [253, 230, 240],\n",
      "        [254, 230, 240],\n",
      "        [253, 230, 239]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 17,  18,  25],\n",
      "        [ 17,  17,  24],\n",
      "        [ 17,  18,  25],\n",
      "        ...,\n",
      "        [  8,   9,   8],\n",
      "        [  7,   9,   7],\n",
      "        [  7,   9,   7]],\n",
      "\n",
      "       [[ 13,  13,  14],\n",
      "        [ 13,  13,  14],\n",
      "        [ 13,  13,  16],\n",
      "        ...,\n",
      "        [  6,   6,   4],\n",
      "        [  8,   8,   6],\n",
      "        [  9,   9,   7]],\n",
      "\n",
      "       [[ 11,  11,  10],\n",
      "        [ 11,  11,  10],\n",
      "        [ 11,  11,   9],\n",
      "        ...,\n",
      "        [  8,   9,   7],\n",
      "        [ 10,  10,   9],\n",
      "        [ 11,  11,   9]]], dtype=uint8)\n",
      "orig_shape: (225, 400)\n",
      "path: '/mnt/d/BKHN/alpr_project/learnopencv/test_image/Cars187.png'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 5.228996276855469, 'inference': 41.03851318359375, 'postprocess': 4.24647331237793}]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8/alpr.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8/alpr_yolov8n_8000img_100epochs.pt\")  # load a pretrained model\n",
    "\n",
    "# Use the model\n",
    "# model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "# metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"./test_image/Cars187.png\")  # predict on an image\n",
    "print(\"results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8/alpr_yolov8n_8000img_100epochs.pt\") \n",
    "\n",
    "def test_img_yolov8(input, out_path):\n",
    "    file_name = input.split(\"/\")[-1]\n",
    "    print(\"file_name:\", file_name)\n",
    "    # Use the model\n",
    "    results = model(input)  # predict on an image\n",
    "    img = cv2.imread(input)\n",
    "    for result in results:\n",
    "        if result.boxes is not None and len(result.boxes) > 0:\n",
    "            # Get the bounding boxes and image for each result\n",
    "            bboxes = result.boxes[0].cpu().numpy()\n",
    "            # img = cv2.imread(input)  # Đảm bảo bạn đã định nghĩa biến 'input'\n",
    "    \n",
    "            # Loop through bboxes and apply OCR, then draw on the image\n",
    "            for bbox in bboxes:\n",
    "                xyxy = bbox.xyxy\n",
    "                x1, y1, x2, y2 = xyxy[0]\n",
    "    \n",
    "                # Kiểm tra xem biển số xe có gần vuông không (ví dụ: tỷ lệ 1:1)\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                aspect_ratio = width / height\n",
    "                print(\"aspect_ratio:\", aspect_ratio)\n",
    "                \n",
    "# ##################################\n",
    "#                 cr_img = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "#                 # Chuyển ảnh sang độ xám để phát hiện cạnh\n",
    "#                 gray = cv2.cvtColor(cr_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "#                 # Sử dụng phát hiện cạnh (Canny) để tạo ra ảnh cạnh\n",
    "#                 edges = cv2.Canny(gray, threshold1=50, threshold2=150, apertureSize=3)\n",
    "                \n",
    "#                 # Tìm các đường thẳng trong ảnh\n",
    "#                 lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "                \n",
    "#                 # Xác định góc nghiêng của ảnh\n",
    "#                 if lines is not None:\n",
    "#                     angles = []\n",
    "#                     for line in lines:\n",
    "#                         x1, y1, x2, y2 = line[0]\n",
    "#                         angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))\n",
    "#                         angles.append(angle)\n",
    "                \n",
    "#                     median_angle = np.median(angles)\n",
    "                \n",
    "#                     # Xoay lại ảnh để đưa góc nghiêng về 0 độ\n",
    "#                     img_rotate = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE if median_angle < 0 else cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "#                     image_filename = str(file_name) + \"_rotate.jpg\"  # Tên file ảnh đầu ra\n",
    "#                     cv2.imwrite(\"results/crop_image/\" + image_filename, image_collage_horizontal)\n",
    "#                 # else:\n",
    "#                 #     # Không tìm thấy đường thẳng, không xoay ảnh\n",
    "#                 #     img = img\n",
    "##############################\n",
    "                if 0 <= aspect_ratio <= 1.5:\n",
    "                    # Biển số xe gần vuông hoặc hình vuông\n",
    "    \n",
    "                    # Tính toán điểm chia ảnh thành hai phần trên và dưới\n",
    "                    split_point = y1 + (y2 - y1) // 2\n",
    "\n",
    "                    \n",
    "                    # Tạo hai phần ảnh con từ ảnh cr_img\n",
    "                    upper_part = img[int(y1):int(split_point), int(x1):int(x2)]\n",
    "                    lower_part = img[int(split_point):int(y2), int(x1):int(x2)]\n",
    "                    \n",
    "                    image_upper=cv2.resize(upper_part,(int(width),int(height/2)))\n",
    "                    image_lower=cv2.resize(lower_part,(int(width),int(height/2)))\n",
    "\n",
    "                    image_collage_horizontal =np.hstack([image_upper, image_lower])\n",
    "                    image_filename = str(file_name) + \".jpg\"  # Tên file ảnh đầu ra\n",
    "                    cv2.imwrite(\"results/crop_image/\" + image_filename, image_collage_horizontal)\n",
    "    \n",
    "                    # Tiếp tục xử lý ảnh chữ nhật cr_img ở đây\n",
    "                    ocr_res = perform_ocr(image_collage_horizontal)\n",
    "    \n",
    "                    # Lưu hai phần ảnh\n",
    "                    # cv2.imwrite(\"results/upper_part.jpg\", upper_part)\n",
    "                    # cv2.imwrite(\"results/\" + str(ct) + \".jpg\", lower_part)\n",
    "                else:\n",
    "                    # Biển số xe không gần vuông\n",
    "                    # Xử lý ảnh bình thường ở đây (cr_img = img[int(y1):int(y2), int(x1):int(x2)])\n",
    "                    cr_img = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    \n",
    "                    \n",
    "                    image_filename = str(file_name) + \".jpg\"  # Tên file ảnh đầu ra\n",
    "                    cv2.imwrite(\"results/crop_image/\" + image_filename, cr_img)\n",
    "                    ocr_res = perform_ocr(cr_img)\n",
    "            recognized_text = ocr_res[0][0][0] if ocr_res else \"No Text\"\n",
    "            print(\"recognized_text: \",recognized_text)\n",
    "            \n",
    "            ocr_conf = ocr_res[0][0][1] if ocr_res else \"No Conf\"\n",
    "            ocr_conf = round(ocr_conf,3)\n",
    "            print(\"ocr_conf: \",ocr_conf)\n",
    "            # Draw on the image\n",
    "            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)  # Red bounding box\n",
    "            cv2.putText(img, recognized_text, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            cv2.putText(img, str(ocr_conf), (int(x1) + 150, int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "        # Writing output image for each image\n",
    "        file_name = os.path.join(out_path, 'out_' + os.path.basename(input))\n",
    "        cv2.imwrite(file_name, img)\n",
    "    \n",
    "\n",
    "def perform_ocr(image):\n",
    "    ocr_res = ocr.ocr(image, cls=False, det=False)\n",
    "    return ocr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1662\n",
      "file_name: boderngoaigiao0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderngoaigiao0.jpg: 384x640 1 plate, 81.7ms\n",
      "Speed: 313.2ms preprocess, 81.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.353833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  41-291-NG-01\n",
      "ocr_conf:  0.819\n",
      "2/1662\n",
      "file_name: boderngoaigiao1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderngoaigiao1.jpg: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.0ms preprocess, 164.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8096281\n",
      "recognized_text:  ROLONG\n",
      "ocr_conf:  0.611\n",
      "3/1662\n",
      "file_name: boderngoaigiao10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderngoaigiao10.jpg: 416x640 1 plate, 128.1ms\n",
      "Speed: 4.5ms preprocess, 128.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7316747\n",
      "recognized_text:  --\n",
      "ocr_conf:  0.48\n",
      "4/1662\n",
      "file_name: boderngoaigiao11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderngoaigiao11.jpg: 416x640 2 plates, 124.9ms\n",
      "Speed: 5.4ms preprocess, 124.9ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7220216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi0.jpg: 480x640 1 plate, 135.8ms\n",
      "Speed: 4.8ms preprocess, 135.8ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  SN\n",
      "ocr_conf:  0.301\n",
      "5/1662\n",
      "file_name: boderquandoi0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7765377\n",
      "recognized_text:  12\n",
      "ocr_conf:  0.485\n",
      "6/1662\n",
      "file_name: boderquandoi1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi1.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.2ms preprocess, 125.6ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6596828\n",
      "recognized_text:  NAEE\n",
      "ocr_conf:  0.3\n",
      "7/1662\n",
      "file_name: boderquandoi10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi10.jpg: 448x640 1 plate, 137.0ms\n",
      "Speed: 4.9ms preprocess, 137.0ms inference, 14.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.724242\n",
      "recognized_text:  27-01\n",
      "ocr_conf:  0.821\n",
      "8/1662\n",
      "file_name: boderquandoi100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi100.jpg: 448x640 1 plate, 128.4ms\n",
      "Speed: 5.1ms preprocess, 128.4ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1637268\n",
      "recognized_text:  CP-23-19\n",
      "ocr_conf:  0.918\n",
      "9/1662\n",
      "file_name: boderquandoi101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi101.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.7ms preprocess, 125.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5458615\n",
      "recognized_text:  BH-52-62\n",
      "ocr_conf:  0.889\n",
      "10/1662\n",
      "file_name: boderquandoi11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi11.jpg: 384x640 1 plate, 166.7ms\n",
      "Speed: 4.0ms preprocess, 166.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.194475\n",
      "recognized_text:  E0S\n",
      "ocr_conf:  0.381\n",
      "11/1662\n",
      "file_name: boderquandoi110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi110.jpg: 448x640 1 plate, 131.7ms\n",
      "Speed: 4.8ms preprocess, 131.7ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.313232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  OH-58-07\n",
      "ocr_conf:  0.9\n",
      "12/1662\n",
      "file_name: boderquandoi20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi20.jpg: 480x640 3 plates, 136.6ms\n",
      "Speed: 3.9ms preprocess, 136.6ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7216663\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "13/1662\n",
      "file_name: boderquandoi21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi21.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.6ms preprocess, 126.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5513003\n",
      "recognized_text:  7H-31-69\n",
      "ocr_conf:  0.899\n",
      "14/1662\n",
      "file_name: boderquandoi30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi30.jpg: 480x640 2 plates, 134.4ms\n",
      "Speed: 5.0ms preprocess, 134.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9930007\n",
      "recognized_text:  KT-53-31\n",
      "ocr_conf:  0.9\n",
      "15/1662\n",
      "file_name: boderquandoi31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi31.jpg: 448x640 1 plate, 131.7ms\n",
      "Speed: 4.7ms preprocess, 131.7ms inference, 5.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7355661\n",
      "recognized_text:  OA-55-91\n",
      "ocr_conf:  0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi40.jpg: 448x640 3 plates, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/1662\n",
      "file_name: boderquandoi40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2172701\n",
      "recognized_text:  TM-27-33\n",
      "ocr_conf:  0.82\n",
      "17/1662\n",
      "file_name: boderquandoi41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi41.jpg: 448x640 1 plate, 126.8ms\n",
      "Speed: 4.8ms preprocess, 126.8ms inference, 7.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.653294\n",
      "recognized_text:  MP-41-60\n",
      "ocr_conf:  0.705\n",
      "18/1662\n",
      "file_name: boderquandoi50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi50.jpg: 384x640 1 plate, 164.9ms\n",
      "Speed: 4.4ms preprocess, 164.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3852212\n",
      "recognized_text:  XA-83-80\n",
      "ocr_conf:  0.947\n",
      "19/1662\n",
      "file_name: boderquandoi51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi51.jpg: 480x640 1 plate, 128.2ms\n",
      "Speed: 5.0ms preprocess, 128.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3519002\n",
      "recognized_text:  TM2366\n",
      "ocr_conf:  0.887\n",
      "20/1662\n",
      "file_name: boderquandoi60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi60.jpg: 448x640 1 plate, 130.0ms\n",
      "Speed: 4.3ms preprocess, 130.0ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7599995\n",
      "recognized_text:  8-2701\n",
      "ocr_conf:  0.479\n",
      "21/1662\n",
      "file_name: boderquandoi61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi61.jpg: 384x640 1 plate, 166.0ms\n",
      "Speed: 4.3ms preprocess, 166.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.29283\n",
      "recognized_text:  59-50-05\n",
      "ocr_conf:  0.789\n",
      "22/1662\n",
      "file_name: boderquandoi70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi70.jpg: 640x608 2 plates, 169.4ms\n",
      "Speed: 5.7ms preprocess, 169.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4012527\n",
      "recognized_text:  HSS\n",
      "ocr_conf:  0.647\n",
      "23/1662\n",
      "file_name: boderquandoi71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi71.jpg: 416x640 1 plate, 134.8ms\n",
      "Speed: 4.4ms preprocess, 134.8ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.475579\n",
      "recognized_text:  TH-52-73\n",
      "ocr_conf:  0.976\n",
      "24/1662\n",
      "file_name: boderquandoi80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi80.jpg: 416x640 1 plate, 128.5ms\n",
      "Speed: 4.6ms preprocess, 128.5ms inference, 3.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2470851\n",
      "recognized_text:  a5m\n",
      "ocr_conf:  0.237\n",
      "25/1662\n",
      "file_name: boderquandoi81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi81.jpg: 448x640 2 plates, 130.6ms\n",
      "Speed: 5.3ms preprocess, 130.6ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4233981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "26/1662\n",
      "file_name: boderquandoi90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi90.jpg: 448x640 1 plate, 138.2ms\n",
      "Speed: 4.1ms preprocess, 138.2ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.072479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  MC\n",
      "ocr_conf:  0.371\n",
      "27/1662\n",
      "file_name: boderquandoi91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/boderquandoi91.jpg: 448x640 1 plate, 148.0ms\n",
      "Speed: 4.8ms preprocess, 148.0ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2352567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "28/1662\n",
      "file_name: brightnessngoaigiao0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessngoaigiao0.jpg: 384x640 2 plates, 164.2ms\n",
      "Speed: 4.1ms preprocess, 164.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4772005\n",
      "recognized_text:  41-291-NG-01\n",
      "ocr_conf:  0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessngoaigiao1.jpg: 384x640 2 plates, 141.0ms\n",
      "Speed: 4.9ms preprocess, 141.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/1662\n",
      "file_name: brightnessngoaigiao1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4539623\n",
      "recognized_text:  100-NG-631-37\n",
      "ocr_conf:  0.706\n",
      "30/1662\n",
      "file_name: brightnessngoaigiao10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessngoaigiao10.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.4ms preprocess, 126.0ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4512687\n",
      "recognized_text:  166-33\n",
      "ocr_conf:  0.71\n",
      "31/1662\n",
      "file_name: brightnessngoaigiao11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessngoaigiao11.jpg: 416x640 2 plates, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3192081\n",
      "recognized_text:  0-NG-376-14\n",
      "ocr_conf:  0.796\n",
      "32/1662\n",
      "file_name: brightnessquandoi0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi0.jpg: 480x640 1 plate, 136.2ms\n",
      "Speed: 4.8ms preprocess, 136.2ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1718401\n",
      "recognized_text:  On55-12\n",
      "ocr_conf:  0.858\n",
      "33/1662\n",
      "file_name: brightnessquandoi1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi1.jpg: 416x640 1 plate, 127.2ms\n",
      "Speed: 4.4ms preprocess, 127.2ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.849486\n",
      "recognized_text:  TH-66-72\n",
      "ocr_conf:  0.925\n",
      "34/1662\n",
      "file_name: brightnessquandoi10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi10.jpg: 448x640 1 plate, 130.6ms\n",
      "Speed: 5.1ms preprocess, 130.6ms inference, 7.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8591285\n",
      "recognized_text:  FM-27-01\n",
      "ocr_conf:  0.879\n",
      "35/1662\n",
      "file_name: brightnessquandoi100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi100.jpg: 448x640 1 plate, 128.6ms\n",
      "Speed: 7.3ms preprocess, 128.6ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8438817\n",
      "recognized_text:  Co27CP-23-19\n",
      "ocr_conf:  0.641\n",
      "36/1662\n",
      "file_name: brightnessquandoi101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi101.jpg: 416x640 2 plates, 126.0ms\n",
      "Speed: 5.0ms preprocess, 126.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2526891\n",
      "recognized_text:  BH-52-62\n",
      "ocr_conf:  0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/1662\n",
      "file_name: brightnessquandoi11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi11.jpg: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.1ms preprocess, 164.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9960107\n",
      "recognized_text:  S93E\n",
      "ocr_conf:  0.266\n",
      "38/1662\n",
      "file_name: brightnessquandoi110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi110.jpg: 448x640 1 plate, 130.8ms\n",
      "Speed: 5.5ms preprocess, 130.8ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9385861\n",
      "recognized_text:  nurndn-58-07\n",
      "ocr_conf:  0.655\n",
      "39/1662\n",
      "file_name: brightnessquandoi20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi20.jpg: 480x640 1 plate, 134.9ms\n",
      "Speed: 4.2ms preprocess, 134.9ms inference, 14.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6992984\n",
      "recognized_text:  E\n",
      "ocr_conf:  0.323\n",
      "40/1662\n",
      "file_name: brightnessquandoi21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi21.jpg: 416x640 1 plate, 126.8ms\n",
      "Speed: 4.3ms preprocess, 126.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.579441\n",
      "recognized_text:  TH-31-69\n",
      "ocr_conf:  0.926\n",
      "41/1662\n",
      "file_name: brightnessquandoi30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi30.jpg: 480x640 2 plates, 137.2ms\n",
      "Speed: 4.8ms preprocess, 137.2ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0703664\n",
      "recognized_text:  KT-53-31\n",
      "ocr_conf:  0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi31.jpg: 448x640 1 plate, 130.8ms\n",
      "Speed: 4.8ms preprocess, 130.8ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/1662\n",
      "file_name: brightnessquandoi31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.366122\n",
      "recognized_text:  OA-55-91\n",
      "ocr_conf:  0.91\n",
      "43/1662\n",
      "file_name: brightnessquandoi40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi40.jpg: 448x640 3 plates, 128.8ms\n",
      "Speed: 4.8ms preprocess, 128.8ms inference, 6.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5448173\n",
      "recognized_text:  27.3323\n",
      "ocr_conf:  0.59\n",
      "44/1662\n",
      "file_name: brightnessquandoi41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi41.jpg: 448x640 1 plate, 129.5ms\n",
      "Speed: 4.6ms preprocess, 129.5ms inference, 6.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.570395\n",
      "recognized_text:  KP-41-60\n",
      "ocr_conf:  0.957\n",
      "45/1662\n",
      "file_name: brightnessquandoi50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi50.jpg: 384x640 1 plate, 166.0ms\n",
      "Speed: 4.5ms preprocess, 166.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7050152\n",
      "recognized_text:  KA-83-80\n",
      "ocr_conf:  0.955\n",
      "46/1662\n",
      "file_name: brightnessquandoi51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi51.jpg: 480x640 1 plate, 136.1ms\n",
      "Speed: 4.8ms preprocess, 136.1ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1786278\n",
      "recognized_text:  TM23-66\n",
      "ocr_conf:  0.936\n",
      "47/1662\n",
      "file_name: brightnessquandoi60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi60.jpg: 448x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6194508\n",
      "recognized_text:  TM-27-01\n",
      "ocr_conf:  0.866\n",
      "48/1662\n",
      "file_name: brightnessquandoi61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi61.jpg: 384x640 1 plate, 167.0ms\n",
      "Speed: 4.1ms preprocess, 167.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5466921\n",
      "recognized_text:  K9-50-03\n",
      "ocr_conf:  0.776\n",
      "49/1662\n",
      "file_name: brightnessquandoi70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi70.jpg: 640x608 1 plate, 183.7ms\n",
      "Speed: 5.3ms preprocess, 183.7ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4097807\n",
      "recognized_text:  OA-52-32\n",
      "ocr_conf:  0.851\n",
      "50/1662\n",
      "file_name: brightnessquandoi71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi71.jpg: 416x640 1 plate, 127.4ms\n",
      "Speed: 4.1ms preprocess, 127.4ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4975522\n",
      "recognized_text:  TH-52-73\n",
      "ocr_conf:  0.958\n",
      "51/1662\n",
      "file_name: brightnessquandoi80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi80.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.8ms preprocess, 123.8ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4237647\n",
      "recognized_text:  Bn53-90\n",
      "ocr_conf:  0.857\n",
      "52/1662\n",
      "file_name: brightnessquandoi81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi81.jpg: 448x640 3 plates, 138.6ms\n",
      "Speed: 4.4ms preprocess, 138.6ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3269838\n",
      "recognized_text:  Dad REE\n",
      "ocr_conf:  0.443\n",
      "53/1662\n",
      "file_name: brightnessquandoi90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi90.jpg: 448x640 2 plates, 129.1ms\n",
      "Speed: 4.2ms preprocess, 129.1ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.350484\n",
      "recognized_text:  E\n",
      "ocr_conf:  0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/brightnessquandoi91.jpg: 448x640 4 plates, 128.6ms\n",
      "Speed: 4.9ms preprocess, 128.6ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/1662\n",
      "file_name: brightnessquandoi91.jpg\n",
      "aspect_ratio: 2.6551652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate0.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.2ms preprocess, 126.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  KC-59:70\n",
      "ocr_conf:  0.731\n",
      "55/1662\n",
      "file_name: CarLongPlate0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3230832\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.96\n",
      "56/1662\n",
      "file_name: CarLongPlate1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate1.jpg: 416x640 1 plate, 129.4ms\n",
      "Speed: 4.7ms preprocess, 129.4ms inference, 15.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2517333\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.913\n",
      "57/1662\n",
      "file_name: CarLongPlate10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate10.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0953772\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.924\n",
      "58/1662\n",
      "file_name: CarLongPlate100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate100.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4749746\n",
      "recognized_text:  51F-324.88\n",
      "ocr_conf:  0.92\n",
      "59/1662\n",
      "file_name: CarLongPlate101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate101.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 13.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3576908\n",
      "recognized_text:  30N-4616\n",
      "ocr_conf:  0.943\n",
      "60/1662\n",
      "file_name: CarLongPlate11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate11.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2981699\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.954\n",
      "61/1662\n",
      "file_name: CarLongPlate110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate110.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.9ms preprocess, 122.3ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.277576\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.947\n",
      "62/1662\n",
      "file_name: CarLongPlate111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate111.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 11.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4307654\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.963\n",
      "63/1662\n",
      "file_name: CarLongPlate120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate120.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1285896\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.956\n",
      "64/1662\n",
      "file_name: CarLongPlate121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate121.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.203826\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.951\n",
      "65/1662\n",
      "file_name: CarLongPlate130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate130.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.2ms preprocess, 123.4ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1873214\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate131.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/1662\n",
      "file_name: CarLongPlate131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2967973\n",
      "recognized_text:  51G-290.34\n",
      "ocr_conf:  0.959\n",
      "67/1662\n",
      "file_name: CarLongPlate140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate140.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.9ms preprocess, 124.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.121384\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.931\n",
      "68/1662\n",
      "file_name: CarLongPlate141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate141.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2514546\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.935\n",
      "69/1662\n",
      "file_name: CarLongPlate150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate150.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3251426\n",
      "recognized_text:  51G-429.71\n",
      "ocr_conf:  0.923\n",
      "70/1662\n",
      "file_name: CarLongPlate151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate151.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.5ms preprocess, 124.3ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4829707\n",
      "recognized_text:  51G-429.71\n",
      "ocr_conf:  0.914\n",
      "71/1662\n",
      "file_name: CarLongPlate160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate160.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.301592\n",
      "recognized_text:  60A-208.80\n",
      "ocr_conf:  0.978\n",
      "72/1662\n",
      "file_name: CarLongPlate161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate161.jpg: 416x640 1 plate, 127.2ms\n",
      "Speed: 4.0ms preprocess, 127.2ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7696548\n",
      "recognized_text:  60A-208.80\n",
      "ocr_conf:  0.968\n",
      "73/1662\n",
      "file_name: CarLongPlate170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate170.jpg: 416x640 1 plate, 134.1ms\n",
      "Speed: 4.2ms preprocess, 134.1ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3044972\n",
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.956\n",
      "74/1662\n",
      "file_name: CarLongPlate171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate171.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.7ms preprocess, 124.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5726757\n",
      "recognized_text:  51A-721.10\n",
      "ocr_conf:  0.965\n",
      "75/1662\n",
      "file_name: CarLongPlate180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate180.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0560484\n",
      "recognized_text:  516-436.30\n",
      "ocr_conf:  0.894\n",
      "76/1662\n",
      "file_name: CarLongPlate181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate181.jpg: 416x640 1 plate, 132.5ms\n",
      "Speed: 4.2ms preprocess, 132.5ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6114142\n",
      "recognized_text:  50Z-1630\n",
      "ocr_conf:  0.919\n",
      "77/1662\n",
      "file_name: CarLongPlate190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate190.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3016062\n",
      "recognized_text:  51F-734.20\n",
      "ocr_conf:  0.974\n",
      "78/1662\n",
      "file_name: CarLongPlate191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate191.jpg: 416x640 1 plate, 128.3ms\n",
      "Speed: 5.4ms preprocess, 128.3ms inference, 17.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3494587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-075.68\n",
      "ocr_conf:  0.936\n",
      "79/1662\n",
      "file_name: CarLongPlate20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate20.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.3ms preprocess, 122.9ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.736217\n",
      "recognized_text:  51F-324.88\n",
      "ocr_conf:  0.959\n",
      "80/1662\n",
      "file_name: CarLongPlate200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate200.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.3ms preprocess, 122.0ms inference, 9.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3405683\n",
      "recognized_text:  51A-029.23\n",
      "ocr_conf:  0.973\n",
      "81/1662\n",
      "file_name: CarLongPlate201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate201.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.531445\n",
      "recognized_text:  51F-734.20\n",
      "ocr_conf:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate21.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.2ms preprocess, 126.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/1662\n",
      "file_name: CarLongPlate21.jpg\n",
      "aspect_ratio: 3.4034631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate210.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-443.13\n",
      "ocr_conf:  0.876\n",
      "83/1662\n",
      "file_name: CarLongPlate210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2041352\n",
      "recognized_text:  51G-011.77\n",
      "ocr_conf:  0.943\n",
      "84/1662\n",
      "file_name: CarLongPlate211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate211.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.3ms preprocess, 124.8ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9909158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate220.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.6ms preprocess, 122.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.979\n",
      "85/1662\n",
      "file_name: CarLongPlate220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4632258\n",
      "recognized_text:  51G-473.40\n",
      "ocr_conf:  0.915\n",
      "86/1662\n",
      "file_name: CarLongPlate221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate221.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.3ms preprocess, 125.6ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5787425\n",
      "recognized_text:  51G-512.92\n",
      "ocr_conf:  0.952\n",
      "87/1662\n",
      "file_name: CarLongPlate230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate230.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4831429\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.966\n",
      "88/1662\n",
      "file_name: CarLongPlate231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate231.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.273889\n",
      "recognized_text:  62A-057.72\n",
      "ocr_conf:  0.954\n",
      "89/1662\n",
      "file_name: CarLongPlate240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate240.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.3ms preprocess, 131.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4995387\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.96\n",
      "90/1662\n",
      "file_name: CarLongPlate241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate241.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2861726\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.968\n",
      "91/1662\n",
      "file_name: CarLongPlate250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate250.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.7ms preprocess, 124.1ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3601544\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.973\n",
      "92/1662\n",
      "file_name: CarLongPlate251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate251.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.4ms preprocess, 122.5ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.385323\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.971\n",
      "93/1662\n",
      "file_name: CarLongPlate260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate260.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.0ms preprocess, 121.9ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3901045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.968\n",
      "94/1662\n",
      "file_name: CarLongPlate261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate261.jpg: 416x640 1 plate, 126.7ms\n",
      "Speed: 4.3ms preprocess, 126.7ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2207038\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/1662\n",
      "file_name: CarLongPlate270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate270.jpg: 416x640 1 plate, 129.0ms\n",
      "Speed: 4.3ms preprocess, 129.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2725925\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.979\n",
      "96/1662\n",
      "file_name: CarLongPlate271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate271.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.8ms preprocess, 131.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1491477\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.967\n",
      "97/1662\n",
      "file_name: CarLongPlate280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate280.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.8ms preprocess, 123.2ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4869587\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.955\n",
      "98/1662\n",
      "file_name: CarLongPlate281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate281.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.8ms preprocess, 123.0ms inference, 15.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3703856\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.912\n",
      "99/1662\n",
      "file_name: CarLongPlate290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate290.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.5ms preprocess, 132.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9926286\n",
      "recognized_text:  51F-869.88\n",
      "ocr_conf:  0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1662\n",
      "file_name: CarLongPlate291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate291.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.1ms preprocess, 123.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1524494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.912\n",
      "101/1662\n",
      "file_name: CarLongPlate30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate30.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.3ms preprocess, 125.4ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6763213\n",
      "recognized_text:  50LD-044.17\n",
      "ocr_conf:  0.901\n",
      "102/1662\n",
      "file_name: CarLongPlate300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate300.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8202875\n",
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.961\n",
      "103/1662\n",
      "file_name: CarLongPlate301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate301.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3271294\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.959\n",
      "104/1662\n",
      "file_name: CarLongPlate31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate31.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.394899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate310.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.2ms preprocess, 122.0ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.94\n",
      "105/1662\n",
      "file_name: CarLongPlate310.jpg\n",
      "aspect_ratio: 3.3383198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate311.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1F-574.93\n",
      "ocr_conf:  0.927\n",
      "106/1662\n",
      "file_name: CarLongPlate311.jpg\n",
      "aspect_ratio: 3.4364047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.959\n",
      "107/1662\n",
      "file_name: CarLongPlate320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate320.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.1ms preprocess, 122.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.860971\n",
      "recognized_text:  51A-165.98\n",
      "ocr_conf:  0.975\n",
      "108/1662\n",
      "file_name: CarLongPlate321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate321.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.822793\n",
      "recognized_text:  51A-165.98\n",
      "ocr_conf:  0.955\n",
      "109/1662\n",
      "file_name: CarLongPlate330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate330.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3665752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate331.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.934\n",
      "110/1662\n",
      "file_name: CarLongPlate331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2161372\n",
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.857\n",
      "111/1662\n",
      "file_name: CarLongPlate340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate340.jpg: 416x640 1 plate, 126.8ms\n",
      "Speed: 4.9ms preprocess, 126.8ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4572315\n",
      "recognized_text:  516-512.92\n",
      "ocr_conf:  0.967\n",
      "112/1662\n",
      "file_name: CarLongPlate341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate341.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5717893\n",
      "recognized_text:  51G-512.92\n",
      "ocr_conf:  0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate350.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.7ms preprocess, 123.6ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/1662\n",
      "file_name: CarLongPlate350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3164496\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.974\n",
      "114/1662\n",
      "file_name: CarLongPlate351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate351.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 13.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5385356\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.951\n",
      "115/1662\n",
      "file_name: CarLongPlate360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate360.jpg: 416x640 1 plate, 133.3ms\n",
      "Speed: 5.0ms preprocess, 133.3ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.319102\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.978\n",
      "116/1662\n",
      "file_name: CarLongPlate361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate361.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2185285\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.952\n",
      "117/1662\n",
      "file_name: CarLongPlate370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate370.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.0ms preprocess, 123.9ms inference, 14.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1763325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate371.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.7ms preprocess, 123.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-869.88\n",
      "ocr_conf:  0.94\n",
      "118/1662\n",
      "file_name: CarLongPlate371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1318905\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.955\n",
      "119/1662\n",
      "file_name: CarLongPlate380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate380.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3251772\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.947\n",
      "120/1662\n",
      "file_name: CarLongPlate381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate381.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.2ms preprocess, 124.3ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1419473\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.954\n",
      "121/1662\n",
      "file_name: CarLongPlate390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate390.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.5ms preprocess, 126.0ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7588613\n",
      "recognized_text:  51F-795.12\n",
      "ocr_conf:  0.983\n",
      "122/1662\n",
      "file_name: CarLongPlate391.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate391.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1501665\n",
      "recognized_text:  56N-7186\n",
      "ocr_conf:  0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate40.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/1662\n",
      "file_name: CarLongPlate40.jpg\n",
      "aspect_ratio: 3.4027367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-290.34\n",
      "ocr_conf:  0.975\n",
      "124/1662\n",
      "file_name: CarLongPlate400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate400.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4326384\n",
      "recognized_text:  51G-472.81\n",
      "ocr_conf:  0.895\n",
      "125/1662\n",
      "file_name: CarLongPlate401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate401.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.4ms preprocess, 124.7ms inference, 8.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7166097\n",
      "recognized_text:  51F-795.12\n",
      "ocr_conf:  0.981\n",
      "126/1662\n",
      "file_name: CarLongPlate41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate41.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.6ms preprocess, 124.1ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5433984\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.957\n",
      "127/1662\n",
      "file_name: CarLongPlate410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate410.jpg: 416x640 1 plate, 155.7ms\n",
      "Speed: 4.2ms preprocess, 155.7ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3637924\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate411.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.2ms preprocess, 121.9ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/1662\n",
      "file_name: CarLongPlate411.jpg\n",
      "aspect_ratio: 3.732044\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate420.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/1662\n",
      "file_name: CarLongPlate420.jpg\n",
      "aspect_ratio: 3.5576959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate421.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-216.70\n",
      "ocr_conf:  0.928\n",
      "130/1662\n",
      "file_name: CarLongPlate421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3865743\n",
      "recognized_text:  59-01509.06\n",
      "ocr_conf:  0.902\n",
      "131/1662\n",
      "file_name: CarLongPlate430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate430.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1579041\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.954\n",
      "132/1662\n",
      "file_name: CarLongPlate431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate431.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3211267\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.951\n",
      "133/1662\n",
      "file_name: CarLongPlate440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate440.jpg: 416x640 1 plate, 135.1ms\n",
      "Speed: 4.5ms preprocess, 135.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2718456\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.935\n",
      "134/1662\n",
      "file_name: CarLongPlate441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate441.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.8ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3684072\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.972\n",
      "135/1662\n",
      "file_name: CarLongPlate450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate450.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.0ms preprocess, 124.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9268656\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/1662\n",
      "file_name: CarLongPlate451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate451.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4791448\n",
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate460.jpg: 416x640 1 plate, 126.9ms\n",
      "Speed: 4.1ms preprocess, 126.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/1662\n",
      "file_name: CarLongPlate460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.099465\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.975\n",
      "138/1662\n",
      "file_name: CarLongPlate461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate461.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2674332\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.954\n",
      "139/1662\n",
      "file_name: CarLongPlate470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate470.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.405378\n",
      "recognized_text:  516-510.08\n",
      "ocr_conf:  0.923\n",
      "140/1662\n",
      "file_name: CarLongPlate471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate471.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.1ms preprocess, 123.7ms inference, 8.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7273269\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.966\n",
      "141/1662\n",
      "file_name: CarLongPlate480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate480.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2030666\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.903\n",
      "142/1662\n",
      "file_name: CarLongPlate481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate481.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0308867\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/1662\n",
      "file_name: CarLongPlate490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate490.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 5.0ms preprocess, 123.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6750495\n",
      "recognized_text:  51G-495.39\n",
      "ocr_conf:  0.94\n",
      "144/1662\n",
      "file_name: CarLongPlate491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate491.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4682229\n",
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.955\n",
      "145/1662\n",
      "file_name: CarLongPlate50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate50.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.296512\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate500.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/1662\n",
      "file_name: CarLongPlate500.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6215072\n",
      "recognized_text:  62A-055.16\n",
      "ocr_conf:  0.946\n",
      "147/1662\n",
      "file_name: CarLongPlate501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate501.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.3ms preprocess, 122.6ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4406972\n",
      "recognized_text:  51F-734.20\n",
      "ocr_conf:  0.968\n",
      "148/1662\n",
      "file_name: CarLongPlate51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate51.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.0ms preprocess, 123.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3683462\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.966\n",
      "149/1662\n",
      "file_name: CarLongPlate510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate510.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.2ms preprocess, 124.0ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3879511\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.978\n",
      "150/1662\n",
      "file_name: CarLongPlate511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate511.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 5.1ms preprocess, 126.3ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4749384\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.979\n",
      "151/1662\n",
      "file_name: CarLongPlate520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate520.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.304321\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.962\n",
      "152/1662\n",
      "file_name: CarLongPlate521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate521.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2963097\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.954\n",
      "153/1662\n",
      "file_name: CarLongPlate530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate530.jpg: 416x640 1 plate, 126.8ms\n",
      "Speed: 4.5ms preprocess, 126.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1889076\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.922\n",
      "154/1662\n",
      "file_name: CarLongPlate531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate531.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.4ms preprocess, 124.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4838622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-373.07\n",
      "ocr_conf:  0.925\n",
      "155/1662\n",
      "file_name: CarLongPlate540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate540.jpg: 416x640 1 plate, 222.9ms\n",
      "Speed: 4.5ms preprocess, 222.9ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1575162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate541.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 13.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.977\n",
      "156/1662\n",
      "file_name: CarLongPlate541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.887225\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.96\n",
      "157/1662\n",
      "file_name: CarLongPlate550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate550.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2552185\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.897\n",
      "158/1662\n",
      "file_name: CarLongPlate551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate551.jpg: 416x640 1 plate, 125.3ms\n",
      "Speed: 4.8ms preprocess, 125.3ms inference, 10.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5024276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.967\n",
      "159/1662\n",
      "file_name: CarLongPlate560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate560.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2687073\n",
      "recognized_text:  51C-593.23\n",
      "ocr_conf:  0.946\n",
      "160/1662\n",
      "file_name: CarLongPlate561.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate561.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1766448\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.968\n",
      "161/1662\n",
      "file_name: CarLongPlate570.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate570.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1284876\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate571.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/1662\n",
      "file_name: CarLongPlate571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.260889\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.978\n",
      "163/1662\n",
      "file_name: CarLongPlate580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate580.jpg: 416x640 1 plate, 140.2ms\n",
      "Speed: 4.5ms preprocess, 140.2ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2846415\n",
      "recognized_text:  51G-102.09\n",
      "ocr_conf:  0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/1662\n",
      "file_name: CarLongPlate581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate581.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.314292\n",
      "recognized_text:  51G-373.07\n",
      "ocr_conf:  0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate590.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/1662\n",
      "file_name: CarLongPlate590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7842891\n",
      "recognized_text:  516-216.70\n",
      "ocr_conf:  0.926\n",
      "166/1662\n",
      "file_name: CarLongPlate591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate591.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.9ms preprocess, 123.1ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4524388\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.935\n",
      "167/1662\n",
      "file_name: CarLongPlate60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate60.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.466374\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.92\n",
      "168/1662\n",
      "file_name: CarLongPlate600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate600.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 5.1ms preprocess, 130.0ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2830667\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.94\n",
      "169/1662\n",
      "file_name: CarLongPlate601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate601.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 8.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2767367\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.961\n",
      "170/1662\n",
      "file_name: CarLongPlate61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate61.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.1ms preprocess, 123.8ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.26637\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.981\n",
      "171/1662\n",
      "file_name: CarLongPlate610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate610.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.7ms preprocess, 124.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1911383\n",
      "recognized_text:  51G-510.08\n",
      "ocr_conf:  0.945\n",
      "172/1662\n",
      "file_name: CarLongPlate611.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate611.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.8ms preprocess, 123.8ms inference, 11.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4026694\n",
      "recognized_text:  56N-0666\n",
      "ocr_conf:  0.966\n",
      "173/1662\n",
      "file_name: CarLongPlate620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate620.jpg: 416x640 1 plate, 129.1ms\n",
      "Speed: 4.3ms preprocess, 129.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4773314\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.958\n",
      "174/1662\n",
      "file_name: CarLongPlate621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate621.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.6ms preprocess, 124.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3297327\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.967\n",
      "175/1662\n",
      "file_name: CarLongPlate630.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate630.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.663848\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.909\n",
      "176/1662\n",
      "file_name: CarLongPlate631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate631.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.8ms preprocess, 123.2ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2859116\n",
      "recognized_text:  60A-038.68\n",
      "ocr_conf:  0.948\n",
      "177/1662\n",
      "file_name: CarLongPlate640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate640.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.3ms preprocess, 123.9ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0432334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate641.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.969\n",
      "178/1662\n",
      "file_name: CarLongPlate641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8243122\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.966\n",
      "179/1662\n",
      "file_name: CarLongPlate650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate650.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2398121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-220.29\n",
      "ocr_conf:  0.962\n",
      "180/1662\n",
      "file_name: CarLongPlate651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate651.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2822225\n",
      "recognized_text:  51G-014.40\n",
      "ocr_conf:  0.914\n",
      "181/1662\n",
      "file_name: CarLongPlate660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate660.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.8ms preprocess, 123.6ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0349975\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.96\n",
      "182/1662\n",
      "file_name: CarLongPlate661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate661.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.7ms preprocess, 122.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1286051\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.956\n",
      "183/1662\n",
      "file_name: CarLongPlate670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate670.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.8ms preprocess, 122.5ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.59824\n",
      "recognized_text:  nv-3993\n",
      "ocr_conf:  0.823\n",
      "184/1662\n",
      "file_name: CarLongPlate671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate671.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0065727\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.921\n",
      "185/1662\n",
      "file_name: CarLongPlate680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate680.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.0ms preprocess, 123.7ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8117988\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.921\n",
      "186/1662\n",
      "file_name: CarLongPlate681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate681.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5480566\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.961\n",
      "187/1662\n",
      "file_name: CarLongPlate690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate690.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.8ms preprocess, 125.6ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7421298\n",
      "recognized_text:  51G-491.60\n",
      "ocr_conf:  0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate691.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/1662\n",
      "file_name: CarLongPlate691.jpg\n",
      "aspect_ratio: 3.2207284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate70.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  61A-229.59\n",
      "ocr_conf:  0.959\n",
      "189/1662\n",
      "file_name: CarLongPlate70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1717336\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.948\n",
      "190/1662\n",
      "file_name: CarLongPlate700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate700.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 6.2ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3978791\n",
      "recognized_text:  51A-602.16\n",
      "ocr_conf:  0.925\n",
      "191/1662\n",
      "file_name: CarLongPlate701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate701.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9157085\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.937\n",
      "192/1662\n",
      "file_name: CarLongPlate71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate71.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 15.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1107202\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.97\n",
      "193/1662\n",
      "file_name: CarLongPlate710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate710.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.9ms preprocess, 132.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.374225\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.956\n",
      "194/1662\n",
      "file_name: CarLongPlate711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate711.jpg: 416x640 1 plate, 155.9ms\n",
      "Speed: 4.8ms preprocess, 155.9ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2715566\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.906\n",
      "195/1662\n",
      "file_name: CarLongPlate720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate720.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.6ms preprocess, 124.2ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3146143\n",
      "recognized_text:  62A-051.95\n",
      "ocr_conf:  0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate721.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/1662\n",
      "file_name: CarLongPlate721.jpg\n",
      "aspect_ratio: 3.8915102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate730.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.6ms preprocess, 122.9ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.962\n",
      "197/1662\n",
      "file_name: CarLongPlate730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.133794\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.921\n",
      "198/1662\n",
      "file_name: CarLongPlate731.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate731.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.011467\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.94\n",
      "199/1662\n",
      "file_name: CarLongPlate740.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate740.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.9ms preprocess, 123.7ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2348294\n",
      "recognized_text:  61A-300.01\n",
      "ocr_conf:  0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/1662\n",
      "file_name: CarLongPlate741.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate741.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.3ms preprocess, 122.5ms inference, 3.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2791817\n",
      "recognized_text:  61A-300.01\n",
      "ocr_conf:  0.905\n",
      "201/1662\n",
      "file_name: CarLongPlate750.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate750.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.4ms preprocess, 122.3ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.614809\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.976\n",
      "202/1662\n",
      "file_name: CarLongPlate751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate751.jpg: 416x640 1 plate, 133.8ms\n",
      "Speed: 4.6ms preprocess, 133.8ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5340607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.968\n",
      "203/1662\n",
      "file_name: CarLongPlate760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate760.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.3ms preprocess, 126.1ms inference, 16.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3426578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate761.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.982\n",
      "204/1662\n",
      "file_name: CarLongPlate761.jpg\n",
      "aspect_ratio: 3.320234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate770.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.98\n",
      "205/1662\n",
      "file_name: CarLongPlate770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6383245\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.964\n",
      "206/1662\n",
      "file_name: CarLongPlate771.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate771.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.494582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.965\n",
      "207/1662\n",
      "file_name: CarLongPlate780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate780.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.4ms preprocess, 124.9ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3808842\n",
      "recognized_text:  51G-011.77\n",
      "ocr_conf:  0.91\n",
      "208/1662\n",
      "file_name: CarLongPlate781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate781.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1538846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  G-011.77\n",
      "ocr_conf:  0.901\n",
      "209/1662\n",
      "file_name: CarLongPlate790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate790.jpg: 416x640 1 plate, 128.8ms\n",
      "Speed: 4.4ms preprocess, 128.8ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8757215\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate791.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 5.0ms preprocess, 125.5ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/1662\n",
      "file_name: CarLongPlate791.jpg\n",
      "aspect_ratio: 3.687791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate80.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.9ms preprocess, 122.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.947\n",
      "211/1662\n",
      "file_name: CarLongPlate80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2435033\n",
      "recognized_text:  61A-897.14\n",
      "ocr_conf:  0.934\n",
      "212/1662\n",
      "file_name: CarLongPlate800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate800.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6751428\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.973\n",
      "213/1662\n",
      "file_name: CarLongPlate801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate801.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 4.4ms preprocess, 130.0ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2672923\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.967\n",
      "214/1662\n",
      "file_name: CarLongPlate81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate81.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2993355\n",
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.973\n",
      "215/1662\n",
      "file_name: CarLongPlate810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate810.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2252233\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.962\n",
      "216/1662\n",
      "file_name: CarLongPlate811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate811.jpg: 416x640 1 plate, 125.9ms\n",
      "Speed: 4.5ms preprocess, 125.9ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.296323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.959\n",
      "217/1662\n",
      "file_name: CarLongPlate820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate820.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2093287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate821.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.964\n",
      "218/1662\n",
      "file_name: CarLongPlate821.jpg\n",
      "aspect_ratio: 3.1464229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-554.33\n",
      "ocr_conf:  0.965\n",
      "219/1662\n",
      "file_name: CarLongPlate830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate830.jpg: 416x640 1 plate, 135.4ms\n",
      "Speed: 5.1ms preprocess, 135.4ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.527998\n",
      "recognized_text:  516-102.09\n",
      "ocr_conf:  0.951\n",
      "220/1662\n",
      "file_name: CarLongPlate831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate831.jpg: 416x640 1 plate, 130.6ms\n",
      "Speed: 4.9ms preprocess, 130.6ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2644045\n",
      "recognized_text:  51G-510.08\n",
      "ocr_conf:  0.939\n",
      "221/1662\n",
      "file_name: CarLongPlate840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate840.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.0ms preprocess, 123.3ms inference, 14.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5144362\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.935\n",
      "222/1662\n",
      "file_name: CarLongPlate841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate841.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.0ms preprocess, 123.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6196785\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.94\n",
      "223/1662\n",
      "file_name: CarLongPlate850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate850.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4837728\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.925\n",
      "224/1662\n",
      "file_name: CarLongPlate851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate851.jpg: 416x640 1 plate, 238.5ms\n",
      "Speed: 4.5ms preprocess, 238.5ms inference, 3.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1817605\n",
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate860.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.2ms preprocess, 123.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/1662\n",
      "file_name: CarLongPlate860.jpg\n",
      "aspect_ratio: 3.1844358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate861.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.3ms preprocess, 123.2ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.952\n",
      "226/1662\n",
      "file_name: CarLongPlate861.jpg\n",
      "aspect_ratio: 4.1434417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate870.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 7.5ms preprocess, 123.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-205.36\n",
      "ocr_conf:  0.974\n",
      "227/1662\n",
      "file_name: CarLongPlate870.jpg\n",
      "aspect_ratio: 3.4085407\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/1662\n",
      "file_name: CarLongPlate871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate871.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2417917\n",
      "recognized_text:  51F-13251\n",
      "ocr_conf:  0.919\n",
      "229/1662\n",
      "file_name: CarLongPlate880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate880.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2788665\n",
      "recognized_text:  516-481.54\n",
      "ocr_conf:  0.918\n",
      "230/1662\n",
      "file_name: CarLongPlate881.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate881.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.2ms preprocess, 122.0ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3045325\n",
      "recognized_text:  51G-481.54\n",
      "ocr_conf:  0.902\n",
      "231/1662\n",
      "file_name: CarLongPlate890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate890.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 6.7ms preprocess, 123.9ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8844867\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.926\n",
      "232/1662\n",
      "file_name: CarLongPlate891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate891.jpg: 416x640 1 plate, 119.7ms\n",
      "Speed: 4.4ms preprocess, 119.7ms inference, 9.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5934956\n",
      "recognized_text:  51F-212.55\n",
      "ocr_conf:  0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/1662\n",
      "file_name: CarLongPlate90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate90.jpg: 416x640 1 plate, 129.4ms\n",
      "Speed: 4.6ms preprocess, 129.4ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9105978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-687.84\n",
      "ocr_conf:  0.971\n",
      "234/1662\n",
      "file_name: CarLongPlate900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate900.jpg: 416x640 1 plate, 126.9ms\n",
      "Speed: 4.4ms preprocess, 126.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4009955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-759.32\n",
      "ocr_conf:  0.918\n",
      "235/1662\n",
      "file_name: CarLongPlate901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate901.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2504165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate91.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.977\n",
      "236/1662\n",
      "file_name: CarLongPlate91.jpg\n",
      "aspect_ratio: 3.5075035\n",
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/1662\n",
      "file_name: CarLongPlate910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate910.jpg: 416x640 1 plate, 128.5ms\n",
      "Speed: 4.4ms preprocess, 128.5ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6729214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate911.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 5.2ms preprocess, 123.5ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.96\n",
      "238/1662\n",
      "file_name: CarLongPlate911.jpg\n",
      "aspect_ratio: 3.176598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.975\n",
      "239/1662\n",
      "file_name: CarLongPlate920.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate920.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 4.6ms preprocess, 125.5ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1440842\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.969\n",
      "240/1662\n",
      "file_name: CarLongPlate921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate921.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4494872\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.97\n",
      "241/1662\n",
      "file_name: CarLongPlate930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate930.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 6.0ms preprocess, 123.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8398333\n",
      "recognized_text:  30E-000.90\n",
      "ocr_conf:  0.975\n",
      "242/1662\n",
      "file_name: CarLongPlate931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate931.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.5ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5631382\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.97\n",
      "243/1662\n",
      "file_name: CarLongPlate940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate940.jpg: 416x640 1 plate, 132.6ms\n",
      "Speed: 4.8ms preprocess, 132.6ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5410464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-356.13\n",
      "ocr_conf:  0.981\n",
      "244/1662\n",
      "file_name: CarLongPlate941.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate941.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 14.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5287123\n",
      "recognized_text:  51F-356.13\n",
      "ocr_conf:  0.971\n",
      "245/1662\n",
      "file_name: CarLongPlate950.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate950.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.6ms preprocess, 122.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2463775\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.936\n",
      "246/1662\n",
      "file_name: CarLongPlate951.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate951.jpg: 416x640 1 plate, 132.3ms\n",
      "Speed: 4.8ms preprocess, 132.3ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8674562\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.965\n",
      "247/1662\n",
      "file_name: CarLongPlate960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate960.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.9ms preprocess, 123.1ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3687878\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.957\n",
      "248/1662\n",
      "file_name: CarLongPlate961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate961.jpg: 416x640 1 plate, 147.0ms\n",
      "Speed: 5.0ms preprocess, 147.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.516787\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.975\n",
      "249/1662\n",
      "file_name: CarLongPlate970.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate970.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.989144\n",
      "recognized_text:  51G-205.36\n",
      "ocr_conf:  0.937\n",
      "250/1662\n",
      "file_name: CarLongPlate971.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate971.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.2ms preprocess, 124.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6754982\n",
      "recognized_text:  51G-205.36\n",
      "ocr_conf:  0.965\n",
      "251/1662\n",
      "file_name: CarLongPlate980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate980.jpg: 416x640 1 plate, 128.4ms\n",
      "Speed: 4.6ms preprocess, 128.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.295258\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.93\n",
      "252/1662\n",
      "file_name: CarLongPlate981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate981.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.0ms preprocess, 124.1ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7508664\n",
      "recognized_text:  51F-132.51\n",
      "ocr_conf:  0.946\n",
      "253/1662\n",
      "file_name: CarLongPlate990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate990.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 6.6ms preprocess, 123.1ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6295378\n",
      "recognized_text:  1F-984.66\n",
      "ocr_conf:  0.934\n",
      "254/1662\n",
      "file_name: CarLongPlate991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlate991.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5967171\n",
      "recognized_text:  51F-582.14\n",
      "ocr_conf:  0.97\n",
      "255/1662\n",
      "file_name: CarLongPlateGen0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen0.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.1615624\n",
      "recognized_text:  HIC-1009H\n",
      "ocr_conf:  0.61\n",
      "256/1662\n",
      "file_name: CarLongPlateGen1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.0ms preprocess, 124.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7534697\n",
      "recognized_text:  1-100\n",
      "ocr_conf:  0.794\n",
      "257/1662\n",
      "file_name: CarLongPlateGen10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen10.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.1ms preprocess, 123.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.707412\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.964\n",
      "258/1662\n",
      "file_name: CarLongPlateGen100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen100.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.2ms preprocess, 125.0ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9548488\n",
      "recognized_text:  PH\n",
      "ocr_conf:  0.384\n",
      "259/1662\n",
      "file_name: CarLongPlateGen1000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1000.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.6ms preprocess, 124.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.239801\n",
      "recognized_text:  51C-100.96\n",
      "ocr_conf:  0.917\n",
      "260/1662\n",
      "file_name: CarLongPlateGen1001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1001.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2167103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.892\n",
      "261/1662\n",
      "file_name: CarLongPlateGen101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen101.jpg: 416x640 1 plate, 126.5ms\n",
      "Speed: 4.3ms preprocess, 126.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7064009\n",
      "recognized_text:  516-316.91\n",
      "ocr_conf:  0.871\n",
      "262/1662\n",
      "file_name: CarLongPlateGen1010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1010.jpg: 416x640 1 plate, 144.9ms\n",
      "Speed: 4.9ms preprocess, 144.9ms inference, 15.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2321596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.974\n",
      "263/1662\n",
      "file_name: CarLongPlateGen1011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1011.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.6ms preprocess, 122.6ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.620345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-495.24\n",
      "ocr_conf:  0.956\n",
      "264/1662\n",
      "file_name: CarLongPlateGen1020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1020.jpg: 416x640 1 plate, 120.2ms\n",
      "Speed: 4.7ms preprocess, 120.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.46597\n",
      "recognized_text:  48A-028.66\n",
      "ocr_conf:  0.971\n",
      "265/1662\n",
      "file_name: CarLongPlateGen1021.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1021.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.9ms preprocess, 124.7ms inference, 16.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4341283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  48A-028.66\n",
      "ocr_conf:  0.933\n",
      "266/1662\n",
      "file_name: CarLongPlateGen1030.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1030.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.5ms preprocess, 128.9ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.761597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1031.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  47A-065.46\n",
      "ocr_conf:  0.969\n",
      "267/1662\n",
      "file_name: CarLongPlateGen1031.jpg\n",
      "aspect_ratio: 3.501528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-893.57\n",
      "ocr_conf:  0.968\n",
      "268/1662\n",
      "file_name: CarLongPlateGen1040.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1040.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 4.9ms preprocess, 125.5ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.940605\n",
      "recognized_text:  02.09\n",
      "ocr_conf:  0.817\n",
      "269/1662\n",
      "file_name: CarLongPlateGen1041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1041.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.9ms preprocess, 123.6ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6800652\n",
      "recognized_text:  51C-495.24\n",
      "ocr_conf:  0.905\n",
      "270/1662\n",
      "file_name: CarLongPlateGen1050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1050.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.6ms preprocess, 122.0ms inference, 10.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2441425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30N-4616\n",
      "ocr_conf:  0.855\n",
      "271/1662\n",
      "file_name: CarLongPlateGen1051.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1051.jpg: 416x640 1 plate, 126.6ms\n",
      "Speed: 4.5ms preprocess, 126.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.654838\n",
      "recognized_text:  48A-028.66\n",
      "ocr_conf:  0.971\n",
      "272/1662\n",
      "file_name: CarLongPlateGen1060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1060.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.1ms preprocess, 123.5ms inference, 9.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3287587\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.979\n",
      "273/1662\n",
      "file_name: CarLongPlateGen1061.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1061.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 5.0ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4291253\n",
      "recognized_text:  51A-05227\n",
      "ocr_conf:  0.97\n",
      "274/1662\n",
      "file_name: CarLongPlateGen1070.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1070.jpg: 416x640 1 plate, 131.3ms\n",
      "Speed: 5.1ms preprocess, 131.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.247801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.975\n",
      "275/1662\n",
      "file_name: CarLongPlateGen1071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1071.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 8.1ms preprocess, 123.5ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.416875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1080.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.3ms preprocess, 122.8ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.965\n",
      "276/1662\n",
      "file_name: CarLongPlateGen1080.jpg\n",
      "aspect_ratio: 3.7344024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1081.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.976\n",
      "277/1662\n",
      "file_name: CarLongPlateGen1081.jpg\n",
      "aspect_ratio: 3.9088123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1090.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.1ms preprocess, 122.9ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.973\n",
      "278/1662\n",
      "file_name: CarLongPlateGen1090.jpg\n",
      "aspect_ratio: 2.8893266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1091.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.6ms preprocess, 123.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.922\n",
      "279/1662\n",
      "file_name: CarLongPlateGen1091.jpg\n",
      "aspect_ratio: 3.35551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen11.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.953\n",
      "280/1662\n",
      "file_name: CarLongPlateGen11.jpg\n",
      "aspect_ratio: 4.9312963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51C-49524\n",
      "ocr_conf:  0.826\n",
      "281/1662\n",
      "file_name: CarLongPlateGen110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen110.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.4ms preprocess, 122.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.1578236\n",
      "recognized_text:  GA33081\n",
      "ocr_conf:  0.37\n",
      "282/1662\n",
      "file_name: CarLongPlateGen1100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1100.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3342698\n",
      "recognized_text:  51G-316.911\n",
      "ocr_conf:  0.877\n",
      "283/1662\n",
      "file_name: CarLongPlateGen1101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1101.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.4ms preprocess, 122.6ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5374746\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.951\n",
      "284/1662\n",
      "file_name: CarLongPlateGen111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen111.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.8ms preprocess, 123.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5932674\n",
      "recognized_text:  CEHON\n",
      "ocr_conf:  0.303\n",
      "285/1662\n",
      "file_name: CarLongPlateGen1110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1110.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.1ms preprocess, 124.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6181636\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.967\n",
      "286/1662\n",
      "file_name: CarLongPlateGen1111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1111.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.4ms preprocess, 124.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6814864\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.96\n",
      "287/1662\n",
      "file_name: CarLongPlateGen1120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1120.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.1ms preprocess, 123.7ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.258991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1121.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 5.0ms preprocess, 124.0ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.955\n",
      "288/1662\n",
      "file_name: CarLongPlateGen1121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6261044\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.935\n",
      "289/1662\n",
      "file_name: CarLongPlateGen1130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1130.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.176881\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.963\n",
      "290/1662\n",
      "file_name: CarLongPlateGen1131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1131.jpg: 416x640 1 plate, 125.9ms\n",
      "Speed: 4.4ms preprocess, 125.9ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.289053\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.97\n",
      "291/1662\n",
      "file_name: CarLongPlateGen1140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1140.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0413272\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.963\n",
      "292/1662\n",
      "file_name: CarLongPlateGen1141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1141.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.3ms preprocess, 122.5ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.041071\n",
      "recognized_text:  51A-01204\n",
      "ocr_conf:  0.951\n",
      "293/1662\n",
      "file_name: CarLongPlateGen1150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1150.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.362237\n",
      "recognized_text:  F-763.54\n",
      "ocr_conf:  0.933\n",
      "294/1662\n",
      "file_name: CarLongPlateGen1151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1151.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.7ms preprocess, 126.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2187345\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.899\n",
      "295/1662\n",
      "file_name: CarLongPlateGen1160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1160.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.5ms preprocess, 124.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.359697\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.97\n",
      "296/1662\n",
      "file_name: CarLongPlateGen1161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1161.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1787138\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.944\n",
      "297/1662\n",
      "file_name: CarLongPlateGen1170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1170.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4717352\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.93\n",
      "298/1662\n",
      "file_name: CarLongPlateGen1171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1171.jpg: 416x640 1 plate, 128.4ms\n",
      "Speed: 4.3ms preprocess, 128.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3045387\n",
      "recognized_text:  51A-721.10\n",
      "ocr_conf:  0.921\n",
      "299/1662\n",
      "file_name: CarLongPlateGen1180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1180.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 5.5ms preprocess, 124.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4449015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1181.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.966\n",
      "300/1662\n",
      "file_name: CarLongPlateGen1181.jpg\n",
      "aspect_ratio: 3.1674032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-15585\n",
      "ocr_conf:  0.917\n",
      "301/1662\n",
      "file_name: CarLongPlateGen1190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1190.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 10.0ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.313813\n",
      "recognized_text:  51F-324.88\n",
      "ocr_conf:  0.941\n",
      "302/1662\n",
      "file_name: CarLongPlateGen1191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1191.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.2ms preprocess, 125.4ms inference, 14.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8371592\n",
      "recognized_text:  B1A73LR2\n",
      "ocr_conf:  0.566\n",
      "303/1662\n",
      "file_name: CarLongPlateGen120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen120.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4488316\n",
      "recognized_text:  1F-15685\n",
      "ocr_conf:  0.593\n",
      "304/1662\n",
      "file_name: CarLongPlateGen1200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1200.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.5ms preprocess, 121.9ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5816925\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.951\n",
      "305/1662\n",
      "file_name: CarLongPlateGen1201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1201.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.5ms preprocess, 122.5ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.338444\n",
      "recognized_text:  50LD-044.117\n",
      "ocr_conf:  0.851\n",
      "306/1662\n",
      "file_name: CarLongPlateGen121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen121.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.7ms preprocess, 124.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7159834\n",
      "recognized_text:  FIEERENE\n",
      "ocr_conf:  0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/1662\n",
      "file_name: CarLongPlateGen1210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1210.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2662852\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.971\n",
      "308/1662\n",
      "file_name: CarLongPlateGen1211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1211.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1520185\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.949\n",
      "309/1662\n",
      "file_name: CarLongPlateGen1220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1220.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4021459\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.974\n",
      "310/1662\n",
      "file_name: CarLongPlateGen1221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1221.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.366378\n",
      "recognized_text:  51G-251.81\n",
      "ocr_conf:  0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1230.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/1662\n",
      "file_name: CarLongPlateGen1230.jpg\n",
      "aspect_ratio: 3.4483993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.98\n",
      "312/1662\n",
      "file_name: CarLongPlateGen1231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1231.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2938304\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.965\n",
      "313/1662\n",
      "file_name: CarLongPlateGen1240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1240.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.4ms preprocess, 122.8ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3639867\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1241.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/1662\n",
      "file_name: CarLongPlateGen1241.jpg\n",
      "aspect_ratio: 3.7325726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.951\n",
      "315/1662\n",
      "file_name: CarLongPlateGen1250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1250.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2103636\n",
      "recognized_text:  60A-038.68\n",
      "ocr_conf:  0.913\n",
      "316/1662\n",
      "file_name: CarLongPlateGen1251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1251.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.5ms preprocess, 124.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.356241\n",
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.974\n",
      "317/1662\n",
      "file_name: CarLongPlateGen1260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1260.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8786824\n",
      "recognized_text:  51G-436.30\n",
      "ocr_conf:  0.9\n",
      "318/1662\n",
      "file_name: CarLongPlateGen1261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1261.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 3.9ms preprocess, 124.2ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6160707\n",
      "recognized_text:  50Z-1630\n",
      "ocr_conf:  0.921\n",
      "319/1662\n",
      "file_name: CarLongPlateGen1270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1270.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3500454\n",
      "recognized_text:  51F-075.68\n",
      "ocr_conf:  0.932\n",
      "320/1662\n",
      "file_name: CarLongPlateGen1271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1271.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3460023\n",
      "recognized_text:  51A-909.05\n",
      "ocr_conf:  0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1280.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/1662\n",
      "file_name: CarLongPlateGen1280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.407274\n",
      "recognized_text:  51A-029.23\n",
      "ocr_conf:  0.958\n",
      "322/1662\n",
      "file_name: CarLongPlateGen1281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1281.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.571805\n",
      "recognized_text:  51F-747.76\n",
      "ocr_conf:  0.972\n",
      "323/1662\n",
      "file_name: CarLongPlateGen1290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1290.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.409747\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.977\n",
      "324/1662\n",
      "file_name: CarLongPlateGen1291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1291.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3840232\n",
      "recognized_text:  51G-373.07\n",
      "ocr_conf:  0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen130.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325/1662\n",
      "file_name: CarLongPlateGen130.jpg\n",
      "aspect_ratio: 3.711438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1300.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  5106592\n",
      "ocr_conf:  0.761\n",
      "326/1662\n",
      "file_name: CarLongPlateGen1300.jpg\n",
      "aspect_ratio: 3.4958777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1301.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.4ms preprocess, 122.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60A-399.51\n",
      "ocr_conf:  0.98\n",
      "327/1662\n",
      "file_name: CarLongPlateGen1301.jpg\n",
      "aspect_ratio: 3.5387437\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen131.jpg: 416x640 1 plate, 123.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/1662\n",
      "file_name: CarLongPlateGen131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.2ms preprocess, 123.0ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.953107\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.873\n",
      "329/1662\n",
      "file_name: CarLongPlateGen1310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1310.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 11.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7832608\n",
      "recognized_text:  60A-214.18\n",
      "ocr_conf:  0.939\n",
      "330/1662\n",
      "file_name: CarLongPlateGen1311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1311.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3561664\n",
      "recognized_text:  51F-220.29\n",
      "ocr_conf:  0.981\n",
      "331/1662\n",
      "file_name: CarLongPlateGen1320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1320.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0046635\n",
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.908\n",
      "332/1662\n",
      "file_name: CarLongPlateGen1321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1321.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 5.1ms preprocess, 124.8ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.051618\n",
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.884\n",
      "333/1662\n",
      "file_name: CarLongPlateGen1330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1330.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 5.3ms preprocess, 122.9ms inference, 12.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.10338\n",
      "recognized_text:  51G-373.07\n",
      "ocr_conf:  0.906\n",
      "334/1662\n",
      "file_name: CarLongPlateGen1331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1331.jpg: 416x640 1 plate, 127.0ms\n",
      "Speed: 4.7ms preprocess, 127.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3933067\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.973\n",
      "335/1662\n",
      "file_name: CarLongPlateGen1340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1340.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.5ms preprocess, 128.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9301245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1341.jpg: 416x640 1 plate, 123.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-06609\n",
      "ocr_conf:  0.957\n",
      "336/1662\n",
      "file_name: CarLongPlateGen1341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.3ms preprocess, 123.4ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.109505\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.982\n",
      "337/1662\n",
      "file_name: CarLongPlateGen1350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1350.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.360413\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.97\n",
      "338/1662\n",
      "file_name: CarLongPlateGen1351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1351.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.4ms preprocess, 123.4ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2907207\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.92\n",
      "339/1662\n",
      "file_name: CarLongPlateGen1360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1360.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1524007\n",
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.91\n",
      "340/1662\n",
      "file_name: CarLongPlateGen1361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1361.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.7ms preprocess, 123.2ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.27502\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1370.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 6.5ms preprocess, 123.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/1662\n",
      "file_name: CarLongPlateGen1370.jpg\n",
      "aspect_ratio: 3.7799568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1371.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 5.0ms preprocess, 123.1ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.965\n",
      "342/1662\n",
      "file_name: CarLongPlateGen1371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1148877\n",
      "recognized_text:  51F-075.68\n",
      "ocr_conf:  0.956\n",
      "343/1662\n",
      "file_name: CarLongPlateGen1380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1380.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.7ms preprocess, 122.5ms inference, 14.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4742203\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1381.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/1662\n",
      "file_name: CarLongPlateGen1381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2114108\n",
      "recognized_text:  51A-029.23\n",
      "ocr_conf:  0.957\n",
      "345/1662\n",
      "file_name: CarLongPlateGen1390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1390.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3451185\n",
      "recognized_text:  51G-495.39\n",
      "ocr_conf:  0.928\n",
      "346/1662\n",
      "file_name: CarLongPlateGen1391.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1391.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6372744\n",
      "recognized_text:  60M8965\n",
      "ocr_conf:  0.917\n",
      "347/1662\n",
      "file_name: CarLongPlateGen140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen140.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.65725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.896\n",
      "348/1662\n",
      "file_name: CarLongPlateGen1400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1400.jpg: 416x640 1 plate, 129.5ms\n",
      "Speed: 4.5ms preprocess, 129.5ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2540221\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.883\n",
      "349/1662\n",
      "file_name: CarLongPlateGen1401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1401.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.6ms preprocess, 124.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1468053\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.872\n",
      "350/1662\n",
      "file_name: CarLongPlateGen141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen141.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7242422\n",
      "recognized_text:  51401209\n",
      "ocr_conf:  0.77\n",
      "351/1662\n",
      "file_name: CarLongPlateGen1410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1410.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3162003\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1411.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/1662\n",
      "file_name: CarLongPlateGen1411.jpg\n",
      "aspect_ratio: 3.268914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1420.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.966\n",
      "353/1662\n",
      "file_name: CarLongPlateGen1420.jpg\n",
      "aspect_ratio: 2.8361745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.976\n",
      "354/1662\n",
      "file_name: CarLongPlateGen1421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1421.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 15.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0971699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1430.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 11.0ms preprocess, 123.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.969\n",
      "355/1662\n",
      "file_name: CarLongPlateGen1430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.457429\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.963\n",
      "356/1662\n",
      "file_name: CarLongPlateGen1431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1431.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.8ms preprocess, 124.1ms inference, 9.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4920084\n",
      "recognized_text:  51F-869.88\n",
      "ocr_conf:  0.971\n",
      "357/1662\n",
      "file_name: CarLongPlateGen1440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1440.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2827473\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.959\n",
      "358/1662\n",
      "file_name: CarLongPlateGen1441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1441.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2879746\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.93\n",
      "359/1662\n",
      "file_name: CarLongPlateGen1450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1450.jpg: 416x640 1 plate, 132.8ms\n",
      "Speed: 4.3ms preprocess, 132.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1429312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  56N-7186\n",
      "ocr_conf:  0.978\n",
      "360/1662\n",
      "file_name: CarLongPlateGen1451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1451.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.8ms preprocess, 125.8ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.702166\n",
      "recognized_text:  51F-207.54\n",
      "ocr_conf:  0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1460.jpg: 416x640 1 plate, 125.7ms\n",
      "Speed: 4.5ms preprocess, 125.7ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/1662\n",
      "file_name: CarLongPlateGen1460.jpg\n",
      "aspect_ratio: 3.3278167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1461.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 5.2ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-217.48\n",
      "ocr_conf:  0.937\n",
      "362/1662\n",
      "file_name: CarLongPlateGen1461.jpg\n",
      "aspect_ratio: 3.2572873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-344.711\n",
      "ocr_conf:  0.924\n",
      "363/1662\n",
      "file_name: CarLongPlateGen1470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1470.jpg: 416x640 1 plate, 158.3ms\n",
      "Speed: 4.9ms preprocess, 158.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6093361\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.967\n",
      "364/1662\n",
      "file_name: CarLongPlateGen1471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1471.jpg: 416x640 1 plate, 126.5ms\n",
      "Speed: 4.6ms preprocess, 126.5ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.616692\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.963\n",
      "365/1662\n",
      "file_name: CarLongPlateGen1480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1480.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3480773\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.977\n",
      "366/1662\n",
      "file_name: CarLongPlateGen1481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1481.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.5ms preprocess, 132.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0818326\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1490.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.7ms preprocess, 122.8ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/1662\n",
      "file_name: CarLongPlateGen1490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0301404\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.93\n",
      "368/1662\n",
      "file_name: CarLongPlateGen1491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1491.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4170244\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.975\n",
      "369/1662\n",
      "file_name: CarLongPlateGen150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen150.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9426732\n",
      "recognized_text:  F-76354\n",
      "ocr_conf:  0.91\n",
      "370/1662\n",
      "file_name: CarLongPlateGen1500.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1500.jpg: 416x640 1 plate, 129.8ms\n",
      "Speed: 4.9ms preprocess, 129.8ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3660135\n",
      "recognized_text:  F-869.88\n",
      "ocr_conf:  0.899\n",
      "371/1662\n",
      "file_name: CarLongPlateGen1501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1501.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 5.2ms preprocess, 123.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3391473\n",
      "recognized_text:  869.88\n",
      "ocr_conf:  0.971\n",
      "372/1662\n",
      "file_name: CarLongPlateGen151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen151.jpg: 416x640 1 plate, 126.6ms\n",
      "Speed: 4.5ms preprocess, 126.6ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.428141\n",
      "recognized_text:  51F-80270\n",
      "ocr_conf:  0.785\n",
      "373/1662\n",
      "file_name: CarLongPlateGen1510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1510.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.5ms preprocess, 132.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2814617\n",
      "recognized_text:  52Z-9755\n",
      "ocr_conf:  0.915\n",
      "374/1662\n",
      "file_name: CarLongPlateGen1511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1511.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.3ms preprocess, 122.8ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9023194\n",
      "recognized_text:  522-9755\n",
      "ocr_conf:  0.903\n",
      "375/1662\n",
      "file_name: CarLongPlateGen1520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1520.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 9.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3398578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-510.08\n",
      "ocr_conf:  0.945\n",
      "376/1662\n",
      "file_name: CarLongPlateGen1521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1521.jpg: 416x640 1 plate, 129.9ms\n",
      "Speed: 4.5ms preprocess, 129.9ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3172984\n",
      "recognized_text:  51G-510.08\n",
      "ocr_conf:  0.921\n",
      "377/1662\n",
      "file_name: CarLongPlateGen1530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1530.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.8ms preprocess, 125.0ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1797028\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.951\n",
      "378/1662\n",
      "file_name: CarLongPlateGen1531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1531.jpg: 416x640 1 plate, 155.6ms\n",
      "Speed: 5.9ms preprocess, 155.6ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8952775\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.919\n",
      "379/1662\n",
      "file_name: CarLongPlateGen1540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1540.jpg: 416x640 1 plate, 125.3ms\n",
      "Speed: 4.6ms preprocess, 125.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5371664\n",
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.949\n",
      "380/1662\n",
      "file_name: CarLongPlateGen1541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1541.jpg: 416x640 1 plate, 127.0ms\n",
      "Speed: 4.1ms preprocess, 127.0ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3671699\n",
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.938\n",
      "381/1662\n",
      "file_name: CarLongPlateGen1550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1550.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6768851\n",
      "recognized_text:  S1C-216.70\n",
      "ocr_conf:  0.872\n",
      "382/1662\n",
      "file_name: CarLongPlateGen1551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1551.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.5ms preprocess, 124.2ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2728744\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1560.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/1662\n",
      "file_name: CarLongPlateGen1560.jpg\n",
      "aspect_ratio: 3.1036434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1561.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-25481\n",
      "ocr_conf:  0.938\n",
      "384/1662\n",
      "file_name: CarLongPlateGen1561.jpg\n",
      "aspect_ratio: 3.1563592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1570.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 5.2ms preprocess, 124.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-25481\n",
      "ocr_conf:  0.959\n",
      "385/1662\n",
      "file_name: CarLongPlateGen1570.jpg\n",
      "aspect_ratio: 3.7140403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1571.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.4ms preprocess, 125.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-646.19\n",
      "ocr_conf:  0.98\n",
      "386/1662\n",
      "file_name: CarLongPlateGen1571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.208415\n",
      "recognized_text:  C-472.81\n",
      "ocr_conf:  0.882\n",
      "387/1662\n",
      "file_name: CarLongPlateGen1580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1580.jpg: 416x640 1 plate, 125.1ms\n",
      "Speed: 4.5ms preprocess, 125.1ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1810884\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.912\n",
      "388/1662\n",
      "file_name: CarLongPlateGen1581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1581.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.7ms preprocess, 123.9ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6076596\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.961\n",
      "389/1662\n",
      "file_name: CarLongPlateGen1590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1590.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 5.3ms preprocess, 123.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4484577\n",
      "recognized_text:  93LD-001.03\n",
      "ocr_conf:  0.928\n",
      "390/1662\n",
      "file_name: CarLongPlateGen1591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1591.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2950523\n",
      "recognized_text:  93D-001.03\n",
      "ocr_conf:  0.962\n",
      "391/1662\n",
      "file_name: CarLongPlateGen160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen160.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.051011\n",
      "recognized_text:  51A-69172\n",
      "ocr_conf:  0.886\n",
      "392/1662\n",
      "file_name: CarLongPlateGen1600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1600.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.2ms preprocess, 124.0ms inference, 15.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.509239\n",
      "recognized_text:  51F-220.29\n",
      "ocr_conf:  0.967\n",
      "393/1662\n",
      "file_name: CarLongPlateGen1601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1601.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1283545\n",
      "recognized_text:  516-01440\n",
      "ocr_conf:  0.918\n",
      "394/1662\n",
      "file_name: CarLongPlateGen161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen161.jpg: 416x640 1 plate, 130.7ms\n",
      "Speed: 5.0ms preprocess, 130.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5456803\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.892\n",
      "395/1662\n",
      "file_name: CarLongPlateGen1610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1610.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.7ms preprocess, 123.9ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.305287\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1611.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/1662\n",
      "file_name: CarLongPlateGen1611.jpg\n",
      "aspect_ratio: 3.3880932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1620.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.6ms preprocess, 124.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.872\n",
      "397/1662\n",
      "file_name: CarLongPlateGen1620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5290077\n",
      "recognized_text:  51G-102.09\n",
      "ocr_conf:  0.926\n",
      "398/1662\n",
      "file_name: CarLongPlateGen1621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1621.jpg: 416x640 1 plate, 131.8ms\n",
      "Speed: 4.3ms preprocess, 131.8ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4663393\n",
      "recognized_text:  51G-373.07\n",
      "ocr_conf:  0.961\n",
      "399/1662\n",
      "file_name: CarLongPlateGen1630.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1630.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.4ms preprocess, 125.6ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4223907\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.945\n",
      "400/1662\n",
      "file_name: CarLongPlateGen1631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1631.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3945372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1640.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.1ms preprocess, 123.9ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.98\n",
      "401/1662\n",
      "file_name: CarLongPlateGen1640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.255405\n",
      "recognized_text:  51F-582.50\n",
      "ocr_conf:  0.971\n",
      "402/1662\n",
      "file_name: CarLongPlateGen1641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1641.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5436041\n",
      "recognized_text:  51F-646.65\n",
      "ocr_conf:  0.958\n",
      "403/1662\n",
      "file_name: CarLongPlateGen1650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1650.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.1ms preprocess, 124.3ms inference, 3.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6635163\n",
      "recognized_text:  51G-472.81\n",
      "ocr_conf:  0.914\n",
      "404/1662\n",
      "file_name: CarLongPlateGen1651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1651.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2820854\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1660.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/1662\n",
      "file_name: CarLongPlateGen1660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6273823\n",
      "recognized_text:  51F-207.54\n",
      "ocr_conf:  0.976\n",
      "406/1662\n",
      "file_name: CarLongPlateGen1661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1661.jpg: 416x640 1 plate, 129.2ms\n",
      "Speed: 4.5ms preprocess, 129.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3956156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-428.61\n",
      "ocr_conf:  0.967\n",
      "407/1662\n",
      "file_name: CarLongPlateGen1670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1670.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.6ms preprocess, 122.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5184555\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/1662\n",
      "file_name: CarLongPlateGen1671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1671.jpg: 416x640 1 plate, 129.7ms\n",
      "Speed: 4.4ms preprocess, 129.7ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.328777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.96\n",
      "409/1662\n",
      "file_name: CarLongPlateGen1680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1680.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.6ms preprocess, 132.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2193072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.886\n",
      "410/1662\n",
      "file_name: CarLongPlateGen1681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1681.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 4.8ms preprocess, 130.0ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5906794\n",
      "recognized_text:  51F-695.45\n",
      "ocr_conf:  0.972\n",
      "411/1662\n",
      "file_name: CarLongPlateGen1690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1690.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 4.4ms preprocess, 130.0ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.505399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-216.70\n",
      "ocr_conf:  0.921\n",
      "412/1662\n",
      "file_name: CarLongPlateGen1691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1691.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.8ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.532001\n",
      "recognized_text:  51G-216.70\n",
      "ocr_conf:  0.956\n",
      "413/1662\n",
      "file_name: CarLongPlateGen170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen170.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 4.5ms preprocess, 130.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7163115\n",
      "recognized_text:  1A-897.14\n",
      "ocr_conf:  0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/1662\n",
      "file_name: CarLongPlateGen1700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1700.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.2ms preprocess, 126.3ms inference, 9.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0354068\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.964\n",
      "415/1662\n",
      "file_name: CarLongPlateGen1701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1701.jpg: 416x640 1 plate, 129.5ms\n",
      "Speed: 4.3ms preprocess, 129.5ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5165462\n",
      "recognized_text:  qV-3993\n",
      "ocr_conf:  0.812\n",
      "416/1662\n",
      "file_name: CarLongPlateGen171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen171.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.1587396\n",
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.749\n",
      "417/1662\n",
      "file_name: CarLongPlateGen1710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1710.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.643692\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1711.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 6.5ms preprocess, 123.9ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/1662\n",
      "file_name: CarLongPlateGen1711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4772956\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.943\n",
      "419/1662\n",
      "file_name: CarLongPlateGen1720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1720.jpg: 416x640 1 plate, 126.2ms\n",
      "Speed: 4.6ms preprocess, 126.2ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1245222\n",
      "recognized_text:  [61A-229.59]\n",
      "ocr_conf:  0.918\n",
      "420/1662\n",
      "file_name: CarLongPlateGen1721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1721.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.9ms preprocess, 123.6ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3239388\n",
      "recognized_text:  51G-102.09\n",
      "ocr_conf:  0.955\n",
      "421/1662\n",
      "file_name: CarLongPlateGen1730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1730.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3548794\n",
      "recognized_text:  51A-602.16\n",
      "ocr_conf:  0.956\n",
      "422/1662\n",
      "file_name: CarLongPlateGen1731.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1731.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.2ms preprocess, 124.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1780512\n",
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1740.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.8ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/1662\n",
      "file_name: CarLongPlateGen1740.jpg\n",
      "aspect_ratio: 3.5245883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1741.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.964\n",
      "424/1662\n",
      "file_name: CarLongPlateGen1741.jpg\n",
      "aspect_ratio: 3.0229526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1750.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1F-446.14\n",
      "ocr_conf:  0.835\n",
      "425/1662\n",
      "file_name: CarLongPlateGen1750.jpg\n",
      "aspect_ratio: 3.09797\n",
      "recognized_text:  61A-395.34\n",
      "ocr_conf:  0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1751.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.1ms preprocess, 123.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/1662\n",
      "file_name: CarLongPlateGen1751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1250422\n",
      "recognized_text:  61A-395.34\n",
      "ocr_conf:  0.965\n",
      "427/1662\n",
      "file_name: CarLongPlateGen1760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1760.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.963172\n",
      "recognized_text:  F-582.50\n",
      "ocr_conf:  0.877\n",
      "428/1662\n",
      "file_name: CarLongPlateGen1761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1761.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4918525\n",
      "recognized_text:  682.50\n",
      "ocr_conf:  0.883\n",
      "429/1662\n",
      "file_name: CarLongPlateGen1770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1770.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6046903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1771.jpg: 416x640 1 plate, 126.4ms\n",
      "Speed: 5.1ms preprocess, 126.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-519.36\n",
      "ocr_conf:  0.927\n",
      "430/1662\n",
      "file_name: CarLongPlateGen1771.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.603298\n",
      "recognized_text:  G-519.36\n",
      "ocr_conf:  0.952\n",
      "431/1662\n",
      "file_name: CarLongPlateGen1780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1780.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.803742\n",
      "recognized_text:  51G-491.60\n",
      "ocr_conf:  0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1781.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/1662\n",
      "file_name: CarLongPlateGen1781.jpg\n",
      "aspect_ratio: 3.6361616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1790.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.3ms preprocess, 125.6ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-207.54\n",
      "ocr_conf:  0.957\n",
      "433/1662\n",
      "file_name: CarLongPlateGen1790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1490827\n",
      "recognized_text:  51G-251.81\n",
      "ocr_conf:  0.843\n",
      "434/1662\n",
      "file_name: CarLongPlateGen1791.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1791.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.532712\n",
      "recognized_text:  51F-491.42\n",
      "ocr_conf:  0.968\n",
      "435/1662\n",
      "file_name: CarLongPlateGen180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen180.jpg: 416x640 1 plate, 126.9ms\n",
      "Speed: 4.2ms preprocess, 126.9ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4591794\n",
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.957\n",
      "436/1662\n",
      "file_name: CarLongPlateGen1800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1800.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.9ms preprocess, 124.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3724895\n",
      "recognized_text:  51G-011.77\n",
      "ocr_conf:  0.934\n",
      "437/1662\n",
      "file_name: CarLongPlateGen1801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1801.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1348388\n",
      "recognized_text:  G-011.77\n",
      "ocr_conf:  0.901\n",
      "438/1662\n",
      "file_name: CarLongPlateGen181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen181.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8722017\n",
      "recognized_text:  61F-155.8\n",
      "ocr_conf:  0.747\n",
      "439/1662\n",
      "file_name: CarLongPlateGen1810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1810.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7454922\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.964\n",
      "440/1662\n",
      "file_name: CarLongPlateGen1811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1811.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6578348\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.97\n",
      "441/1662\n",
      "file_name: CarLongPlateGen1820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1820.jpg: 416x640 1 plate, 129.2ms\n",
      "Speed: 6.9ms preprocess, 129.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.220602\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.969\n",
      "442/1662\n",
      "file_name: CarLongPlateGen1821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1821.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.6ms preprocess, 125.6ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3492172\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.962\n",
      "443/1662\n",
      "file_name: CarLongPlateGen1830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1830.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.042623\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.97\n",
      "444/1662\n",
      "file_name: CarLongPlateGen1831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1831.jpg: 416x640 1 plate, 127.2ms\n",
      "Speed: 4.5ms preprocess, 127.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3432126\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.94\n",
      "445/1662\n",
      "file_name: CarLongPlateGen1840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1840.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3955371\n",
      "recognized_text:  30E-000.90\n",
      "ocr_conf:  0.976\n",
      "446/1662\n",
      "file_name: CarLongPlateGen1841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1841.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 6.1ms preprocess, 125.8ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5631905\n",
      "recognized_text:  30E-000.90\n",
      "ocr_conf:  0.96\n",
      "447/1662\n",
      "file_name: CarLongPlateGen1850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1850.jpg: 416x640 1 plate, 127.6ms\n",
      "Speed: 4.7ms preprocess, 127.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5669544\n",
      "recognized_text:  51F-356.13\n",
      "ocr_conf:  0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/1662\n",
      "file_name: CarLongPlateGen1851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1851.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.4ms preprocess, 124.9ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7400382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1860.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.5ms preprocess, 121.9ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-72110\n",
      "ocr_conf:  0.966\n",
      "449/1662\n",
      "file_name: CarLongPlateGen1860.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5418487\n",
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.948\n",
      "450/1662\n",
      "file_name: CarLongPlateGen1861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1861.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.6ms preprocess, 125.8ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4231493\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/1662\n",
      "file_name: CarLongPlateGen1870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1870.jpg: 416x640 1 plate, 128.3ms\n",
      "Speed: 4.5ms preprocess, 128.3ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6204932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-048.77\n",
      "ocr_conf:  0.972\n",
      "452/1662\n",
      "file_name: CarLongPlateGen1871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1871.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.372303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-048.77\n",
      "ocr_conf:  0.963\n",
      "453/1662\n",
      "file_name: CarLongPlateGen1880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1880.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7187247\n",
      "recognized_text:  51F-212.55\n",
      "ocr_conf:  0.967\n",
      "454/1662\n",
      "file_name: CarLongPlateGen1881.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1881.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 5.2ms preprocess, 124.2ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5077708\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.96\n",
      "455/1662\n",
      "file_name: CarLongPlateGen1890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1890.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.4ms preprocess, 124.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5384128\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.956\n",
      "456/1662\n",
      "file_name: CarLongPlateGen1891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1891.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.0ms preprocess, 123.6ms inference, 11.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2891905\n",
      "recognized_text:  51G-481.54\n",
      "ocr_conf:  0.933\n",
      "457/1662\n",
      "file_name: CarLongPlateGen190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen190.jpg: 416x640 1 plate, 143.5ms\n",
      "Speed: 5.9ms preprocess, 143.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9975781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  A6\n",
      "ocr_conf:  0.367\n",
      "458/1662\n",
      "file_name: CarLongPlateGen1900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1900.jpg: 416x640 1 plate, 126.6ms\n",
      "Speed: 4.9ms preprocess, 126.6ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7458649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-21255\n",
      "ocr_conf:  0.974\n",
      "459/1662\n",
      "file_name: CarLongPlateGen1901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1901.jpg: 416x640 1 plate, 128.8ms\n",
      "Speed: 4.6ms preprocess, 128.8ms inference, 14.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2701209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-278.09\n",
      "ocr_conf:  0.975\n",
      "460/1662\n",
      "file_name: CarLongPlateGen191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen191.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.7ms preprocess, 124.4ms inference, 12.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.6262684\n",
      "recognized_text:  RIA73L82\n",
      "ocr_conf:  0.573\n",
      "461/1662\n",
      "file_name: CarLongPlateGen1910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1910.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6040335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60LD4379\n",
      "ocr_conf:  0.976\n",
      "462/1662\n",
      "file_name: CarLongPlateGen1911.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1911.jpg: 416x640 1 plate, 130.6ms\n",
      "Speed: 4.6ms preprocess, 130.6ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3575168\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.957\n",
      "463/1662\n",
      "file_name: CarLongPlateGen1920.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1920.jpg: 416x640 1 plate, 127.2ms\n",
      "Speed: 4.3ms preprocess, 127.2ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6529217\n",
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.92\n",
      "464/1662\n",
      "file_name: CarLongPlateGen1921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1921.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.5ms preprocess, 122.1ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8176196\n",
      "recognized_text:  93LD-001.03\n",
      "ocr_conf:  0.871\n",
      "465/1662\n",
      "file_name: CarLongPlateGen1930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1930.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 3.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7232625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.976\n",
      "466/1662\n",
      "file_name: CarLongPlateGen1931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1931.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.4ms preprocess, 125.8ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.735818\n",
      "recognized_text:  61F-079.73\n",
      "ocr_conf:  0.94\n",
      "467/1662\n",
      "file_name: CarLongPlateGen1940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1940.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1466951\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.932\n",
      "468/1662\n",
      "file_name: CarLongPlateGen1941.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1941.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6565437\n",
      "recognized_text:  61A-229.59\n",
      "ocr_conf:  0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/1662\n",
      "file_name: CarLongPlateGen1950.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1950.jpg: 416x640 1 plate, 127.1ms\n",
      "Speed: 4.6ms preprocess, 127.1ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4300718\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.942\n",
      "470/1662\n",
      "file_name: CarLongPlateGen1951.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1951.jpg: 416x640 1 plate, 127.6ms\n",
      "Speed: 5.0ms preprocess, 127.6ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5040507\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.961\n",
      "471/1662\n",
      "file_name: CarLongPlateGen1960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1960.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2905264\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.927\n",
      "472/1662\n",
      "file_name: CarLongPlateGen1961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1961.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 7.0ms preprocess, 122.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4738882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.961\n",
      "473/1662\n",
      "file_name: CarLongPlateGen1970.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1970.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.5ms preprocess, 124.9ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.381\n",
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.952\n",
      "474/1662\n",
      "file_name: CarLongPlateGen1971.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1971.jpg: 416x640 1 plate, 121.3ms\n",
      "Speed: 4.2ms preprocess, 121.3ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.423472\n",
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.978\n",
      "475/1662\n",
      "file_name: CarLongPlateGen1980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1980.jpg: 416x640 1 plate, 132.0ms\n",
      "Speed: 4.4ms preprocess, 132.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.428604\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.949\n",
      "476/1662\n",
      "file_name: CarLongPlateGen1981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1981.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.2ms preprocess, 124.2ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3529527\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.966\n",
      "477/1662\n",
      "file_name: CarLongPlateGen1990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1990.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 8.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.612676\n",
      "recognized_text:  STF-984.66\n",
      "ocr_conf:  0.868\n",
      "478/1662\n",
      "file_name: CarLongPlateGen1991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen1991.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5788927\n",
      "recognized_text:  51F-582.14\n",
      "ocr_conf:  0.963\n",
      "479/1662\n",
      "file_name: CarLongPlateGen20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen20.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8839672\n",
      "recognized_text:  48A-028.66\n",
      "ocr_conf:  0.924\n",
      "480/1662\n",
      "file_name: CarLongPlateGen200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen200.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.2ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9032636\n",
      "recognized_text:  M\n",
      "ocr_conf:  0.366\n",
      "481/1662\n",
      "file_name: CarLongPlateGen2000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2000.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.787264\n",
      "recognized_text:  51G-100.96\n",
      "ocr_conf:  0.959\n",
      "482/1662\n",
      "file_name: CarLongPlateGen2001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2001.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 7.0ms preprocess, 124.0ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.725264\n",
      "recognized_text:  51C-100.96\n",
      "ocr_conf:  0.901\n",
      "483/1662\n",
      "file_name: CarLongPlateGen201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen201.jpg: 416x640 1 plate, 127.4ms\n",
      "Speed: 4.4ms preprocess, 127.4ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6902502\n",
      "recognized_text:  SOL0D\n",
      "ocr_conf:  0.655\n",
      "484/1662\n",
      "file_name: CarLongPlateGen2010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2010.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 8.3ms preprocess, 123.7ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2331247\n",
      "recognized_text:  51G-495.24\n",
      "ocr_conf:  0.953\n",
      "485/1662\n",
      "file_name: CarLongPlateGen2011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2011.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.2ms preprocess, 125.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0104713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2020.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.962\n",
      "486/1662\n",
      "file_name: CarLongPlateGen2020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2713082\n",
      "recognized_text:  516-228.07\n",
      "ocr_conf:  0.956\n",
      "487/1662\n",
      "file_name: CarLongPlateGen2021.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2021.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.3ms preprocess, 121.9ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3960736\n",
      "recognized_text:  51G-495.39\n",
      "ocr_conf:  0.969\n",
      "488/1662\n",
      "file_name: CarLongPlateGen2030.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2030.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2305632\n",
      "recognized_text:  51A-648.26\n",
      "ocr_conf:  0.956\n",
      "489/1662\n",
      "file_name: CarLongPlateGen2031.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2031.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 4.6ms preprocess, 125.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8721097\n",
      "recognized_text:  51A-648.26\n",
      "ocr_conf:  0.931\n",
      "490/1662\n",
      "file_name: CarLongPlateGen2040.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2040.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2633314\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.918\n",
      "491/1662\n",
      "file_name: CarLongPlateGen2041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2041.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9972157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2050.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-795.12\n",
      "ocr_conf:  0.978\n",
      "492/1662\n",
      "file_name: CarLongPlateGen2050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.4382143\n",
      "recognized_text:  72120\n",
      "ocr_conf:  0.443\n",
      "493/1662\n",
      "file_name: CarLongPlateGen2051.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2051.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.2ms preprocess, 124.9ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6544893\n",
      "recognized_text:  51F-734.20\n",
      "ocr_conf:  0.969\n",
      "494/1662\n",
      "file_name: CarLongPlateGen2060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2060.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.873639\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.905\n",
      "495/1662\n",
      "file_name: CarLongPlateGen2061.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2061.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3588283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.953\n",
      "496/1662\n",
      "file_name: CarLongPlateGen2070.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2070.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2197886\n",
      "recognized_text:  56S-4698\n",
      "ocr_conf:  0.94\n",
      "497/1662\n",
      "file_name: CarLongPlateGen2071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2071.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.4ms preprocess, 124.6ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.346262\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.969\n",
      "498/1662\n",
      "file_name: CarLongPlateGen2080.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2080.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6574445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.971\n",
      "499/1662\n",
      "file_name: CarLongPlateGen2081.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2081.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.2ms preprocess, 124.2ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3299668\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.972\n",
      "500/1662\n",
      "file_name: CarLongPlateGen2090.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2090.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 5.0ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7278323\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.961\n",
      "501/1662\n",
      "file_name: CarLongPlateGen2091.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2091.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.9ms preprocess, 123.7ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7421424\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.962\n",
      "502/1662\n",
      "file_name: CarLongPlateGen21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen21.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.242557\n",
      "recognized_text:  ARA 0X6G\n",
      "ocr_conf:  0.491\n",
      "503/1662\n",
      "file_name: CarLongPlateGen210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen210.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.7ms preprocess, 122.2ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7492979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.902\n",
      "504/1662\n",
      "file_name: CarLongPlateGen2100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2100.jpg: 416x640 1 plate, 128.5ms\n",
      "Speed: 4.4ms preprocess, 128.5ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.779679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2101.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-590.10\n",
      "ocr_conf:  0.932\n",
      "505/1662\n",
      "file_name: CarLongPlateGen2101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.356113\n",
      "recognized_text:  51E-042.75\n",
      "ocr_conf:  0.878\n",
      "506/1662\n",
      "file_name: CarLongPlateGen211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen211.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.6ms preprocess, 124.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9578261\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.956\n",
      "507/1662\n",
      "file_name: CarLongPlateGen2110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2110.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 14.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8260033\n",
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.949\n",
      "508/1662\n",
      "file_name: CarLongPlateGen2111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2111.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.0912952\n",
      "recognized_text:  COLD011\n",
      "ocr_conf:  0.515\n",
      "509/1662\n",
      "file_name: CarLongPlateGen2120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2120.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0642824\n",
      "recognized_text:  51G-290.34\n",
      "ocr_conf:  0.968\n",
      "510/1662\n",
      "file_name: CarLongPlateGen2121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2121.jpg: 416x640 1 plate, 130.1ms\n",
      "Speed: 9.9ms preprocess, 130.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.760589\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2130.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/1662\n",
      "file_name: CarLongPlateGen2130.jpg\n",
      "aspect_ratio: 3.2132769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2131.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.971\n",
      "512/1662\n",
      "file_name: CarLongPlateGen2131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5528166\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.927\n",
      "513/1662\n",
      "file_name: CarLongPlateGen2140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2140.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0995417\n",
      "recognized_text:  56S-4698\n",
      "ocr_conf:  0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2141.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.8ms preprocess, 123.2ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/1662\n",
      "file_name: CarLongPlateGen2141.jpg\n",
      "aspect_ratio: 3.172076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2150.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.968\n",
      "515/1662\n",
      "file_name: CarLongPlateGen2150.jpg\n",
      "aspect_ratio: 3.1455986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2151.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-376.75\n",
      "ocr_conf:  0.941\n",
      "516/1662\n",
      "file_name: CarLongPlateGen2151.jpg\n",
      "aspect_ratio: 4.088462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2160.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-376.75\n",
      "ocr_conf:  0.949\n",
      "517/1662\n",
      "file_name: CarLongPlateGen2160.jpg\n",
      "aspect_ratio: 3.4441726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2161.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.948\n",
      "518/1662\n",
      "file_name: CarLongPlateGen2161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.197796\n",
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.95\n",
      "519/1662\n",
      "file_name: CarLongPlateGen2170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2170.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8184028\n",
      "recognized_text:  51F-324.88\n",
      "ocr_conf:  0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2171.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 6.5ms preprocess, 123.5ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/1662\n",
      "file_name: CarLongPlateGen2171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0245974\n",
      "recognized_text:  51F-324.88\n",
      "ocr_conf:  0.937\n",
      "521/1662\n",
      "file_name: CarLongPlateGen2180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2180.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3371866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2181.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 12.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.972\n",
      "522/1662\n",
      "file_name: CarLongPlateGen2181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8616726\n",
      "recognized_text:  51E65Jir-00532\n",
      "ocr_conf:  0.556\n",
      "523/1662\n",
      "file_name: CarLongPlateGen2190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2190.jpg: 416x640 1 plate, 132.4ms\n",
      "Speed: 4.6ms preprocess, 132.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5757682\n",
      "recognized_text:  50LD-044.17\n",
      "ocr_conf:  0.893\n",
      "524/1662\n",
      "file_name: CarLongPlateGen2191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2191.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 8.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7595623\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.958\n",
      "525/1662\n",
      "file_name: CarLongPlateGen220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen220.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.854187\n",
      "recognized_text:  61A05227\n",
      "ocr_conf:  0.879\n",
      "526/1662\n",
      "file_name: CarLongPlateGen2200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2200.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 14.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.921034\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.966\n",
      "527/1662\n",
      "file_name: CarLongPlateGen2201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2201.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 5.3ms preprocess, 123.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.459468\n",
      "recognized_text:  51G-251.81\n",
      "ocr_conf:  0.952\n",
      "528/1662\n",
      "file_name: CarLongPlateGen221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen221.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.5ms preprocess, 124.3ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.408227\n",
      "recognized_text:  51G-25181\n",
      "ocr_conf:  0.834\n",
      "529/1662\n",
      "file_name: CarLongPlateGen2210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2210.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.7ms preprocess, 123.5ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7899554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  0707351F-0/3.70\n",
      "ocr_conf:  0.782\n",
      "530/1662\n",
      "file_name: CarLongPlateGen2211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2211.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.6ms preprocess, 124.2ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5400048\n",
      "recognized_text:  F5.61712 517-01A12\n",
      "ocr_conf:  0.611\n",
      "531/1662\n",
      "file_name: CarLongPlateGen2220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2220.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.5ms preprocess, 124.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1578367\n",
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.964\n",
      "532/1662\n",
      "file_name: CarLongPlateGen2221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2221.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.3ms preprocess, 124.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3983037\n",
      "recognized_text:  60A-208.80\n",
      "ocr_conf:  0.975\n",
      "533/1662\n",
      "file_name: CarLongPlateGen2230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2230.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 7.8ms preprocess, 123.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8607628\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.957\n",
      "534/1662\n",
      "file_name: CarLongPlateGen2231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2231.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6391969\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.914\n",
      "535/1662\n",
      "file_name: CarLongPlateGen2240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2240.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9879308\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.964\n",
      "536/1662\n",
      "file_name: CarLongPlateGen2241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2241.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 3.9ms preprocess, 122.9ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8764527\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.953\n",
      "537/1662\n",
      "file_name: CarLongPlateGen2250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2250.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4404514\n",
      "recognized_text:  51F-574.93\n",
      "ocr_conf:  0.907\n",
      "538/1662\n",
      "file_name: CarLongPlateGen2251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2251.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6902485\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2260.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.8ms preprocess, 122.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539/1662\n",
      "file_name: CarLongPlateGen2260.jpg\n",
      "aspect_ratio: 3.1717696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2261.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.5ms preprocess, 122.8ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  48A-051.77\n",
      "ocr_conf:  0.915\n",
      "540/1662\n",
      "file_name: CarLongPlateGen2261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4086373\n",
      "recognized_text:  51C-495.39\n",
      "ocr_conf:  0.878\n",
      "541/1662\n",
      "file_name: CarLongPlateGen2270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2270.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.4ms preprocess, 124.5ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0535533\n",
      "recognized_text:  51G-473.40\n",
      "ocr_conf:  0.943\n",
      "542/1662\n",
      "file_name: CarLongPlateGen2271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2271.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.5070004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2280.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.9ms preprocess, 124.6ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-730.29\n",
      "ocr_conf:  0.926\n",
      "543/1662\n",
      "file_name: CarLongPlateGen2280.jpg\n",
      "aspect_ratio: 4.1129236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2281.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.9ms preprocess, 123.5ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60A-214.18\n",
      "ocr_conf:  0.975\n",
      "544/1662\n",
      "file_name: CarLongPlateGen2281.jpg\n",
      "aspect_ratio: 3.4605675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-220.29\n",
      "ocr_conf:  0.966\n",
      "545/1662\n",
      "file_name: CarLongPlateGen2290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2290.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2595994\n",
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.905\n",
      "546/1662\n",
      "file_name: CarLongPlateGen2291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2291.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.0ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1381538\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.925\n",
      "547/1662\n",
      "file_name: CarLongPlateGen230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen230.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.976183\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.929\n",
      "548/1662\n",
      "file_name: CarLongPlateGen2300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2300.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.8ms preprocess, 124.8ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.388862\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.974\n",
      "549/1662\n",
      "file_name: CarLongPlateGen2301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2301.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1547084\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.947\n",
      "550/1662\n",
      "file_name: CarLongPlateGen231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen231.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1205578\n",
      "recognized_text:  518-07973\n",
      "ocr_conf:  0.744\n",
      "551/1662\n",
      "file_name: CarLongPlateGen2310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2310.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.423687\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2311.jpg: 416x640 1 plate, 121.6ms\n",
      "Speed: 4.5ms preprocess, 121.6ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/1662\n",
      "file_name: CarLongPlateGen2311.jpg\n",
      "aspect_ratio: 2.6770768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2320.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.967\n",
      "553/1662\n",
      "file_name: CarLongPlateGen2320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.928395\n",
      "recognized_text:  50Z-1630\n",
      "ocr_conf:  0.931\n",
      "554/1662\n",
      "file_name: CarLongPlateGen2321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2321.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0324\n",
      "recognized_text:  50Z-1630\n",
      "ocr_conf:  0.915\n",
      "555/1662\n",
      "file_name: CarLongPlateGen2330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2330.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.667205\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.952\n",
      "556/1662\n",
      "file_name: CarLongPlateGen2331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2331.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.5ms preprocess, 124.5ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.206691\n",
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.976\n",
      "557/1662\n",
      "file_name: CarLongPlateGen2340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2340.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2893703\n",
      "recognized_text:  51F-574.93\n",
      "ocr_conf:  0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2341.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/1662\n",
      "file_name: CarLongPlateGen2341.jpg\n",
      "aspect_ratio: 2.1183052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2350.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71F-574.93\n",
      "ocr_conf:  0.921\n",
      "559/1662\n",
      "file_name: CarLongPlateGen2350.jpg\n",
      "aspect_ratio: 3.286269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2351.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-165.98\n",
      "ocr_conf:  0.937\n",
      "560/1662\n",
      "file_name: CarLongPlateGen2351.jpg\n",
      "aspect_ratio: 3.9834023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2360.jpg: 416x640 1 plate, 126.6ms\n",
      "Speed: 4.4ms preprocess, 126.6ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-165.98\n",
      "ocr_conf:  0.97\n",
      "561/1662\n",
      "file_name: CarLongPlateGen2360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2944086\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.956\n",
      "562/1662\n",
      "file_name: CarLongPlateGen2361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2361.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4813535\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.944\n",
      "563/1662\n",
      "file_name: CarLongPlateGen2370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2370.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.7ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3168266\n",
      "recognized_text:  60A-399.51\n",
      "ocr_conf:  0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564/1662\n",
      "file_name: CarLongPlateGen2371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2371.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3949277\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.975\n",
      "565/1662\n",
      "file_name: CarLongPlateGen2380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2380.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.7ms preprocess, 123.7ms inference, 11.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.75602\n",
      "recognized_text:  51F-220.29\n",
      "ocr_conf:  0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566/1662\n",
      "file_name: CarLongPlateGen2381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2381.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3336146\n",
      "recognized_text:  51A-052.27\n",
      "ocr_conf:  0.968\n",
      "567/1662\n",
      "file_name: CarLongPlateGen2390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2390.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.893318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2391.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-869.88\n",
      "ocr_conf:  0.903\n",
      "568/1662\n",
      "file_name: CarLongPlateGen2391.jpg\n",
      "aspect_ratio: 2.5823338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen240.jpg: 416x640 1 plate, 125.7ms\n",
      "Speed: 4.4ms preprocess, 125.7ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.971\n",
      "569/1662\n",
      "file_name: CarLongPlateGen240.jpg\n",
      "aspect_ratio: 3.2022443\n",
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2400.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/1662\n",
      "file_name: CarLongPlateGen2400.jpg\n",
      "aspect_ratio: 3.400769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2401.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.0ms preprocess, 123.4ms inference, 13.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.952\n",
      "571/1662\n",
      "file_name: CarLongPlateGen2401.jpg\n",
      "aspect_ratio: 3.412529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30V-3993\n",
      "ocr_conf:  0.98\n",
      "572/1662\n",
      "file_name: CarLongPlateGen241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen241.jpg: 416x640 1 plate, 128.7ms\n",
      "Speed: 4.5ms preprocess, 128.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.3611665\n",
      "recognized_text:  61F-161.69\n",
      "ocr_conf:  0.837\n",
      "573/1662\n",
      "file_name: CarLongPlateGen2410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2410.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.1ms preprocess, 123.3ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9681156\n",
      "recognized_text:  51A-724.44\n",
      "ocr_conf:  0.954\n",
      "574/1662\n",
      "file_name: CarLongPlateGen2411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2411.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7679267\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.958\n",
      "575/1662\n",
      "file_name: CarLongPlateGen2420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2420.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.9ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.774398\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.928\n",
      "576/1662\n",
      "file_name: CarLongPlateGen2421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2421.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.6ms preprocess, 124.8ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6989155\n",
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.977\n",
      "577/1662\n",
      "file_name: CarLongPlateGen2430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2430.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.5ms preprocess, 124.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.447033\n",
      "recognized_text:  51C-216.70\n",
      "ocr_conf:  0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/1662\n",
      "file_name: CarLongPlateGen2431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2431.jpg: 416x640 1 plate, 120.3ms\n",
      "Speed: 4.4ms preprocess, 120.3ms inference, 3.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9691024\n",
      "recognized_text:  51G-216.70\n",
      "ocr_conf:  0.907\n",
      "579/1662\n",
      "file_name: CarLongPlateGen2440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2440.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.9ms preprocess, 123.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3441688\n",
      "recognized_text:  51A.0120/51A012.04\n",
      "ocr_conf:  0.771\n",
      "580/1662\n",
      "file_name: CarLongPlateGen2441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2441.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.6ms preprocess, 124.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5334353\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.955\n",
      "581/1662\n",
      "file_name: CarLongPlateGen2450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2450.jpg: 416x640 1 plate, 126.2ms\n",
      "Speed: 4.6ms preprocess, 126.2ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9522934\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.963\n",
      "582/1662\n",
      "file_name: CarLongPlateGen2451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2451.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.550224\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.968\n",
      "583/1662\n",
      "file_name: CarLongPlateGen2460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2460.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 5.2ms preprocess, 122.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5274324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  [61A-229.59]\n",
      "ocr_conf:  0.885\n",
      "584/1662\n",
      "file_name: CarLongPlateGen2461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2461.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5717556\n",
      "recognized_text:  51G-102.09\n",
      "ocr_conf:  0.946\n",
      "585/1662\n",
      "file_name: CarLongPlateGen2470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2470.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.1ms preprocess, 123.2ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.304409\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2471.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.9ms preprocess, 123.5ms inference, 8.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/1662\n",
      "file_name: CarLongPlateGen2471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.065468\n",
      "recognized_text:  1C51008\n",
      "ocr_conf:  0.825\n",
      "587/1662\n",
      "file_name: CarLongPlateGen2480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2480.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 6.3ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5335875\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.968\n",
      "588/1662\n",
      "file_name: CarLongPlateGen2481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2481.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.8ms preprocess, 122.8ms inference, 14.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2057867\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2490.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.5ms preprocess, 123.2ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589/1662\n",
      "file_name: CarLongPlateGen2490.jpg\n",
      "aspect_ratio: 3.5575562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1F-590.11\n",
      "ocr_conf:  0.938\n",
      "590/1662\n",
      "file_name: CarLongPlateGen2491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2491.jpg: 416x640 1 plate, 126.5ms\n",
      "Speed: 4.5ms preprocess, 126.5ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5794451\n",
      "recognized_text:  51F-042.75\n",
      "ocr_conf:  0.945\n",
      "591/1662\n",
      "file_name: CarLongPlateGen250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen250.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8451955\n",
      "recognized_text:  60A-03060\n",
      "ocr_conf:  0.774\n",
      "592/1662\n",
      "file_name: CarLongPlateGen2500.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2500.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 6.9ms preprocess, 123.5ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.717165\n",
      "recognized_text:  62A-055.16\n",
      "ocr_conf:  0.969\n",
      "593/1662\n",
      "file_name: CarLongPlateGen2501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2501.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 4.6ms preprocess, 125.5ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1923716\n",
      "recognized_text:  S1G-216.70\n",
      "ocr_conf:  0.858\n",
      "594/1662\n",
      "file_name: CarLongPlateGen251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen251.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 13.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.303242\n",
      "recognized_text:  51A721.10\n",
      "ocr_conf:  0.923\n",
      "595/1662\n",
      "file_name: CarLongPlateGen2510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2510.jpg: 416x640 1 plate, 132.7ms\n",
      "Speed: 4.6ms preprocess, 132.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8686786\n",
      "recognized_text:  51F311.18\n",
      "ocr_conf:  0.927\n",
      "596/1662\n",
      "file_name: CarLongPlateGen2511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2511.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8659065\n",
      "recognized_text:  51G-25481\n",
      "ocr_conf:  0.9\n",
      "597/1662\n",
      "file_name: CarLongPlateGen2520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2520.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.570343\n",
      "recognized_text:  51F-646.19\n",
      "ocr_conf:  0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2521.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.7ms preprocess, 123.5ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/1662\n",
      "file_name: CarLongPlateGen2521.jpg\n",
      "aspect_ratio: 3.0583825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2530.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 7.4ms preprocess, 122.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  G-472.81\n",
      "ocr_conf:  0.885\n",
      "599/1662\n",
      "file_name: CarLongPlateGen2530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.038353\n",
      "recognized_text:  516-394.66\n",
      "ocr_conf:  0.876\n",
      "600/1662\n",
      "file_name: CarLongPlateGen2531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2531.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3010647\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.931\n",
      "601/1662\n",
      "file_name: CarLongPlateGen2540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2540.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 9.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9815116\n",
      "recognized_text:  5F-882.70\n",
      "ocr_conf:  0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2541.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 5.0ms preprocess, 123.9ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602/1662\n",
      "file_name: CarLongPlateGen2541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5174553\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.956\n",
      "603/1662\n",
      "file_name: CarLongPlateGen2550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2550.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7024026\n",
      "recognized_text:  51G-216.70\n",
      "ocr_conf:  0.948\n",
      "604/1662\n",
      "file_name: CarLongPlateGen2551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2551.jpg: 416x640 1 plate, 127.7ms\n",
      "Speed: 4.3ms preprocess, 127.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1947877\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.961\n",
      "605/1662\n",
      "file_name: CarLongPlateGen2560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2560.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0997615\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.892\n",
      "606/1662\n",
      "file_name: CarLongPlateGen2561.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2561.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 5.3ms preprocess, 122.3ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9077907\n",
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.956\n",
      "607/1662\n",
      "file_name: CarLongPlateGen2570.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2570.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.9ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8777547\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.946\n",
      "608/1662\n",
      "file_name: CarLongPlateGen2571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2571.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 13.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1551602\n",
      "recognized_text:  51A-602.16\n",
      "ocr_conf:  0.975\n",
      "609/1662\n",
      "file_name: CarLongPlateGen2580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2580.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2626884\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.964\n",
      "610/1662\n",
      "file_name: CarLongPlateGen2581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2581.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 5.1ms preprocess, 123.9ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2995098\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.908\n",
      "611/1662\n",
      "file_name: CarLongPlateGen2590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2590.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 8.6ms preprocess, 124.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.463283\n",
      "recognized_text:  516-510.08\n",
      "ocr_conf:  0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2591.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.8ms preprocess, 123.3ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/1662\n",
      "file_name: CarLongPlateGen2591.jpg\n",
      "aspect_ratio: 1.9064955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen260.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  GN0666156N-0000\n",
      "ocr_conf:  0.791\n",
      "613/1662\n",
      "file_name: CarLongPlateGen260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.058828\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "614/1662\n",
      "file_name: CarLongPlateGen2600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2600.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2352498\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.931\n",
      "615/1662\n",
      "file_name: CarLongPlateGen2601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2601.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4643226\n",
      "recognized_text:  51C-031.83\n",
      "ocr_conf:  0.953\n",
      "616/1662\n",
      "file_name: CarLongPlateGen261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen261.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.7ms preprocess, 123.5ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3888252\n",
      "recognized_text:  50Z-1630\n",
      "ocr_conf:  0.928\n",
      "617/1662\n",
      "file_name: CarLongPlateGen2610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2610.jpg: 416x640 1 plate, 133.3ms\n",
      "Speed: 4.3ms preprocess, 133.3ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5903032\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.952\n",
      "618/1662\n",
      "file_name: CarLongPlateGen2611.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2611.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.950993\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.914\n",
      "619/1662\n",
      "file_name: CarLongPlateGen2620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2620.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.6ms preprocess, 124.2ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1066802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2621.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-720.78\n",
      "ocr_conf:  0.951\n",
      "620/1662\n",
      "file_name: CarLongPlateGen2621.jpg\n",
      "aspect_ratio: 2.4716747\n",
      "recognized_text:  51F-695.45\n",
      "ocr_conf:  0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2630.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621/1662\n",
      "file_name: CarLongPlateGen2630.jpg\n",
      "aspect_ratio: 2.5576448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2631.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 6.4ms preprocess, 123.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-216.70\n",
      "ocr_conf:  0.928\n",
      "622/1662\n",
      "file_name: CarLongPlateGen2631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1853845\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.917\n",
      "623/1662\n",
      "file_name: CarLongPlateGen2640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2640.jpg: 416x640 1 plate, 133.0ms\n",
      "Speed: 5.5ms preprocess, 133.0ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2992058\n",
      "recognized_text:  qV-3993\n",
      "ocr_conf:  0.839\n",
      "624/1662\n",
      "file_name: CarLongPlateGen2641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2641.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.5ms preprocess, 124.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0034146\n",
      "recognized_text:  51G-394.66\n",
      "ocr_conf:  0.898\n",
      "625/1662\n",
      "file_name: CarLongPlateGen2650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2650.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.9ms preprocess, 123.9ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8123534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.95\n",
      "626/1662\n",
      "file_name: CarLongPlateGen2651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2651.jpg: 416x640 1 plate, 131.3ms\n",
      "Speed: 4.4ms preprocess, 131.3ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8771757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  c751F030.34\n",
      "ocr_conf:  0.781\n",
      "627/1662\n",
      "file_name: CarLongPlateGen2660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2660.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0749555\n",
      "recognized_text:  510-100.39\n",
      "ocr_conf:  0.911\n",
      "628/1662\n",
      "file_name: CarLongPlateGen2661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2661.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.1ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1484919\n",
      "recognized_text:  51D-100.39\n",
      "ocr_conf:  0.945\n",
      "629/1662\n",
      "file_name: CarLongPlateGen2670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2670.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 15.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.766704\n",
      "recognized_text:  29A-517.96\n",
      "ocr_conf:  0.967\n",
      "630/1662\n",
      "file_name: CarLongPlateGen2671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2671.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.7ms preprocess, 122.7ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7861366\n",
      "recognized_text:  29A-517.96\n",
      "ocr_conf:  0.965\n",
      "631/1662\n",
      "file_name: CarLongPlateGen2680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2680.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.6ms preprocess, 124.5ms inference, 8.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9783638\n",
      "recognized_text:  62A-051.95\n",
      "ocr_conf:  0.969\n",
      "632/1662\n",
      "file_name: CarLongPlateGen2681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2681.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7745762\n",
      "recognized_text:  62A051.95\n",
      "ocr_conf:  0.944\n",
      "633/1662\n",
      "file_name: CarLongPlateGen2690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2690.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.8ms preprocess, 123.7ms inference, 15.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1880004\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.958\n",
      "634/1662\n",
      "file_name: CarLongPlateGen2691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2691.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.872974\n",
      "recognized_text:  60A-359.811\n",
      "ocr_conf:  0.927\n",
      "635/1662\n",
      "file_name: CarLongPlateGen270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen270.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 8.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9514368\n",
      "recognized_text:  51F-07568\n",
      "ocr_conf:  0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2700.jpg: 416x640 1 plate, 126.9ms\n",
      "Speed: 4.6ms preprocess, 126.9ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/1662\n",
      "file_name: CarLongPlateGen2700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.130516\n",
      "recognized_text:  51F-026.87\n",
      "ocr_conf:  0.963\n",
      "637/1662\n",
      "file_name: CarLongPlateGen2701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2701.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 15.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9671485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  61F-026.87\n",
      "ocr_conf:  0.886\n",
      "638/1662\n",
      "file_name: CarLongPlateGen271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen271.jpg: 416x640 1 plate, 129.4ms\n",
      "Speed: 6.2ms preprocess, 129.4ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.544106\n",
      "recognized_text:  514-90905\n",
      "ocr_conf:  0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/1662\n",
      "file_name: CarLongPlateGen2710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2710.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8790731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  5G-491.60\n",
      "ocr_conf:  0.917\n",
      "640/1662\n",
      "file_name: CarLongPlateGen2711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2711.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 13.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8103414\n",
      "recognized_text:  51F-207.54\n",
      "ocr_conf:  0.963\n",
      "641/1662\n",
      "file_name: CarLongPlateGen2720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2720.jpg: 416x640 1 plate, 127.4ms\n",
      "Speed: 4.5ms preprocess, 127.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6027182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2721.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.9ms preprocess, 122.8ms inference, 8.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1025101516-251.07\n",
      "ocr_conf:  0.782\n",
      "642/1662\n",
      "file_name: CarLongPlateGen2721.jpg\n",
      "aspect_ratio: 3.0412261\n",
      "recognized_text:  51F-491.42\n",
      "ocr_conf:  0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/1662\n",
      "file_name: CarLongPlateGen2730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2730.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.6ms preprocess, 125.8ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2891312\n",
      "recognized_text:  51G-011.77\n",
      "ocr_conf:  0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2731.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 9.8ms preprocess, 124.9ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/1662\n",
      "file_name: CarLongPlateGen2731.jpg\n",
      "aspect_ratio: 3.3455667\n",
      "recognized_text:  G-011.77\n",
      "ocr_conf:  0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/1662\n",
      "file_name: CarLongPlateGen2740.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2740.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.6ms preprocess, 124.0ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.676144\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2741.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.5ms preprocess, 124.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646/1662\n",
      "file_name: CarLongPlateGen2741.jpg\n",
      "aspect_ratio: 3.366165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2750.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60LD-005.84\n",
      "ocr_conf:  0.937\n",
      "647/1662\n",
      "file_name: CarLongPlateGen2750.jpg\n",
      "aspect_ratio: 4.5627813\n",
      "recognized_text:  1051008\n",
      "ocr_conf:  0.921\n",
      "648/1662\n",
      "file_name: CarLongPlateGen2751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2751.jpg: 416x640 1 plate, 127.1ms\n",
      "Speed: 4.5ms preprocess, 127.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4648225\n",
      "recognized_text:  51G-510.08\n",
      "ocr_conf:  0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2760.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 11.9ms preprocess, 123.3ms inference, 16.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649/1662\n",
      "file_name: CarLongPlateGen2760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6942391\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.973\n",
      "650/1662\n",
      "file_name: CarLongPlateGen2761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2761.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6466372\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.958\n",
      "651/1662\n",
      "file_name: CarLongPlateGen2770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2770.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2248255\n",
      "recognized_text:  F16017251A-091.79\n",
      "ocr_conf:  0.694\n",
      "652/1662\n",
      "file_name: CarLongPlateGen2771.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2771.jpg: 416x640 1 plate, 131.8ms\n",
      "Speed: 4.6ms preprocess, 131.8ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8058538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2780.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 11.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.976\n",
      "653/1662\n",
      "file_name: CarLongPlateGen2780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4392917\n",
      "recognized_text:  51F-244.03\n",
      "ocr_conf:  0.98\n",
      "654/1662\n",
      "file_name: CarLongPlateGen2781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2781.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.147502\n",
      "recognized_text:  51F-753.26\n",
      "ocr_conf:  0.952\n",
      "655/1662\n",
      "file_name: CarLongPlateGen2790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2790.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1635811\n",
      "recognized_text:  516-513.32\n",
      "ocr_conf:  0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2791.jpg: 416x640 1 plate, 132.9ms\n",
      "Speed: 4.4ms preprocess, 132.9ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/1662\n",
      "file_name: CarLongPlateGen2791.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5134525\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.975\n",
      "657/1662\n",
      "file_name: CarLongPlateGen280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen280.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.9ms preprocess, 122.5ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8826933\n",
      "recognized_text:  HEA978S7\n",
      "ocr_conf:  0.441\n",
      "658/1662\n",
      "file_name: CarLongPlateGen2800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2800.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5500717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2801.jpg: 416x640 1 plate, 125.9ms\n",
      "Speed: 4.5ms preprocess, 125.9ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-212.55\n",
      "ocr_conf:  0.96\n",
      "659/1662\n",
      "file_name: CarLongPlateGen2801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.1992025\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.975\n",
      "660/1662\n",
      "file_name: CarLongPlateGen281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen281.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.4837813\n",
      "recognized_text:  61F-747.76\n",
      "ocr_conf:  0.881\n",
      "661/1662\n",
      "file_name: CarLongPlateGen2810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2810.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.6ms preprocess, 124.2ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4153264\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.946\n",
      "662/1662\n",
      "file_name: CarLongPlateGen2811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2811.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0509348\n",
      "recognized_text:  51G-481.54\n",
      "ocr_conf:  0.929\n",
      "663/1662\n",
      "file_name: CarLongPlateGen2820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2820.jpg: 416x640 1 plate, 128.5ms\n",
      "Speed: 4.4ms preprocess, 128.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.428281\n",
      "recognized_text:  51G-205.36\n",
      "ocr_conf:  0.973\n",
      "664/1662\n",
      "file_name: CarLongPlateGen2821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2821.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.8ms preprocess, 123.9ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.255119\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.931\n",
      "665/1662\n",
      "file_name: CarLongPlateGen2830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2830.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5992465\n",
      "recognized_text:  29A-517.96\n",
      "ocr_conf:  0.932\n",
      "666/1662\n",
      "file_name: CarLongPlateGen2831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2831.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3094895\n",
      "recognized_text:  29A-517.96\n",
      "ocr_conf:  0.973\n",
      "667/1662\n",
      "file_name: CarLongPlateGen2840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2840.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 13.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.601833\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.897\n",
      "668/1662\n",
      "file_name: CarLongPlateGen2841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2841.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.850537\n",
      "recognized_text:  C10120451A-012.04\n",
      "ocr_conf:  0.823\n",
      "669/1662\n",
      "file_name: CarLongPlateGen2850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2850.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.418909\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2851.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/1662\n",
      "file_name: CarLongPlateGen2851.jpg\n",
      "aspect_ratio: 3.3426285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2860.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.9ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.975\n",
      "671/1662\n",
      "file_name: CarLongPlateGen2860.jpg\n",
      "aspect_ratio: 3.7956119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2861.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.954\n",
      "672/1662\n",
      "file_name: CarLongPlateGen2861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9472198\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.933\n",
      "673/1662\n",
      "file_name: CarLongPlateGen2870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2870.jpg: 416x640 1 plate, 131.3ms\n",
      "Speed: 4.2ms preprocess, 131.3ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.159136\n",
      "recognized_text:  G-513.32\n",
      "ocr_conf:  0.839\n",
      "674/1662\n",
      "file_name: CarLongPlateGen2871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2871.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.4ms preprocess, 121.9ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8749044\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.886\n",
      "675/1662\n",
      "file_name: CarLongPlateGen2880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2880.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8495595\n",
      "recognized_text:  ..066.42\n",
      "ocr_conf:  0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2881.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.8ms preprocess, 123.3ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/1662\n",
      "file_name: CarLongPlateGen2881.jpg\n",
      "aspect_ratio: 3.6684413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2890.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.929\n",
      "677/1662\n",
      "file_name: CarLongPlateGen2890.jpg\n",
      "aspect_ratio: 2.7828114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2891.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.8ms preprocess, 123.6ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.924\n",
      "678/1662\n",
      "file_name: CarLongPlateGen2891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3610303\n",
      "recognized_text:  51F-132.51\n",
      "ocr_conf:  0.947\n",
      "679/1662\n",
      "file_name: CarLongPlateGen290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen290.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 13.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.273742\n",
      "recognized_text:  F1F-311.18\n",
      "ocr_conf:  0.728\n",
      "680/1662\n",
      "file_name: CarLongPlateGen2900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2900.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.583414\n",
      "recognized_text:  50Z-0618\n",
      "ocr_conf:  0.941\n",
      "681/1662\n",
      "file_name: CarLongPlateGen2901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2901.jpg: 416x640 1 plate, 129.8ms\n",
      "Speed: 4.4ms preprocess, 129.8ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1318254\n",
      "recognized_text:  50Z-0618\n",
      "ocr_conf:  0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/1662\n",
      "file_name: CarLongPlateGen291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen291.jpg: 416x640 1 plate, 127.7ms\n",
      "Speed: 4.8ms preprocess, 127.7ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7938569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51837307\n",
      "ocr_conf:  0.799\n",
      "683/1662\n",
      "file_name: CarLongPlateGen2910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2910.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0705893\n",
      "recognized_text:  51G-519.36\n",
      "ocr_conf:  0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2911.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.7ms preprocess, 123.6ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/1662\n",
      "file_name: CarLongPlateGen2911.jpg\n",
      "aspect_ratio: 1.2492071\n",
      "recognized_text:  6.82651A0\n",
      "ocr_conf:  0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/1662\n",
      "file_name: CarLongPlateGen2920.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2920.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0587835\n",
      "recognized_text:  29A-517.96\n",
      "ocr_conf:  0.973\n",
      "686/1662\n",
      "file_name: CarLongPlateGen2921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2921.jpg: 416x640 1 plate, 128.0ms\n",
      "Speed: 4.5ms preprocess, 128.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4620956\n",
      "recognized_text:  7.96.29A-51\n",
      "ocr_conf:  0.83\n",
      "687/1662\n",
      "file_name: CarLongPlateGen2930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2930.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7228192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1865043A-10\n",
      "ocr_conf:  0.862\n",
      "688/1662\n",
      "file_name: CarLongPlateGen2931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2931.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.3ms preprocess, 125.8ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1719158\n",
      "recognized_text:  43A-186.50\n",
      "ocr_conf:  0.877\n",
      "689/1662\n",
      "file_name: CarLongPlateGen2940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2940.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3363883\n",
      "recognized_text:  51F-869.88\n",
      "ocr_conf:  0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/1662\n",
      "file_name: CarLongPlateGen2941.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2941.jpg: 416x640 1 plate, 120.7ms\n",
      "Speed: 4.4ms preprocess, 120.7ms inference, 13.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8458536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2950.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51E869.88\n",
      "ocr_conf:  0.865\n",
      "691/1662\n",
      "file_name: CarLongPlateGen2950.jpg\n",
      "aspect_ratio: 1.8470614\n",
      "recognized_text:  51F78995.12\n",
      "ocr_conf:  0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2951.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 5.3ms preprocess, 122.4ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/1662\n",
      "file_name: CarLongPlateGen2951.jpg\n",
      "aspect_ratio: 2.0443845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-795.12\n",
      "ocr_conf:  0.885\n",
      "693/1662\n",
      "file_name: CarLongPlateGen2960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2960.jpg: 416x640 1 plate, 126.7ms\n",
      "Speed: 4.4ms preprocess, 126.7ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4416301\n",
      "recognized_text:  51F-734.20\n",
      "ocr_conf:  0.967\n",
      "694/1662\n",
      "file_name: CarLongPlateGen2961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2961.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.5ms preprocess, 125.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4454807\n",
      "recognized_text:  6342051F70\n",
      "ocr_conf:  0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2970.jpg: 416x640 1 plate, 125.6ms\n",
      "Speed: 4.8ms preprocess, 125.6ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695/1662\n",
      "file_name: CarLongPlateGen2970.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1105185\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.909\n",
      "696/1662\n",
      "file_name: CarLongPlateGen2971.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2971.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.6ms preprocess, 125.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0001476\n",
      "recognized_text:  514-012.04\n",
      "ocr_conf:  0.909\n",
      "697/1662\n",
      "file_name: CarLongPlateGen2980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2980.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.9ms preprocess, 124.5ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5421724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2981.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.2ms preprocess, 123.6ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  517748A-03\n",
      "ocr_conf:  0.845\n",
      "698/1662\n",
      "file_name: CarLongPlateGen2981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0935712\n",
      "recognized_text:  51F-76354\n",
      "ocr_conf:  0.866\n",
      "699/1662\n",
      "file_name: CarLongPlateGen2990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2990.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4878352\n",
      "recognized_text:  61.5951F-10\n",
      "ocr_conf:  0.858\n",
      "700/1662\n",
      "file_name: CarLongPlateGen2991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen2991.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.6ms preprocess, 122.7ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6525297\n",
      "recognized_text:  51F-161.59\n",
      "ocr_conf:  0.965\n",
      "701/1662\n",
      "file_name: CarLongPlateGen30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen30.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.4ms preprocess, 124.6ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.3745193\n",
      "recognized_text:  M.006546\n",
      "ocr_conf:  0.649\n",
      "702/1662\n",
      "file_name: CarLongPlateGen300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen300.jpg: 416x640 1 plate, 130.3ms\n",
      "Speed: 4.6ms preprocess, 130.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.6197734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60A-399.51\n",
      "ocr_conf:  0.959\n",
      "703/1662\n",
      "file_name: CarLongPlateGen3000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3000.jpg: 416x640 1 plate, 131.2ms\n",
      "Speed: 4.3ms preprocess, 131.2ms inference, 14.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.281888\n",
      "recognized_text:  40351F-2\n",
      "ocr_conf:  0.72\n",
      "704/1662\n",
      "file_name: CarLongPlateGen3001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3001.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4673955\n",
      "recognized_text:  51F-244.03)\n",
      "ocr_conf:  0.848\n",
      "705/1662\n",
      "file_name: CarLongPlateGen301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen301.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.264274\n",
      "recognized_text:  51F-065.32\n",
      "ocr_conf:  0.944\n",
      "706/1662\n",
      "file_name: CarLongPlateGen3010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3010.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3846583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  55.8551-3\n",
      "ocr_conf:  0.796\n",
      "707/1662\n",
      "file_name: CarLongPlateGen3011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3011.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.9ms preprocess, 124.1ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2947503\n",
      "recognized_text:  155.8551F-73\n",
      "ocr_conf:  0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3020.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 11.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708/1662\n",
      "file_name: CarLongPlateGen3020.jpg\n",
      "aspect_ratio: 1.7959584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-33324.88\n",
      "ocr_conf:  0.801\n",
      "709/1662\n",
      "file_name: CarLongPlateGen3021.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3021.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.7ms preprocess, 124.3ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.541628\n",
      "recognized_text:  024.8851F-34\n",
      "ocr_conf:  0.744\n",
      "710/1662\n",
      "file_name: CarLongPlateGen3030.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3030.jpg: 416x640 1 plate, 125.3ms\n",
      "Speed: 4.9ms preprocess, 125.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.524914\n",
      "recognized_text:  4.1150L0-0BE\n",
      "ocr_conf:  0.688\n",
      "711/1662\n",
      "file_name: CarLongPlateGen3031.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3031.jpg: 416x640 1 plate, 125.3ms\n",
      "Speed: 4.2ms preprocess, 125.3ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.051159\n",
      "recognized_text:  50LD-064.37\n",
      "ocr_conf:  0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/1662\n",
      "file_name: CarLongPlateGen3040.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3040.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9427056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3041.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  514.050052.27\n",
      "ocr_conf:  0.793\n",
      "713/1662\n",
      "file_name: CarLongPlateGen3041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.86313\n",
      "recognized_text:  514.05505227\n",
      "ocr_conf:  0.745\n",
      "714/1662\n",
      "file_name: CarLongPlateGen3050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3050.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.9ms preprocess, 122.8ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4534237\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.962\n",
      "715/1662\n",
      "file_name: CarLongPlateGen3051.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3051.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 5.2ms preprocess, 124.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5245789\n",
      "recognized_text:  617.1251F-00\n",
      "ocr_conf:  0.822\n",
      "716/1662\n",
      "file_name: CarLongPlateGen3060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3060.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.8ms preprocess, 123.9ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7822726\n",
      "recognized_text:  4698565\n",
      "ocr_conf:  0.868\n",
      "717/1662\n",
      "file_name: CarLongPlateGen3061.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3061.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 15.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4774804\n",
      "recognized_text:  56S-4698\n",
      "ocr_conf:  0.964\n",
      "718/1662\n",
      "file_name: CarLongPlateGen3070.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3070.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8702184\n",
      "recognized_text:  [61A.32029.59\n",
      "ocr_conf:  0.704\n",
      "719/1662\n",
      "file_name: CarLongPlateGen3071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3071.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4540968\n",
      "recognized_text:  02959(61A-2E\n",
      "ocr_conf:  0.803\n",
      "720/1662\n",
      "file_name: CarLongPlateGen3080.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3080.jpg: 416x640 1 plate, 129.7ms\n",
      "Speed: 4.2ms preprocess, 129.7ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4419968\n",
      "recognized_text:  51G-316.91\n",
      "ocr_conf:  0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3081.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/1662\n",
      "file_name: CarLongPlateGen3081.jpg\n",
      "aspect_ratio: 1.8700212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3090.jpg: 416x640 1 plate, 127.7ms\n",
      "Speed: 4.4ms preprocess, 127.7ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516.310316.91\n",
      "ocr_conf:  0.866\n",
      "722/1662\n",
      "file_name: CarLongPlateGen3090.jpg\n",
      "aspect_ratio: 1.8385992\n",
      "recognized_text:  604.3359.81\n",
      "ocr_conf:  0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723/1662\n",
      "file_name: CarLongPlateGen3091.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3091.jpg: 416x640 1 plate, 191.3ms\n",
      "Speed: 4.5ms preprocess, 191.3ms inference, 15.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6239766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59.81-60A-30\n",
      "ocr_conf:  0.768\n",
      "724/1662\n",
      "file_name: CarLongPlateGen31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen31.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.7ms preprocess, 126.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8852785\n",
      "recognized_text:  51F-89357\n",
      "ocr_conf:  0.96\n",
      "725/1662\n",
      "file_name: CarLongPlateGen310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen310.jpg: 416x640 1 plate, 132.6ms\n",
      "Speed: 4.3ms preprocess, 132.6ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0897624\n",
      "recognized_text:  GUL21KT8\n",
      "ocr_conf:  0.423\n",
      "726/1662\n",
      "file_name: CarLongPlateGen3100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3100.jpg: 416x640 1 plate, 128.4ms\n",
      "Speed: 4.4ms preprocess, 128.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.28973\n",
      "recognized_text:  51F-207.54\n",
      "ocr_conf:  0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/1662\n",
      "file_name: CarLongPlateGen3101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3101.jpg: 416x640 1 plate, 130.5ms\n",
      "Speed: 4.6ms preprocess, 130.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6420332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-2007.54\n",
      "ocr_conf:  0.775\n",
      "728/1662\n",
      "file_name: CarLongPlateGen311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen311.jpg: 416x640 1 plate, 130.3ms\n",
      "Speed: 7.0ms preprocess, 130.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4064367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-22029\n",
      "ocr_conf:  0.907\n",
      "729/1662\n",
      "file_name: CarLongPlateGen3110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3110.jpg: 416x640 1 plate, 127.5ms\n",
      "Speed: 4.5ms preprocess, 127.5ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.965853\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.961\n",
      "730/1662\n",
      "file_name: CarLongPlateGen3111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3111.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.657059\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.934\n",
      "731/1662\n",
      "file_name: CarLongPlateGen3120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3120.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5720491\n",
      "recognized_text:  51A.715.29\n",
      "ocr_conf:  0.777\n",
      "732/1662\n",
      "file_name: CarLongPlateGen3121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3121.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9258507\n",
      "recognized_text:  5168-290.34\n",
      "ocr_conf:  0.808\n",
      "733/1662\n",
      "file_name: CarLongPlateGen3130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3130.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5265453\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.893\n",
      "734/1662\n",
      "file_name: CarLongPlateGen3131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3131.jpg: 416x640 1 plate, 126.8ms\n",
      "Speed: 4.2ms preprocess, 126.8ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8747356\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.973\n",
      "735/1662\n",
      "file_name: CarLongPlateGen3140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3140.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.9ms preprocess, 123.8ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0639365\n",
      "recognized_text:  516-373.07\n",
      "ocr_conf:  0.926\n",
      "736/1662\n",
      "file_name: CarLongPlateGen3141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3141.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9090652\n",
      "recognized_text:  516-373.07\n",
      "ocr_conf:  0.965\n",
      "737/1662\n",
      "file_name: CarLongPlateGen3150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3150.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5643705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-80097.14\n",
      "ocr_conf:  0.82\n",
      "738/1662\n",
      "file_name: CarLongPlateGen3151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3151.jpg: 416x640 1 plate, 125.3ms\n",
      "Speed: 4.7ms preprocess, 125.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0742552\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3160.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.7ms preprocess, 124.5ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739/1662\n",
      "file_name: CarLongPlateGen3160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0965948\n",
      "recognized_text:  51F-46.14\n",
      "ocr_conf:  0.9\n",
      "740/1662\n",
      "file_name: CarLongPlateGen3161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3161.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 10.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8398035\n",
      "recognized_text:  61F-446.14\n",
      "ocr_conf:  0.895\n",
      "741/1662\n",
      "file_name: CarLongPlateGen3170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3170.jpg: 416x640 1 plate, 126.7ms\n",
      "Speed: 4.4ms preprocess, 126.7ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2412179\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.942\n",
      "742/1662\n",
      "file_name: CarLongPlateGen3171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3171.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5459825\n",
      "recognized_text:  51F.046.65\n",
      "ocr_conf:  0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743/1662\n",
      "file_name: CarLongPlateGen3180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3180.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1964753\n",
      "recognized_text:  51F-574.93\n",
      "ocr_conf:  0.921\n",
      "744/1662\n",
      "file_name: CarLongPlateGen3181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3181.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.598506\n",
      "recognized_text:  51F-069.48\n",
      "ocr_conf:  0.917\n",
      "745/1662\n",
      "file_name: CarLongPlateGen3190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3190.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 16.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4574951\n",
      "recognized_text:  517748A-0308\n",
      "ocr_conf:  0.786\n",
      "746/1662\n",
      "file_name: CarLongPlateGen3191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3191.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.8ms preprocess, 122.2ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2498965\n",
      "recognized_text:  09539516-4\n",
      "ocr_conf:  0.775\n",
      "747/1662\n",
      "file_name: CarLongPlateGen320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen320.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.9ms preprocess, 124.4ms inference, 14.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8112047\n",
      "recognized_text:  516-394.68\n",
      "ocr_conf:  0.772\n",
      "748/1662\n",
      "file_name: CarLongPlateGen3200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3200.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 6.7ms preprocess, 124.1ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9553604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3201.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.2ms preprocess, 123.8ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  044.1750LD-0\n",
      "ocr_conf:  0.73\n",
      "749/1662\n",
      "file_name: CarLongPlateGen3201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7467483\n",
      "recognized_text:  1734051G-42\n",
      "ocr_conf:  0.857\n",
      "750/1662\n",
      "file_name: CarLongPlateGen321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen321.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.6385317\n",
      "recognized_text:  61C-396.6\n",
      "ocr_conf:  0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/1662\n",
      "file_name: CarLongPlateGen3210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3210.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7010179\n",
      "recognized_text:  752951A-770\n",
      "ocr_conf:  0.829\n",
      "752/1662\n",
      "file_name: CarLongPlateGen3211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3211.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.9ms preprocess, 123.4ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.597442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  62A-057.72\n",
      "ocr_conf:  0.939\n",
      "753/1662\n",
      "file_name: CarLongPlateGen3220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3220.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3879837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3221.jpg: 416x640 1 plate, 121.3ms\n",
      "Speed: 4.6ms preprocess, 121.3ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  0522751A-US\n",
      "ocr_conf:  0.757\n",
      "754/1662\n",
      "file_name: CarLongPlateGen3221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2722204\n",
      "recognized_text:  51F-598.81\n",
      "ocr_conf:  0.858\n",
      "755/1662\n",
      "file_name: CarLongPlateGen3230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3230.jpg: 416x640 1 plate, 126.7ms\n",
      "Speed: 4.4ms preprocess, 126.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.282407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3231.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.96\n",
      "756/1662\n",
      "file_name: CarLongPlateGen3231.jpg\n",
      "aspect_ratio: 1.432105\n",
      "recognized_text:  617.1251F-00\n",
      "ocr_conf:  0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3240.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.7ms preprocess, 124.4ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757/1662\n",
      "file_name: CarLongPlateGen3240.jpg\n",
      "aspect_ratio: 2.9373698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3241.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.4ms preprocess, 131.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  52Y-6490\n",
      "ocr_conf:  0.961\n",
      "758/1662\n",
      "file_name: CarLongPlateGen3241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6925225\n",
      "recognized_text:  V.64906210\n",
      "ocr_conf:  0.775\n",
      "759/1662\n",
      "file_name: CarLongPlateGen3250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3250.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9560523\n",
      "recognized_text:  223751G-222\n",
      "ocr_conf:  0.737\n",
      "760/1662\n",
      "file_name: CarLongPlateGen3251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3251.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 5.0ms preprocess, 123.8ms inference, 13.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5205896\n",
      "recognized_text:  5162237\n",
      "ocr_conf:  0.839\n",
      "761/1662\n",
      "file_name: CarLongPlateGen3260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3260.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4185884\n",
      "recognized_text:  1597451A-4\n",
      "ocr_conf:  0.817\n",
      "762/1662\n",
      "file_name: CarLongPlateGen3261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3261.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.5ms preprocess, 124.7ms inference, 10.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8765134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3270.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.7ms preprocess, 123.7ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  518-1500439.74\n",
      "ocr_conf:  0.732\n",
      "763/1662\n",
      "file_name: CarLongPlateGen3270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7240539\n",
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.962\n",
      "764/1662\n",
      "file_name: CarLongPlateGen3271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3271.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6537675\n",
      "recognized_text:  51F.5390.11\n",
      "ocr_conf:  0.836\n",
      "765/1662\n",
      "file_name: CarLongPlateGen3280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3280.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5177835\n",
      "recognized_text:  275.2951A-7\n",
      "ocr_conf:  0.83\n",
      "766/1662\n",
      "file_name: CarLongPlateGen3281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3281.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1086698\n",
      "recognized_text:  514-7756.29\n",
      "ocr_conf:  0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/1662\n",
      "file_name: CarLongPlateGen3290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3290.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.1ms preprocess, 122.9ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6519452\n",
      "recognized_text:  16.91516-31\n",
      "ocr_conf:  0.874\n",
      "768/1662\n",
      "file_name: CarLongPlateGen3291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3291.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.4ms preprocess, 124.3ms inference, 11.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5281934\n",
      "recognized_text:  97351F-0/8\n",
      "ocr_conf:  0.828\n",
      "769/1662\n",
      "file_name: CarLongPlateGen330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen330.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.8ms preprocess, 124.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.2012515\n",
      "recognized_text:  5118-273.07\n",
      "ocr_conf:  0.761\n",
      "770/1662\n",
      "file_name: CarLongPlateGen3300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3300.jpg: 416x640 1 plate, 131.8ms\n",
      "Speed: 4.5ms preprocess, 131.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4691513\n",
      "recognized_text:  51F-311.18\n",
      "ocr_conf:  0.947\n",
      "771/1662\n",
      "file_name: CarLongPlateGen3301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3301.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2873542\n",
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/1662\n",
      "file_name: CarLongPlateGen331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen331.jpg: 416x640 1 plate, 128.2ms\n",
      "Speed: 4.5ms preprocess, 128.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.189079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51103084\n",
      "ocr_conf:  0.74\n",
      "773/1662\n",
      "file_name: CarLongPlateGen3310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3310.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 5.0ms preprocess, 125.0ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2378426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51G-512.92\n",
      "ocr_conf:  0.868\n",
      "774/1662\n",
      "file_name: CarLongPlateGen3311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3311.jpg: 416x640 1 plate, 131.6ms\n",
      "Speed: 4.9ms preprocess, 131.6ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1540384\n",
      "recognized_text:  51F-730.29\n",
      "ocr_conf:  0.906\n",
      "775/1662\n",
      "file_name: CarLongPlateGen3320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3320.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.6ms preprocess, 124.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.178789\n",
      "recognized_text:  62A-057.72\n",
      "ocr_conf:  0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/1662\n",
      "file_name: CarLongPlateGen3321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3321.jpg: 416x640 1 plate, 131.6ms\n",
      "Speed: 4.7ms preprocess, 131.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8939073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3330.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.4ms preprocess, 125.4ms inference, 12.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  624OOLA-057.72\n",
      "ocr_conf:  0.694\n",
      "777/1662\n",
      "file_name: CarLongPlateGen3330.jpg\n",
      "aspect_ratio: 2.177579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.921\n",
      "778/1662\n",
      "file_name: CarLongPlateGen3331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3331.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.1ms preprocess, 123.7ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6733131\n",
      "recognized_text:  51A-0112.04\n",
      "ocr_conf:  0.878\n",
      "779/1662\n",
      "file_name: CarLongPlateGen3340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3340.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5405679\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.9\n",
      "780/1662\n",
      "file_name: CarLongPlateGen3341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3341.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 13.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7568221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516.5310.08\n",
      "ocr_conf:  0.839\n",
      "781/1662\n",
      "file_name: CarLongPlateGen3350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3350.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 4.5ms preprocess, 124.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3750247\n",
      "recognized_text:  317.97516-2A\n",
      "ocr_conf:  0.768\n",
      "782/1662\n",
      "file_name: CarLongPlateGen3351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3351.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.6ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4080199\n",
      "recognized_text:  055.1662A-08\n",
      "ocr_conf:  0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/1662\n",
      "file_name: CarLongPlateGen3360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3360.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.5ms preprocess, 122.5ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3552893\n",
      "recognized_text:  044.750L0-0\n",
      "ocr_conf:  0.56\n",
      "784/1662\n",
      "file_name: CarLongPlateGen3361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3361.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 8.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2025135\n",
      "recognized_text:  514-853.25\n",
      "ocr_conf:  0.864\n",
      "785/1662\n",
      "file_name: CarLongPlateGen3370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3370.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.3ms preprocess, 124.6ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0556796\n",
      "recognized_text:  51A-775.29\n",
      "ocr_conf:  0.974\n",
      "786/1662\n",
      "file_name: CarLongPlateGen3371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3371.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 9.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1033134\n",
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.963\n",
      "787/1662\n",
      "file_name: CarLongPlateGen3380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3380.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.8ms preprocess, 122.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7856575\n",
      "recognized_text:  0522751A-03\n",
      "ocr_conf:  0.904\n",
      "788/1662\n",
      "file_name: CarLongPlateGen3381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3381.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0660272\n",
      "recognized_text:  516-216.70\n",
      "ocr_conf:  0.941\n",
      "789/1662\n",
      "file_name: CarLongPlateGen3390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3390.jpg: 416x640 1 plate, 129.0ms\n",
      "Speed: 4.4ms preprocess, 129.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8209454\n",
      "recognized_text:  012.0451A-01\n",
      "ocr_conf:  0.932\n",
      "790/1662\n",
      "file_name: CarLongPlateGen3391.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3391.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.44578\n",
      "recognized_text:  51A-D1204\n",
      "ocr_conf:  0.808\n",
      "791/1662\n",
      "file_name: CarLongPlateGen340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen340.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.9ms preprocess, 123.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8776834\n",
      "recognized_text:  51F06509\n",
      "ocr_conf:  0.816\n",
      "792/1662\n",
      "file_name: CarLongPlateGen3400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3400.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7307836\n",
      "recognized_text:  827051F-86\n",
      "ocr_conf:  0.874\n",
      "793/1662\n",
      "file_name: CarLongPlateGen3401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3401.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.483715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  0827051F-88\n",
      "ocr_conf:  0.816\n",
      "794/1662\n",
      "file_name: CarLongPlateGen341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen341.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8144517\n",
      "recognized_text:  1A86714\n",
      "ocr_conf:  0.708\n",
      "795/1662\n",
      "file_name: CarLongPlateGen3410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3410.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4789001\n",
      "recognized_text:  161.59AF-1Oee\n",
      "ocr_conf:  0.587\n",
      "796/1662\n",
      "file_name: CarLongPlateGen3411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3411.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9006971\n",
      "recognized_text:  614.230229.59\n",
      "ocr_conf:  0.763\n",
      "797/1662\n",
      "file_name: CarLongPlateGen3420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3420.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5261117\n",
      "recognized_text:  H514151A-90\n",
      "ocr_conf:  0.742\n",
      "798/1662\n",
      "file_name: CarLongPlateGen3421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3421.jpg: 416x640 1 plate, 130.9ms\n",
      "Speed: 4.5ms preprocess, 130.9ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2053447\n",
      "recognized_text:  51A-961.411\n",
      "ocr_conf:  0.803\n",
      "799/1662\n",
      "file_name: CarLongPlateGen3430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3430.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9755772\n",
      "recognized_text:  133251G-513\n",
      "ocr_conf:  0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/1662\n",
      "file_name: CarLongPlateGen3431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3431.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8917043\n",
      "recognized_text:  513.32516-01\n",
      "ocr_conf:  0.833\n",
      "801/1662\n",
      "file_name: CarLongPlateGen3440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3440.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0707047\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.933\n",
      "802/1662\n",
      "file_name: CarLongPlateGen3441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3441.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1541278\n",
      "recognized_text:  60A-359.81\n",
      "ocr_conf:  0.89\n",
      "803/1662\n",
      "file_name: CarLongPlateGen3450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3450.jpg: 416x640 1 plate, 127.9ms\n",
      "Speed: 4.5ms preprocess, 127.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7847664\n",
      "recognized_text:  783.9651F-70\n",
      "ocr_conf:  0.794\n",
      "804/1662\n",
      "file_name: CarLongPlateGen3451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3451.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4696404\n",
      "recognized_text:  51F.3883.96\n",
      "ocr_conf:  0.649\n",
      "805/1662\n",
      "file_name: CarLongPlateGen3460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3460.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.532441\n",
      "recognized_text:  56N186\n",
      "ocr_conf:  0.945\n",
      "806/1662\n",
      "file_name: CarLongPlateGen3461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3461.jpg: 416x640 1 plate, 129.6ms\n",
      "Speed: 4.3ms preprocess, 129.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6094763\n",
      "recognized_text:  9244451A70\n",
      "ocr_conf:  0.757\n",
      "807/1662\n",
      "file_name: CarLongPlateGen3470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3470.jpg: 416x640 1 plate, 131.4ms\n",
      "Speed: 4.5ms preprocess, 131.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7385731\n",
      "recognized_text:  044.11FOLD-0R\n",
      "ocr_conf:  0.565\n",
      "808/1662\n",
      "file_name: CarLongPlateGen3471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3471.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 6.0ms preprocess, 123.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.689064\n",
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.875\n",
      "809/1662\n",
      "file_name: CarLongPlateGen3480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3480.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.2ms preprocess, 124.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8512031\n",
      "recognized_text:  100.96516-10\n",
      "ocr_conf:  0.89\n",
      "810/1662\n",
      "file_name: CarLongPlateGen3481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3481.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6982244\n",
      "recognized_text:  51G.10100.96\n",
      "ocr_conf:  0.812\n",
      "811/1662\n",
      "file_name: CarLongPlateGen3490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3490.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 5.0ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2011294\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.868\n",
      "812/1662\n",
      "file_name: CarLongPlateGen3491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3491.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.2ms preprocess, 123.8ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2815027\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen350.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 14.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813/1662\n",
      "file_name: CarLongPlateGen350.jpg\n",
      "aspect_ratio: 3.517479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3500.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  61G-81681\n",
      "ocr_conf:  0.529\n",
      "814/1662\n",
      "file_name: CarLongPlateGen3500.jpg\n",
      "aspect_ratio: 2.7605066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3501.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.922\n",
      "815/1662\n",
      "file_name: CarLongPlateGen3501.jpg\n",
      "aspect_ratio: 2.7146003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.887\n",
      "816/1662\n",
      "file_name: CarLongPlateGen351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen351.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 8.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0110793\n",
      "recognized_text:  D6-318\n",
      "ocr_conf:  0.384\n",
      "817/1662\n",
      "file_name: CarLongPlateGen3510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3510.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4222887\n",
      "recognized_text:  0167051G-21\n",
      "ocr_conf:  0.754\n",
      "818/1662\n",
      "file_name: CarLongPlateGen3511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3511.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9548256\n",
      "recognized_text:  51F-63030.34\n",
      "ocr_conf:  0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3520.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.8ms preprocess, 123.8ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819/1662\n",
      "file_name: CarLongPlateGen3520.jpg\n",
      "aspect_ratio: 3.1700885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3521.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.5ms preprocess, 124.3ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-882.70\n",
      "ocr_conf:  0.907\n",
      "820/1662\n",
      "file_name: CarLongPlateGen3521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.257851\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.942\n",
      "821/1662\n",
      "file_name: CarLongPlateGen3530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3530.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8562384\n",
      "recognized_text:  514-961.41\n",
      "ocr_conf:  0.824\n",
      "822/1662\n",
      "file_name: CarLongPlateGen3531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3531.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.404121\n",
      "recognized_text:  51F-446.14\n",
      "ocr_conf:  0.884\n",
      "823/1662\n",
      "file_name: CarLongPlateGen3540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3540.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 9.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8628982\n",
      "recognized_text:  61A.30395.34\n",
      "ocr_conf:  0.845\n",
      "824/1662\n",
      "file_name: CarLongPlateGen3541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3541.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 5.3ms preprocess, 123.8ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.375301\n",
      "recognized_text:  51G-513.32)\n",
      "ocr_conf:  0.848\n",
      "825/1662\n",
      "file_name: CarLongPlateGen3550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3550.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 5.0ms preprocess, 123.5ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.169926\n",
      "recognized_text:  [614-229.59\n",
      "ocr_conf:  0.909\n",
      "826/1662\n",
      "file_name: CarLongPlateGen3551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3551.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.5ms preprocess, 122.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8558977\n",
      "recognized_text:  51F-026.87\n",
      "ocr_conf:  0.9\n",
      "827/1662\n",
      "file_name: CarLongPlateGen3560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3560.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 4.4ms preprocess, 122.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2263982\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3561.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 5.3ms preprocess, 122.8ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/1662\n",
      "file_name: CarLongPlateGen3561.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3513393\n",
      "recognized_text:  51B-216.66\n",
      "ocr_conf:  0.862\n",
      "829/1662\n",
      "file_name: CarLongPlateGen3570.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3570.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.8ms preprocess, 123.9ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8793492\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.906\n",
      "830/1662\n",
      "file_name: CarLongPlateGen3571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3571.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1700041\n",
      "recognized_text:  51A-961.41\n",
      "ocr_conf:  0.966\n",
      "831/1662\n",
      "file_name: CarLongPlateGen3580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3580.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.4ms preprocess, 124.8ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1477273\n",
      "recognized_text:  51F-630.34\n",
      "ocr_conf:  0.802\n",
      "832/1662\n",
      "file_name: CarLongPlateGen3581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3581.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.6ms preprocess, 131.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9104724\n",
      "recognized_text:  51F:21I44.03\n",
      "ocr_conf:  0.817\n",
      "833/1662\n",
      "file_name: CarLongPlateGen3590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3590.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9061953\n",
      "recognized_text:  516-01014.40\n",
      "ocr_conf:  0.911\n",
      "834/1662\n",
      "file_name: CarLongPlateGen3591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3591.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9364448\n",
      "recognized_text:  001440-516-014\n",
      "ocr_conf:  0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen360.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.8ms preprocess, 123.2ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/1662\n",
      "file_name: CarLongPlateGen360.jpg\n",
      "aspect_ratio: 3.0456967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3600.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-51332\n",
      "ocr_conf:  0.87\n",
      "836/1662\n",
      "file_name: CarLongPlateGen3600.jpg\n",
      "aspect_ratio: 2.1387565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3601.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-22261\n",
      "ocr_conf:  0.874\n",
      "837/1662\n",
      "file_name: CarLongPlateGen3601.jpg\n",
      "aspect_ratio: 3.279562\n",
      "recognized_text:  51A-012.04\n",
      "ocr_conf:  0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen361.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838/1662\n",
      "file_name: CarLongPlateGen361.jpg\n",
      "aspect_ratio: 4.351628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3610.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.747\n",
      "839/1662\n",
      "file_name: CarLongPlateGen3610.jpg\n",
      "aspect_ratio: 1.7348228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3611.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.1ms preprocess, 123.7ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  079.7351F-07\n",
      "ocr_conf:  0.923\n",
      "840/1662\n",
      "file_name: CarLongPlateGen3611.jpg\n",
      "aspect_ratio: 1.6868829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-019.73\n",
      "ocr_conf:  0.888\n",
      "841/1662\n",
      "file_name: CarLongPlateGen3620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3620.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.83155\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.972\n",
      "842/1662\n",
      "file_name: CarLongPlateGen3621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3621.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.4ms preprocess, 124.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5982677\n",
      "recognized_text:  51A.6091.72\n",
      "ocr_conf:  0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3630.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.3ms preprocess, 122.9ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843/1662\n",
      "file_name: CarLongPlateGen3630.jpg\n",
      "aspect_ratio: 1.8476683\n",
      "recognized_text:  51D-1000.39\n",
      "ocr_conf:  0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3631.jpg: 416x640 1 plate, 125.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844/1662\n",
      "file_name: CarLongPlateGen3631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.5ms preprocess, 125.9ms inference, 10.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1756215\n",
      "recognized_text:  510-100.39\n",
      "ocr_conf:  0.895\n",
      "845/1662\n",
      "file_name: CarLongPlateGen3640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3640.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.445263\n",
      "recognized_text:  29A317.96\n",
      "ocr_conf:  0.8\n",
      "846/1662\n",
      "file_name: CarLongPlateGen3641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3641.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.627023\n",
      "recognized_text:  Z9A-5317.96\n",
      "ocr_conf:  0.806\n",
      "847/1662\n",
      "file_name: CarLongPlateGen3650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3650.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0169492\n",
      "recognized_text:  51A-602.16\n",
      "ocr_conf:  0.878\n",
      "848/1662\n",
      "file_name: CarLongPlateGen3651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3651.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.6ms preprocess, 124.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8481492\n",
      "recognized_text:  624.051.95\n",
      "ocr_conf:  0.835\n",
      "849/1662\n",
      "file_name: CarLongPlateGen3660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3660.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6036036\n",
      "recognized_text:  155.8551F-13\n",
      "ocr_conf:  0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3661.jpg: 416x640 1 plate, 125.1ms\n",
      "Speed: 7.5ms preprocess, 125.1ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/1662\n",
      "file_name: CarLongPlateGen3661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7110307\n",
      "recognized_text:  51F-222.61\n",
      "ocr_conf:  0.934\n",
      "851/1662\n",
      "file_name: CarLongPlateGen3670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3670.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 4.6ms preprocess, 122.4ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9100479\n",
      "recognized_text:  000161A-300\n",
      "ocr_conf:  0.884\n",
      "852/1662\n",
      "file_name: CarLongPlateGen3671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3671.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 5.3ms preprocess, 121.9ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8320737\n",
      "recognized_text:  61A-300.01\n",
      "ocr_conf:  0.918\n",
      "853/1662\n",
      "file_name: CarLongPlateGen3680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3680.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.8ms preprocess, 123.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0899239\n",
      "recognized_text:  51F-161.69\n",
      "ocr_conf:  0.903\n",
      "854/1662\n",
      "file_name: CarLongPlateGen3681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3681.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.4ms preprocess, 124.3ms inference, 8.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4624512\n",
      "recognized_text:  51.5951-1009BE\n",
      "ocr_conf:  0.87\n",
      "855/1662\n",
      "file_name: CarLongPlateGen3690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3690.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.065091\n",
      "recognized_text:  50LD-044.11\n",
      "ocr_conf:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856/1662\n",
      "file_name: CarLongPlateGen3691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3691.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 8.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8808649\n",
      "recognized_text:  501D-044.11\n",
      "ocr_conf:  0.854\n",
      "857/1662\n",
      "file_name: CarLongPlateGen370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen370.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 9.0ms preprocess, 122.7ms inference, 15.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9382265\n",
      "recognized_text:  61F-0427\n",
      "ocr_conf:  0.85\n",
      "858/1662\n",
      "file_name: CarLongPlateGen3700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3700.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.2ms preprocess, 122.5ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.935164\n",
      "recognized_text:  0090551A-903\n",
      "ocr_conf:  0.892\n",
      "859/1662\n",
      "file_name: CarLongPlateGen3701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3701.jpg: 416x640 1 plate, 126.4ms\n",
      "Speed: 4.7ms preprocess, 126.4ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3623204\n",
      "recognized_text:  51G-100.96)\n",
      "ocr_conf:  0.888\n",
      "860/1662\n",
      "file_name: CarLongPlateGen371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen371.jpg: 416x640 1 plate, 129.3ms\n",
      "Speed: 4.6ms preprocess, 129.3ms inference, 10.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.592912\n",
      "recognized_text:  076\n",
      "ocr_conf:  0.712\n",
      "861/1662\n",
      "file_name: CarLongPlateGen3710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3710.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 5.7ms preprocess, 123.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.356343\n",
      "recognized_text:  G-373.07\n",
      "ocr_conf:  0.941\n",
      "862/1662\n",
      "file_name: CarLongPlateGen3711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3711.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 10.7ms preprocess, 125.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3064749\n",
      "recognized_text:  653605.\n",
      "ocr_conf:  0.84\n",
      "863/1662\n",
      "file_name: CarLongPlateGen3720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3720.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.4ms preprocess, 125.0ms inference, 10.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6433046\n",
      "recognized_text:  60LD-005.84\n",
      "ocr_conf:  0.83\n",
      "864/1662\n",
      "file_name: CarLongPlateGen3721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3721.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.397347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  41860A-21\n",
      "ocr_conf:  0.798\n",
      "865/1662\n",
      "file_name: CarLongPlateGen3730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3730.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.1ms preprocess, 123.1ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1883917\n",
      "recognized_text:  61F-244.03\n",
      "ocr_conf:  0.855\n",
      "866/1662\n",
      "file_name: CarLongPlateGen3731.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3731.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0076346\n",
      "recognized_text:  51F-795.12\n",
      "ocr_conf:  0.882\n",
      "867/1662\n",
      "file_name: CarLongPlateGen3740.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3740.jpg: 416x640 1 plate, 127.6ms\n",
      "Speed: 4.1ms preprocess, 127.6ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0889814\n",
      "recognized_text:  51F-07973\n",
      "ocr_conf:  0.865\n",
      "868/1662\n",
      "file_name: CarLongPlateGen3741.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3741.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7075335\n",
      "recognized_text:  51F-61357712\n",
      "ocr_conf:  0.724\n",
      "869/1662\n",
      "file_name: CarLongPlateGen3750.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3750.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.4ms preprocess, 124.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6103616\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.944\n",
      "870/1662\n",
      "file_name: CarLongPlateGen3751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3751.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.3ms preprocess, 122.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4409425\n",
      "recognized_text:  51G-102.09\n",
      "ocr_conf:  0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3760.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/1662\n",
      "file_name: CarLongPlateGen3760.jpg\n",
      "aspect_ratio: 2.1755917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  S1F-446.14\n",
      "ocr_conf:  0.853\n",
      "872/1662\n",
      "file_name: CarLongPlateGen3761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3761.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.7ms preprocess, 124.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.0070803\n",
      "recognized_text:  51F-24.03\n",
      "ocr_conf:  0.897\n",
      "873/1662\n",
      "file_name: CarLongPlateGen3770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3770.jpg: 416x640 1 plate, 132.3ms\n",
      "Speed: 4.3ms preprocess, 132.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.286541\n",
      "recognized_text:  51332516-0\n",
      "ocr_conf:  0.808\n",
      "874/1662\n",
      "file_name: CarLongPlateGen3771.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3771.jpg: 416x640 1 plate, 127.9ms\n",
      "Speed: 4.5ms preprocess, 127.9ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.210049\n",
      "recognized_text:  51G-513.32\n",
      "ocr_conf:  0.909\n",
      "875/1662\n",
      "file_name: CarLongPlateGen3780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3780.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.5ms preprocess, 124.0ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.3389406\n",
      "recognized_text:  51G-205.36\n",
      "ocr_conf:  0.967\n",
      "876/1662\n",
      "file_name: CarLongPlateGen3781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3781.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7519659\n",
      "recognized_text:  51F-78009.04\n",
      "ocr_conf:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3790.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/1662\n",
      "file_name: CarLongPlateGen3790.jpg\n",
      "aspect_ratio: 1.9080062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3791.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  165.8551F-150\n",
      "ocr_conf:  0.756\n",
      "878/1662\n",
      "file_name: CarLongPlateGen3791.jpg\n",
      "aspect_ratio: 2.6877782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.889\n",
      "879/1662\n",
      "file_name: CarLongPlateGen380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen380.jpg: 416x640 1 plate, 130.5ms\n",
      "Speed: 4.4ms preprocess, 130.5ms inference, 15.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9395435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  61637601\n",
      "ocr_conf:  0.573\n",
      "880/1662\n",
      "file_name: CarLongPlateGen3800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3800.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 11.6ms preprocess, 123.3ms inference, 8.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4969015\n",
      "recognized_text:  51F-984.66\n",
      "ocr_conf:  0.934\n",
      "881/1662\n",
      "file_name: CarLongPlateGen3801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3801.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.2ms preprocess, 122.9ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4994504\n",
      "recognized_text:  51F.90384.66\n",
      "ocr_conf:  0.784\n",
      "882/1662\n",
      "file_name: CarLongPlateGen381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen381.jpg: 416x640 1 plate, 130.8ms\n",
      "Speed: 4.8ms preprocess, 130.8ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.426848\n",
      "recognized_text:  12821\n",
      "ocr_conf:  0.72\n",
      "883/1662\n",
      "file_name: CarLongPlateGen3810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3810.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4353513\n",
      "recognized_text:  399330V3\n",
      "ocr_conf:  0.637\n",
      "884/1662\n",
      "file_name: CarLongPlateGen3811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3811.jpg: 416x640 1 plate, 125.1ms\n",
      "Speed: 4.8ms preprocess, 125.1ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.634315\n",
      "recognized_text:  B0-3993\n",
      "ocr_conf:  0.786\n",
      "885/1662\n",
      "file_name: CarLongPlateGen3820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3820.jpg: 416x640 1 plate, 130.4ms\n",
      "Speed: 4.3ms preprocess, 130.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6819149\n",
      "recognized_text:  796.29A-51\n",
      "ocr_conf:  0.825\n",
      "886/1662\n",
      "file_name: CarLongPlateGen3821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3821.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2865803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3830.jpg: 416x640 1 plate, 133.9ms\n",
      "Speed: 5.3ms preprocess, 133.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  796294-57\n",
      "ocr_conf:  0.814\n",
      "887/1662\n",
      "file_name: CarLongPlateGen3830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.65452\n",
      "recognized_text:  5988151F-03\n",
      "ocr_conf:  0.859\n",
      "888/1662\n",
      "file_name: CarLongPlateGen3831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3831.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5305701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3840.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.0ms preprocess, 123.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-0112.04\n",
      "ocr_conf:  0.787\n",
      "889/1662\n",
      "file_name: CarLongPlateGen3840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9210343\n",
      "recognized_text:  5643351A-533\n",
      "ocr_conf:  0.717\n",
      "890/1662\n",
      "file_name: CarLongPlateGen3841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3841.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4550831\n",
      "recognized_text:  30E-000.90\n",
      "ocr_conf:  0.937\n",
      "891/1662\n",
      "file_name: CarLongPlateGen3850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3850.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2368174\n",
      "recognized_text:  51F-356.13\n",
      "ocr_conf:  0.932\n",
      "892/1662\n",
      "file_name: CarLongPlateGen3851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3851.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 4.8ms preprocess, 121.8ms inference, 3.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9253745\n",
      "recognized_text:  51E.356356.13\n",
      "ocr_conf:  0.755\n",
      "893/1662\n",
      "file_name: CarLongPlateGen3860.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3860.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.662075\n",
      "recognized_text:  L4.0351F-2VN\n",
      "ocr_conf:  0.684\n",
      "894/1662\n",
      "file_name: CarLongPlateGen3861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3861.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8294536\n",
      "recognized_text:  140351F2\n",
      "ocr_conf:  0.773\n",
      "895/1662\n",
      "file_name: CarLongPlateGen3870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3870.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3764125\n",
      "recognized_text:  59.8160A-38\n",
      "ocr_conf:  0.825\n",
      "896/1662\n",
      "file_name: CarLongPlateGen3871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3871.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9893577\n",
      "recognized_text:  048.7751F-0\n",
      "ocr_conf:  0.791\n",
      "897/1662\n",
      "file_name: CarLongPlateGen3880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3880.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4092088\n",
      "recognized_text:  51F-789.04\n",
      "ocr_conf:  0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3881.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/1662\n",
      "file_name: CarLongPlateGen3881.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6324248\n",
      "recognized_text:  51G-519.36\n",
      "ocr_conf:  0.956\n",
      "899/1662\n",
      "file_name: CarLongPlateGen3890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3890.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1835618\n",
      "recognized_text:  [29A-239.50\n",
      "ocr_conf:  0.952\n",
      "900/1662\n",
      "file_name: CarLongPlateGen3891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3891.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.7ms preprocess, 122.8ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.161588\n",
      "recognized_text:  516-481.54\n",
      "ocr_conf:  0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen390.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/1662\n",
      "file_name: CarLongPlateGen390.jpg\n",
      "aspect_ratio: 3.83149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3900.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-49539\n",
      "ocr_conf:  0.89\n",
      "902/1662\n",
      "file_name: CarLongPlateGen3900.jpg\n",
      "aspect_ratio: 1.7676877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen3901.jpg: 416x640 1 plate, 126.9ms\n",
      "Speed: 4.5ms preprocess, 126.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  507.06C-0618\n",
      "ocr_conf:  0.768\n",
      "903/1662\n",
      "file_name: CarLongPlateGen3901.jpg\n",
      "aspect_ratio: 1.4945636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen391.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 5.0ms preprocess, 123.1ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  3.06185020\n",
      "ocr_conf:  0.801\n",
      "904/1662\n",
      "file_name: CarLongPlateGen391.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7776381\n",
      "recognized_text:  RM8906\n",
      "ocr_conf:  0.342\n",
      "905/1662\n",
      "file_name: CarLongPlateGen40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen40.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0849023\n",
      "recognized_text:  02.09\n",
      "ocr_conf:  0.938\n",
      "906/1662\n",
      "file_name: CarLongPlateGen400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen400.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6629689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  510-10096\n",
      "ocr_conf:  0.889\n",
      "907/1662\n",
      "file_name: CarLongPlateGen401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen401.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2167916\n",
      "recognized_text:  51010898\n",
      "ocr_conf:  0.69\n",
      "908/1662\n",
      "file_name: CarLongPlateGen41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen41.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5385804\n",
      "recognized_text:  51649524\n",
      "ocr_conf:  0.901\n",
      "909/1662\n",
      "file_name: CarLongPlateGen410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen410.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 12.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5469382\n",
      "recognized_text:  G1F-065.32\n",
      "ocr_conf:  0.804\n",
      "910/1662\n",
      "file_name: CarLongPlateGen411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen411.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2733848\n",
      "recognized_text:  1F-065.32\n",
      "ocr_conf:  0.906\n",
      "911/1662\n",
      "file_name: CarLongPlateGen420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen420.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3615053\n",
      "recognized_text:  51F-617.12\n",
      "ocr_conf:  0.936\n",
      "912/1662\n",
      "file_name: CarLongPlateGen421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen421.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 7.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8006086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  DEEN\n",
      "ocr_conf:  0.268\n",
      "913/1662\n",
      "file_name: CarLongPlateGen430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen430.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.7ms preprocess, 124.4ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8598692\n",
      "recognized_text:  BTF-88270\n",
      "ocr_conf:  0.897\n",
      "914/1662\n",
      "file_name: CarLongPlateGen431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen431.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.5678687\n",
      "recognized_text:  1F-869.88\n",
      "ocr_conf:  0.874\n",
      "915/1662\n",
      "file_name: CarLongPlateGen440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen440.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.472079\n",
      "recognized_text:  61F-15585\n",
      "ocr_conf:  0.773\n",
      "916/1662\n",
      "file_name: CarLongPlateGen441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen441.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.048369\n",
      "recognized_text:  RF-22261\n",
      "ocr_conf:  0.761\n",
      "917/1662\n",
      "file_name: CarLongPlateGen450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen450.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9074857\n",
      "recognized_text:  56N-7180\n",
      "ocr_conf:  0.704\n",
      "918/1662\n",
      "file_name: CarLongPlateGen451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen451.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.0509486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  2074\n",
      "ocr_conf:  0.537\n",
      "919/1662\n",
      "file_name: CarLongPlateGen460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen460.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.5ms preprocess, 124.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0091996\n",
      "recognized_text:  516-21748\n",
      "ocr_conf:  0.819\n",
      "920/1662\n",
      "file_name: CarLongPlateGen461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen461.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5765715\n",
      "recognized_text:  51G-344.71\n",
      "ocr_conf:  0.86\n",
      "921/1662\n",
      "file_name: CarLongPlateGen470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen470.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.5ms preprocess, 124.1ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.529408\n",
      "recognized_text:  51F-88270\n",
      "ocr_conf:  0.865\n",
      "922/1662\n",
      "file_name: CarLongPlateGen471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen471.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 7.3ms preprocess, 123.5ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5436099\n",
      "recognized_text:  8270\n",
      "ocr_conf:  0.675\n",
      "923/1662\n",
      "file_name: CarLongPlateGen480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen480.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.521175\n",
      "recognized_text:  61A\n",
      "ocr_conf:  0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen481.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.5ms preprocess, 122.2ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/1662\n",
      "file_name: CarLongPlateGen481.jpg\n",
      "aspect_ratio: 4.36755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  FEFSU801\n",
      "ocr_conf:  0.537\n",
      "925/1662\n",
      "file_name: CarLongPlateGen490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen490.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.766718\n",
      "recognized_text:  16344\n",
      "ocr_conf:  0.581\n",
      "926/1662\n",
      "file_name: CarLongPlateGen491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen491.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.093787\n",
      "recognized_text:  01F-079.73\n",
      "ocr_conf:  0.857\n",
      "927/1662\n",
      "file_name: CarLongPlateGen50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen50.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 10.1ms preprocess, 124.6ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4901085\n",
      "recognized_text:  30N-4616\n",
      "ocr_conf:  0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/1662\n",
      "file_name: CarLongPlateGen500.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen500.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 5.0ms preprocess, 125.8ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.78499\n",
      "recognized_text:  8698\n",
      "ocr_conf:  0.837\n",
      "929/1662\n",
      "file_name: CarLongPlateGen501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen501.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.7ms preprocess, 123.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.716279\n",
      "recognized_text:  69.88\n",
      "ocr_conf:  0.843\n",
      "930/1662\n",
      "file_name: CarLongPlateGen51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen51.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.853674\n",
      "recognized_text:  40A-028.66\n",
      "ocr_conf:  0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931/1662\n",
      "file_name: CarLongPlateGen510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen510.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 16.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5970109\n",
      "recognized_text:  627-9755\n",
      "ocr_conf:  0.848\n",
      "932/1662\n",
      "file_name: CarLongPlateGen511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen511.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3552349\n",
      "recognized_text:  52Z-9755\n",
      "ocr_conf:  0.825\n",
      "933/1662\n",
      "file_name: CarLongPlateGen520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen520.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9041018\n",
      "recognized_text:  516-510.08\n",
      "ocr_conf:  0.957\n",
      "934/1662\n",
      "file_name: CarLongPlateGen521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen521.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.5ms preprocess, 124.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.985982\n",
      "recognized_text:  510 510.00\n",
      "ocr_conf:  0.792\n",
      "935/1662\n",
      "file_name: CarLongPlateGen530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen530.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.609214\n",
      "recognized_text:  1F-155.80\n",
      "ocr_conf:  0.686\n",
      "936/1662\n",
      "file_name: CarLongPlateGen531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen531.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2824938\n",
      "recognized_text:  51F-222.6\n",
      "ocr_conf:  0.795\n",
      "937/1662\n",
      "file_name: CarLongPlateGen540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen540.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9569151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1F-042.79\n",
      "ocr_conf:  0.807\n",
      "938/1662\n",
      "file_name: CarLongPlateGen541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen541.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9137185\n",
      "recognized_text:  F-04225\n",
      "ocr_conf:  0.559\n",
      "939/1662\n",
      "file_name: CarLongPlateGen550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen550.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.5ms preprocess, 124.5ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.166646\n",
      "recognized_text:  1C-21670\n",
      "ocr_conf:  0.84\n",
      "940/1662\n",
      "file_name: CarLongPlateGen551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen551.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.1ms preprocess, 124.0ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5851116\n",
      "recognized_text:  IF-698A\n",
      "ocr_conf:  0.59\n",
      "941/1662\n",
      "file_name: CarLongPlateGen560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen560.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9290168\n",
      "recognized_text:  1G-25481\n",
      "ocr_conf:  0.902\n",
      "942/1662\n",
      "file_name: CarLongPlateGen561.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen561.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.462246\n",
      "recognized_text:  51G-25481\n",
      "ocr_conf:  0.836\n",
      "943/1662\n",
      "file_name: CarLongPlateGen570.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen570.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3673248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  57F 6661\n",
      "ocr_conf:  0.629\n",
      "944/1662\n",
      "file_name: CarLongPlateGen571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen571.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.1ms preprocess, 123.5ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.546259\n",
      "recognized_text:  C-47281\n",
      "ocr_conf:  0.867\n",
      "945/1662\n",
      "file_name: CarLongPlateGen580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen580.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.7ms preprocess, 124.1ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8989036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen581.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.6ms preprocess, 122.0ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  510-394.80\n",
      "ocr_conf:  0.739\n",
      "946/1662\n",
      "file_name: CarLongPlateGen581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.079377\n",
      "recognized_text:  61F-079.73\n",
      "ocr_conf:  0.887\n",
      "947/1662\n",
      "file_name: CarLongPlateGen590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen590.jpg: 416x640 1 plate, 129.7ms\n",
      "Speed: 4.3ms preprocess, 129.7ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0715992\n",
      "recognized_text:  930-00103\n",
      "ocr_conf:  0.889\n",
      "948/1662\n",
      "file_name: CarLongPlateGen591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen591.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.3ms preprocess, 123.6ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3719373\n",
      "recognized_text:  93L0-00709\n",
      "ocr_conf:  0.71\n",
      "949/1662\n",
      "file_name: CarLongPlateGen60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen60.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.19683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  S1A-05227\n",
      "ocr_conf:  0.709\n",
      "950/1662\n",
      "file_name: CarLongPlateGen600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen600.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8654742\n",
      "recognized_text:  51F-22029\n",
      "ocr_conf:  0.801\n",
      "951/1662\n",
      "file_name: CarLongPlateGen601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen601.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.6ms preprocess, 124.0ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0681663\n",
      "recognized_text:  616016.40\n",
      "ocr_conf:  0.806\n",
      "952/1662\n",
      "file_name: CarLongPlateGen61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen61.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7388973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen610.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  22\n",
      "ocr_conf:  0.385\n",
      "953/1662\n",
      "file_name: CarLongPlateGen610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.655182\n",
      "recognized_text:  51F-089.48\n",
      "ocr_conf:  0.793\n",
      "954/1662\n",
      "file_name: CarLongPlateGen611.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen611.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8504865\n",
      "recognized_text:  516-39.66\n",
      "ocr_conf:  0.798\n",
      "955/1662\n",
      "file_name: CarLongPlateGen620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen620.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.6ms preprocess, 126.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4780617\n",
      "recognized_text:  51G-10209\n",
      "ocr_conf:  0.877\n",
      "956/1662\n",
      "file_name: CarLongPlateGen621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen621.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 5.5ms preprocess, 124.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5694673\n",
      "recognized_text:  516-373.07\n",
      "ocr_conf:  0.925\n",
      "957/1662\n",
      "file_name: CarLongPlateGen630.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen630.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3326783\n",
      "recognized_text:  51F-244.05\n",
      "ocr_conf:  0.69\n",
      "958/1662\n",
      "file_name: CarLongPlateGen631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen631.jpg: 416x640 1 plate, 125.1ms\n",
      "Speed: 4.6ms preprocess, 125.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7664585\n",
      "recognized_text:  1A-691.72\n",
      "ocr_conf:  0.905\n",
      "959/1662\n",
      "file_name: CarLongPlateGen640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen640.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.7ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.322446\n",
      "recognized_text:  1F-582.50\n",
      "ocr_conf:  0.933\n",
      "960/1662\n",
      "file_name: CarLongPlateGen641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen641.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8260605\n",
      "recognized_text:  51-685\n",
      "ocr_conf:  0.521\n",
      "961/1662\n",
      "file_name: CarLongPlateGen650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen650.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.434287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  616-472.81\n",
      "ocr_conf:  0.872\n",
      "962/1662\n",
      "file_name: CarLongPlateGen651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen651.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0680385\n",
      "recognized_text:  51A-897.14\n",
      "ocr_conf:  0.759\n",
      "963/1662\n",
      "file_name: CarLongPlateGen660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen660.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8689022\n",
      "recognized_text:  51F/47.64\n",
      "ocr_conf:  0.657\n",
      "964/1662\n",
      "file_name: CarLongPlateGen661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen661.jpg: 416x640 1 plate, 130.9ms\n",
      "Speed: 7.3ms preprocess, 130.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.241856\n",
      "recognized_text:  616-28.61\n",
      "ocr_conf:  0.756\n",
      "965/1662\n",
      "file_name: CarLongPlateGen670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen670.jpg: 416x640 1 plate, 141.1ms\n",
      "Speed: 4.5ms preprocess, 141.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7255156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51A-853.25\n",
      "ocr_conf:  0.916\n",
      "966/1662\n",
      "file_name: CarLongPlateGen671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen671.jpg: 416x640 1 plate, 129.1ms\n",
      "Speed: 4.5ms preprocess, 129.1ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5984478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  514400\n",
      "ocr_conf:  0.471\n",
      "967/1662\n",
      "file_name: CarLongPlateGen680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen680.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.4ms preprocess, 123.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.796131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  610-61334\n",
      "ocr_conf:  0.767\n",
      "968/1662\n",
      "file_name: CarLongPlateGen681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen681.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5565183\n",
      "recognized_text:  61F-695.45\n",
      "ocr_conf:  0.897\n",
      "969/1662\n",
      "file_name: CarLongPlateGen690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen690.jpg: 416x640 1 plate, 131.4ms\n",
      "Speed: 4.7ms preprocess, 131.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4476655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-21670\n",
      "ocr_conf:  0.87\n",
      "970/1662\n",
      "file_name: CarLongPlateGen691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen691.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.3ms preprocess, 124.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.037993\n",
      "recognized_text:  51621670\n",
      "ocr_conf:  0.863\n",
      "971/1662\n",
      "file_name: CarLongPlateGen70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen70.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.431222\n",
      "recognized_text:  F1207978\n",
      "ocr_conf:  0.44\n",
      "972/1662\n",
      "file_name: CarLongPlateGen700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen700.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0146565\n",
      "recognized_text:  5120043\n",
      "ocr_conf:  0.506\n",
      "973/1662\n",
      "file_name: CarLongPlateGen701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen701.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6930096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  oqv-3993\n",
      "ocr_conf:  0.774\n",
      "974/1662\n",
      "file_name: CarLongPlateGen71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen71.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.202717\n",
      "recognized_text:  F1P-07073\n",
      "ocr_conf:  0.503\n",
      "975/1662\n",
      "file_name: CarLongPlateGen710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen710.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.7ms preprocess, 123.8ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7119443\n",
      "recognized_text:  1F07.12\n",
      "ocr_conf:  0.695\n",
      "976/1662\n",
      "file_name: CarLongPlateGen711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen711.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.3ms preprocess, 122.9ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9443653\n",
      "recognized_text:  5188270\n",
      "ocr_conf:  0.891\n",
      "977/1662\n",
      "file_name: CarLongPlateGen720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen720.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0203257\n",
      "recognized_text:  A-229.5\n",
      "ocr_conf:  0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/1662\n",
      "file_name: CarLongPlateGen721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen721.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.070221\n",
      "recognized_text:  51C-10209\n",
      "ocr_conf:  0.898\n",
      "979/1662\n",
      "file_name: CarLongPlateGen730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen730.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4059713\n",
      "recognized_text:  51A-602.10\n",
      "ocr_conf:  0.92\n",
      "980/1662\n",
      "file_name: CarLongPlateGen731.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen731.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.44571\n",
      "recognized_text:  SA72A0\n",
      "ocr_conf:  0.675\n",
      "981/1662\n",
      "file_name: CarLongPlateGen740.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen740.jpg: 416x640 1 plate, 129.4ms\n",
      "Speed: 4.5ms preprocess, 129.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.584431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1614\n",
      "ocr_conf:  0.914\n",
      "982/1662\n",
      "file_name: CarLongPlateGen741.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen741.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 6.1ms preprocess, 123.7ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7775102\n",
      "recognized_text:  IF-44616\n",
      "ocr_conf:  0.55\n",
      "983/1662\n",
      "file_name: CarLongPlateGen750.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen750.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.255794\n",
      "recognized_text:  61A-395.34\n",
      "ocr_conf:  0.913\n",
      "984/1662\n",
      "file_name: CarLongPlateGen751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen751.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9810352\n",
      "recognized_text:  61A-39534\n",
      "ocr_conf:  0.919\n",
      "985/1662\n",
      "file_name: CarLongPlateGen760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen760.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4003177\n",
      "recognized_text:  582.50\n",
      "ocr_conf:  0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen761.jpg: 416x640 2 plates, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986/1662\n",
      "file_name: CarLongPlateGen761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.086015\n",
      "recognized_text:  R2A\n",
      "ocr_conf:  0.414\n",
      "987/1662\n",
      "file_name: CarLongPlateGen770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen770.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.034513\n",
      "recognized_text:  516-519.36\n",
      "ocr_conf:  0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen771.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 6.5ms preprocess, 123.5ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988/1662\n",
      "file_name: CarLongPlateGen771.jpg\n",
      "aspect_ratio: 3.3961282\n",
      "recognized_text:  51938\n",
      "ocr_conf:  0.834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989/1662\n",
      "file_name: CarLongPlateGen780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen780.jpg: 416x640 1 plate, 135.6ms\n",
      "Speed: 4.5ms preprocess, 135.6ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4063725\n",
      "recognized_text:  56-491.60\n",
      "ocr_conf:  0.89\n",
      "990/1662\n",
      "file_name: CarLongPlateGen781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen781.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 4.5ms preprocess, 121.8ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0952168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-20754\n",
      "ocr_conf:  0.932\n",
      "991/1662\n",
      "file_name: CarLongPlateGen790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen790.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.8ms preprocess, 124.4ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.1396112\n",
      "recognized_text:  516-251.81\n",
      "ocr_conf:  0.881\n",
      "992/1662\n",
      "file_name: CarLongPlateGen791.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen791.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4547222\n",
      "recognized_text:  GSIA\n",
      "ocr_conf:  0.41\n",
      "993/1662\n",
      "file_name: CarLongPlateGen80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen80.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.8ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.963273\n",
      "recognized_text:  61F-83034\n",
      "ocr_conf:  0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen800.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.6ms preprocess, 126.3ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/1662\n",
      "file_name: CarLongPlateGen800.jpg\n",
      "aspect_ratio: 3.4900146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  516-011.77\n",
      "ocr_conf:  0.909\n",
      "995/1662\n",
      "file_name: CarLongPlateGen801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen801.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.5ms preprocess, 124.2ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2269943\n",
      "recognized_text:  G-071.77\n",
      "ocr_conf:  0.723\n",
      "996/1662\n",
      "file_name: CarLongPlateGen81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen81.jpg: 416x640 1 plate, 132.5ms\n",
      "Speed: 4.3ms preprocess, 132.5ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5605361\n",
      "recognized_text:  AO\n",
      "ocr_conf:  0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/1662\n",
      "file_name: CarLongPlateGen810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen810.jpg: 416x640 1 plate, 125.5ms\n",
      "Speed: 4.5ms preprocess, 125.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.22631\n",
      "recognized_text:  GIA2KEAT)\n",
      "ocr_conf:  0.385\n",
      "998/1662\n",
      "file_name: CarLongPlateGen811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen811.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 10.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.558456\n",
      "recognized_text:  51A-9H1.611\n",
      "ocr_conf:  0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen820.jpg: 416x640 1 plate, 132.0ms\n",
      "Speed: 4.6ms preprocess, 132.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999/1662\n",
      "file_name: CarLongPlateGen820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.127888\n",
      "recognized_text:  EIA77579\n",
      "ocr_conf:  0.749\n",
      "1000/1662\n",
      "file_name: CarLongPlateGen821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen821.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.9ms preprocess, 123.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.098076\n",
      "recognized_text:  1F-44614\n",
      "ocr_conf:  0.693\n",
      "1001/1662\n",
      "file_name: CarLongPlateGen830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen830.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3722587\n",
      "recognized_text:  61F-59881\n",
      "ocr_conf:  0.809\n",
      "1002/1662\n",
      "file_name: CarLongPlateGen831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen831.jpg: 416x640 1 plate, 126.4ms\n",
      "Speed: 4.6ms preprocess, 126.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.215888\n",
      "recognized_text:  FIrsteA\n",
      "ocr_conf:  0.364\n",
      "1003/1662\n",
      "file_name: CarLongPlateGen840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen840.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8313024\n",
      "recognized_text:  30F-000.90\n",
      "ocr_conf:  0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004/1662\n",
      "file_name: CarLongPlateGen841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen841.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.6ms preprocess, 122.1ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4587247\n",
      "recognized_text:  e\n",
      "ocr_conf:  0.304\n",
      "1005/1662\n",
      "file_name: CarLongPlateGen850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen850.jpg: 416x640 1 plate, 129.3ms\n",
      "Speed: 4.4ms preprocess, 129.3ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9971988\n",
      "recognized_text:  S1F-35613\n",
      "ocr_conf:  0.61\n",
      "1006/1662\n",
      "file_name: CarLongPlateGen851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen851.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.4ms preprocess, 122.7ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3516498\n",
      "recognized_text:  S1A72110\n",
      "ocr_conf:  0.701\n",
      "1007/1662\n",
      "file_name: CarLongPlateGen860.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen860.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.7ms preprocess, 125.0ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.423088\n",
      "recognized_text:  H161332\n",
      "ocr_conf:  0.754\n",
      "1008/1662\n",
      "file_name: CarLongPlateGen861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen861.jpg: 416x640 1 plate, 131.8ms\n",
      "Speed: 4.8ms preprocess, 131.8ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7537422\n",
      "recognized_text:  51F-155.85\n",
      "ocr_conf:  0.874\n",
      "1009/1662\n",
      "file_name: CarLongPlateGen870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen870.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.007904\n",
      "recognized_text:  F-05877\n",
      "ocr_conf:  0.676\n",
      "1010/1662\n",
      "file_name: CarLongPlateGen871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen871.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.9ms preprocess, 123.9ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.143885\n",
      "recognized_text:  P520\n",
      "ocr_conf:  0.27\n",
      "1011/1662\n",
      "file_name: CarLongPlateGen880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen880.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.1ms preprocess, 123.6ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9125555\n",
      "recognized_text:  SIF-ZI2E5\n",
      "ocr_conf:  0.529\n",
      "1012/1662\n",
      "file_name: CarLongPlateGen881.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen881.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.8ms preprocess, 122.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9832778\n",
      "recognized_text:  51F-692.59\n",
      "ocr_conf:  0.925\n",
      "1013/1662\n",
      "file_name: CarLongPlateGen890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen890.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7394502\n",
      "recognized_text:  R12E763\n",
      "ocr_conf:  0.422\n",
      "1014/1662\n",
      "file_name: CarLongPlateGen891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen891.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.5336823\n",
      "recognized_text:  516481.64\n",
      "ocr_conf:  0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015/1662\n",
      "file_name: CarLongPlateGen90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen90.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.4ms preprocess, 123.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.906366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen900.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.2ms preprocess, 122.9ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  A-89714\n",
      "ocr_conf:  0.871\n",
      "1016/1662\n",
      "file_name: CarLongPlateGen900.jpg\n",
      "aspect_ratio: 3.856433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen901.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  N1F-21259\n",
      "ocr_conf:  0.715\n",
      "1017/1662\n",
      "file_name: CarLongPlateGen901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3727205\n",
      "recognized_text:  51F-278.09\n",
      "ocr_conf:  0.874\n",
      "1018/1662\n",
      "file_name: CarLongPlateGen91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen91.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.4ms preprocess, 124.9ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9253907\n",
      "recognized_text:  EIR\n",
      "ocr_conf:  0.218\n",
      "1019/1662\n",
      "file_name: CarLongPlateGen910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen910.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1147642\n",
      "recognized_text:  JRULOSE\n",
      "ocr_conf:  0.452\n",
      "1020/1662\n",
      "file_name: CarLongPlateGen911.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen911.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.673887\n",
      "recognized_text:  KOA-35481\n",
      "ocr_conf:  0.749\n",
      "1021/1662\n",
      "file_name: CarLongPlateGen920.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen920.jpg: 416x640 1 plate, 127.3ms\n",
      "Speed: 4.4ms preprocess, 127.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8881803\n",
      "recognized_text:  GIFSIT\n",
      "ocr_conf:  0.481\n",
      "1022/1662\n",
      "file_name: CarLongPlateGen921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen921.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.3ms preprocess, 123.9ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1576216\n",
      "recognized_text:  E\n",
      "ocr_conf:  0.142\n",
      "1023/1662\n",
      "file_name: CarLongPlateGen930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen930.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8829212\n",
      "recognized_text:  51F-079.73\n",
      "ocr_conf:  0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1662\n",
      "file_name: CarLongPlateGen931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen931.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7160332\n",
      "recognized_text:  079.73\n",
      "ocr_conf:  0.859\n",
      "1025/1662\n",
      "file_name: CarLongPlateGen940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen940.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5302956\n",
      "recognized_text:  51A-691.72\n",
      "ocr_conf:  0.895\n",
      "1026/1662\n",
      "file_name: CarLongPlateGen941.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen941.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 5.0ms preprocess, 124.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.8454597\n",
      "recognized_text:  (SA22H\n",
      "ocr_conf:  0.571\n",
      "1027/1662\n",
      "file_name: CarLongPlateGen950.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen950.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7784393\n",
      "recognized_text:  61A-961.4\n",
      "ocr_conf:  0.636\n",
      "1028/1662\n",
      "file_name: CarLongPlateGen951.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen951.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.3ms preprocess, 124.8ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.287676\n",
      "recognized_text:  A-9014\n",
      "ocr_conf:  0.566\n",
      "1029/1662\n",
      "file_name: CarLongPlateGen960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen960.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7617297\n",
      "recognized_text:  116569\n",
      "ocr_conf:  0.688\n",
      "1030/1662\n",
      "file_name: CarLongPlateGen961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen961.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5012329\n",
      "recognized_text:  1F-155.85\n",
      "ocr_conf:  0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen970.jpg: 416x640 1 plate, 135.8ms\n",
      "Speed: 4.5ms preprocess, 135.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031/1662\n",
      "file_name: CarLongPlateGen970.jpg\n",
      "aspect_ratio: 4.280274\n",
      "recognized_text:  61F-590.11\n",
      "ocr_conf:  0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen971.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.8ms preprocess, 124.3ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1662\n",
      "file_name: CarLongPlateGen971.jpg\n",
      "aspect_ratio: 3.0763278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen980.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51F-590.11\n",
      "ocr_conf:  0.93\n",
      "1033/1662\n",
      "file_name: CarLongPlateGen980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0717604\n",
      "recognized_text:  51F-69259\n",
      "ocr_conf:  0.879\n",
      "1034/1662\n",
      "file_name: CarLongPlateGen981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen981.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8137023\n",
      "recognized_text:  51F-69258\n",
      "ocr_conf:  0.778\n",
      "1035/1662\n",
      "file_name: CarLongPlateGen990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen990.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.206075\n",
      "recognized_text:  F-9848\n",
      "ocr_conf:  0.685\n",
      "1036/1662\n",
      "file_name: CarLongPlateGen991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/CarLongPlateGen991.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.7932372\n",
      "recognized_text:  61F-587.14\n",
      "ocr_conf:  0.761\n",
      "1037/1662\n",
      "file_name: cropngoaigiao0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropngoaigiao0.jpg: 384x640 1 plate, 167.7ms\n",
      "Speed: 4.1ms preprocess, 167.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.885166\n",
      "recognized_text:  -41-291-NG-01\n",
      "ocr_conf:  0.908\n",
      "1038/1662\n",
      "file_name: cropngoaigiao1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropngoaigiao1.jpg: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.3ms preprocess, 163.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.9511466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropngoaigiao10.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.1ms preprocess, 124.6ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  80\n",
      "ocr_conf:  0.33\n",
      "1039/1662\n",
      "file_name: cropngoaigiao10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1934762\n",
      "recognized_text:  51NG166-33\n",
      "ocr_conf:  0.902\n",
      "1040/1662\n",
      "file_name: cropngoaigiao11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropngoaigiao11.jpg: 416x640 1 plate, 126.5ms\n",
      "Speed: 4.6ms preprocess, 126.5ms inference, 14.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.583849\n",
      "recognized_text:  M13\n",
      "ocr_conf:  0.468\n",
      "1041/1662\n",
      "file_name: cropquandoi0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi0.jpg: 480x640 1 plate, 135.0ms\n",
      "Speed: 5.0ms preprocess, 135.0ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0645204\n",
      "recognized_text:  OH55-12\n",
      "ocr_conf:  0.945\n",
      "1042/1662\n",
      "file_name: cropquandoi1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi1.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.3ms preprocess, 128.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2608252\n",
      "recognized_text:  TH-66-72\n",
      "ocr_conf:  0.901\n",
      "1043/1662\n",
      "file_name: cropquandoi10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi10.jpg: 448x640 1 plate, 131.5ms\n",
      "Speed: 4.7ms preprocess, 131.5ms inference, 14.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1400223\n",
      "recognized_text:  FM-27-01\n",
      "ocr_conf:  0.919\n",
      "1044/1662\n",
      "file_name: cropquandoi100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi100.jpg: 448x640 1 plate, 127.9ms\n",
      "Speed: 8.8ms preprocess, 127.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.069466\n",
      "recognized_text:  CP-23-19\n",
      "ocr_conf:  0.982\n",
      "1045/1662\n",
      "file_name: cropquandoi101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi101.jpg: 416x640 2 plates, 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 14.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3041453\n",
      "recognized_text:  BH-52-62\n",
      "ocr_conf:  0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1662\n",
      "file_name: cropquandoi11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi11.jpg: 384x640 1 plate, 165.0ms\n",
      "Speed: 3.8ms preprocess, 165.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9632345\n",
      "recognized_text:  1\n",
      "ocr_conf:  0.348\n",
      "1047/1662\n",
      "file_name: cropquandoi110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi110.jpg: 448x640 1 plate, 132.3ms\n",
      "Speed: 5.5ms preprocess, 132.3ms inference, 6.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.78897387\n",
      "recognized_text:  nuUn\n",
      "ocr_conf:  0.385\n",
      "1048/1662\n",
      "file_name: cropquandoi21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi21.jpg: 416x640 1 plate, 130.0ms\n",
      "Speed: 4.5ms preprocess, 130.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6496098\n",
      "recognized_text:  TH-31-69\n",
      "ocr_conf:  0.931\n",
      "1049/1662\n",
      "file_name: cropquandoi30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi30.jpg: 480x640 1 plate, 135.0ms\n",
      "Speed: 4.8ms preprocess, 135.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8508112\n",
      "recognized_text:  KT.52.31MP-3331\n",
      "ocr_conf:  0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1662\n",
      "file_name: cropquandoi31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi31.jpg: 448x640 1 plate, 136.0ms\n",
      "Speed: 5.5ms preprocess, 136.0ms inference, 6.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2728815\n",
      "recognized_text:  OA-55-91\n",
      "ocr_conf:  0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051/1662\n",
      "file_name: cropquandoi40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi40.jpg: 448x640 3 plates, 137.4ms\n",
      "Speed: 9.3ms preprocess, 137.4ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1508006\n",
      "recognized_text:  C4.27.331N-21-3\n",
      "ocr_conf:  0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1662\n",
      "file_name: cropquandoi41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi41.jpg: 448x640 1 plate, 129.7ms\n",
      "Speed: 10.3ms preprocess, 129.7ms inference, 13.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8320885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  KP-41-60\n",
      "ocr_conf:  0.946\n",
      "1053/1662\n",
      "file_name: cropquandoi50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi50.jpg: 384x640 1 plate, 176.6ms\n",
      "Speed: 4.8ms preprocess, 176.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.137168\n",
      "recognized_text:  XA-8380\n",
      "ocr_conf:  0.807\n",
      "1054/1662\n",
      "file_name: cropquandoi60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi60.jpg: 448x640 1 plate, 130.6ms\n",
      "Speed: 4.9ms preprocess, 130.6ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8673823\n",
      "recognized_text:  TK-27-01\n",
      "ocr_conf:  0.724\n",
      "1055/1662\n",
      "file_name: cropquandoi61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi61.jpg: 384x640 1 plate, 135.3ms\n",
      "Speed: 9.1ms preprocess, 135.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5926187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi71.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  D.CA\n",
      "ocr_conf:  0.433\n",
      "1056/1662\n",
      "file_name: cropquandoi71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.0150857\n",
      "recognized_text:  TH-52-73\n",
      "ocr_conf:  0.951\n",
      "1057/1662\n",
      "file_name: cropquandoi80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi80.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.7ms preprocess, 128.9ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0047773\n",
      "recognized_text:  BH53-90\n",
      "ocr_conf:  0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi81.jpg: 448x640 4 plates, 130.9ms\n",
      "Speed: 4.7ms preprocess, 130.9ms inference, 5.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058/1662\n",
      "file_name: cropquandoi81.jpg\n",
      "aspect_ratio: 1.3454491\n",
      "recognized_text:  ed R\n",
      "ocr_conf:  0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1662\n",
      "file_name: cropquandoi90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi90.jpg: 448x640 1 plate, 136.1ms\n",
      "Speed: 8.2ms preprocess, 136.1ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6130793\n",
      "recognized_text:  B-54-23\n",
      "ocr_conf:  0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060/1662\n",
      "file_name: cropquandoi91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/cropquandoi91.jpg: 448x640 2 plates, 128.6ms\n",
      "Speed: 10.2ms preprocess, 128.6ms inference, 8.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2128842\n",
      "recognized_text:  KC-59-70\n",
      "ocr_conf:  0.759\n",
      "1061/1662\n",
      "file_name: ngoaigiao0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/ngoaigiao0.jpg: 384x640 2 plates, 132.2ms\n",
      "Speed: 4.1ms preprocess, 132.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4891696\n",
      "recognized_text:  41-291-NG-01\n",
      "ocr_conf:  0.925\n",
      "1062/1662\n",
      "file_name: ngoaigiao1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/ngoaigiao1.jpg: 384x640 3 plates, 163.7ms\n",
      "Speed: 4.8ms preprocess, 163.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4334724\n",
      "recognized_text:  10.-N-631-37\n",
      "ocr_conf:  0.599\n",
      "1063/1662\n",
      "file_name: ngoaigiao10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/ngoaigiao10.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.4ms preprocess, 125.8ms inference, 15.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4388479\n",
      "recognized_text:  166-33\n",
      "ocr_conf:  0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064/1662\n",
      "file_name: ngoaigiao11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/ngoaigiao11.jpg: 416x640 2 plates, 124.2ms\n",
      "Speed: 4.8ms preprocess, 124.2ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5664136\n",
      "recognized_text:  80-NG-376-14\n",
      "ocr_conf:  0.862\n",
      "1065/1662\n",
      "file_name: quandoi0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi0.jpg: 480x640 1 plate, 135.8ms\n",
      "Speed: 6.0ms preprocess, 135.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1724814\n",
      "recognized_text:  OH55-12\n",
      "ocr_conf:  0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1662\n",
      "file_name: quandoi1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi1.jpg: 416x640 1 plate, 127.6ms\n",
      "Speed: 4.6ms preprocess, 127.6ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.827747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  TH-66-72\n",
      "ocr_conf:  0.937\n",
      "1067/1662\n",
      "file_name: quandoi10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi10.jpg: 448x640 1 plate, 136.4ms\n",
      "Speed: 5.1ms preprocess, 136.4ms inference, 15.2ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7926855\n",
      "recognized_text:  FM-27-01\n",
      "ocr_conf:  0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi100.jpg: 448x640 1 plate, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 12.8ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1662\n",
      "file_name: quandoi100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8896635\n",
      "recognized_text:  CD.2zCP-23-19\n",
      "ocr_conf:  0.696\n",
      "1069/1662\n",
      "file_name: quandoi101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi101.jpg: 416x640 2 plates, 125.8ms\n",
      "Speed: 4.7ms preprocess, 125.8ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2184377\n",
      "recognized_text:  BH-52-62\n",
      "ocr_conf:  0.897\n",
      "1070/1662\n",
      "file_name: quandoi11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi11.jpg: 384x640 1 plate, 162.7ms\n",
      "Speed: 4.0ms preprocess, 162.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1268632\n",
      "recognized_text:  0B-17-50\n",
      "ocr_conf:  0.863\n",
      "1071/1662\n",
      "file_name: quandoi110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi110.jpg: 448x640 1 plate, 132.0ms\n",
      "Speed: 5.7ms preprocess, 132.0ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.9710511\n",
      "recognized_text:  purndn-58-07\n",
      "ocr_conf:  0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072/1662\n",
      "file_name: quandoi20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi20.jpg: 480x640 2 plates, 153.0ms\n",
      "Speed: 7.7ms preprocess, 153.0ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7089556\n",
      "recognized_text:  MI0\n",
      "ocr_conf:  0.367\n",
      "1073/1662\n",
      "file_name: quandoi21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi21.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.3ms preprocess, 128.9ms inference, 15.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5587034\n",
      "recognized_text:  TH-31-69\n",
      "ocr_conf:  0.951\n",
      "1074/1662\n",
      "file_name: quandoi30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi30.jpg: 480x640 1 plate, 143.6ms\n",
      "Speed: 5.2ms preprocess, 143.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1711864\n",
      "recognized_text:  KT-53-31\n",
      "ocr_conf:  0.951\n",
      "1075/1662\n",
      "file_name: quandoi31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi31.jpg: 448x640 1 plate, 129.2ms\n",
      "Speed: 4.9ms preprocess, 129.2ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5410311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  OA-55-91\n",
      "ocr_conf:  0.934\n",
      "1076/1662\n",
      "file_name: quandoi40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi40.jpg: 448x640 3 plates, 128.5ms\n",
      "Speed: 5.5ms preprocess, 128.5ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.142631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  MEe OUANe\n",
      "ocr_conf:  0.168\n",
      "1077/1662\n",
      "file_name: quandoi41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi41.jpg: 448x640 1 plate, 128.9ms\n",
      "Speed: 5.0ms preprocess, 128.9ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5999875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  KP-41-60\n",
      "ocr_conf:  0.948\n",
      "1078/1662\n",
      "file_name: quandoi50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi50.jpg: 384x640 1 plate, 166.5ms\n",
      "Speed: 4.7ms preprocess, 166.5ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6725054\n",
      "recognized_text:  KA-83-80\n",
      "ocr_conf:  0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi51.jpg: 480x640 1 plate, 134.9ms\n",
      "Speed: 7.7ms preprocess, 134.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1662\n",
      "file_name: quandoi51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.177112\n",
      "recognized_text:  TM23-66\n",
      "ocr_conf:  0.945\n",
      "1080/1662\n",
      "file_name: quandoi60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi60.jpg: 448x640 1 plate, 139.9ms\n",
      "Speed: 4.8ms preprocess, 139.9ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6808493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  TN-27-01\n",
      "ocr_conf:  0.908\n",
      "1081/1662\n",
      "file_name: quandoi61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi61.jpg: 384x640 1 plate, 152.0ms\n",
      "Speed: 4.1ms preprocess, 152.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6508503\n",
      "recognized_text:  K9-50-03\n",
      "ocr_conf:  0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082/1662\n",
      "file_name: quandoi70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi70.jpg: 640x608 1 plate, 165.2ms\n",
      "Speed: 5.6ms preprocess, 165.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 608)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2554426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  OA-52-32\n",
      "ocr_conf:  0.874\n",
      "1083/1662\n",
      "file_name: quandoi71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi71.jpg: 416x640 1 plate, 133.2ms\n",
      "Speed: 4.6ms preprocess, 133.2ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5672498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  TH-52-73\n",
      "ocr_conf:  0.959\n",
      "1084/1662\n",
      "file_name: quandoi80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi80.jpg: 416x640 1 plate, 126.7ms\n",
      "Speed: 7.9ms preprocess, 126.7ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1947832\n",
      "recognized_text:  BH53-90\n",
      "ocr_conf:  0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085/1662\n",
      "file_name: quandoi81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi81.jpg: 448x640 4 plates, 131.4ms\n",
      "Speed: 4.7ms preprocess, 131.4ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3012285\n",
      "recognized_text:  D R\n",
      "ocr_conf:  0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi90.jpg: 448x640 2 plates, 128.7ms\n",
      "Speed: 3.9ms preprocess, 128.7ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086/1662\n",
      "file_name: quandoi90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3544647\n",
      "recognized_text:  SE\n",
      "ocr_conf:  0.487\n",
      "1087/1662\n",
      "file_name: quandoi91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/quandoi91.jpg: 448x640 4 plates, 131.6ms\n",
      "Speed: 6.2ms preprocess, 131.6ms inference, 8.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6748612\n",
      "recognized_text:  KC-59:70\n",
      "ocr_conf:  0.739\n",
      "1088/1662\n",
      "file_name: rotatengoaigiao0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatengoaigiao0.jpg: 384x640 2 plates, 154.2ms\n",
      "Speed: 4.4ms preprocess, 154.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.077496\n",
      "recognized_text:  41-291-NG-01\n",
      "ocr_conf:  0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1662\n",
      "file_name: rotatengoaigiao1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatengoaigiao1.jpg: 384x640 2 plates, 140.5ms\n",
      "Speed: 4.3ms preprocess, 140.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3813593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  00-NG-631-3\n",
      "ocr_conf:  0.699\n",
      "1090/1662\n",
      "file_name: rotatengoaigiao10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatengoaigiao10.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.4ms preprocess, 131.0ms inference, 12.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4447492\n",
      "recognized_text:  166-33\n",
      "ocr_conf:  0.893\n",
      "1091/1662\n",
      "file_name: rotatengoaigiao11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatengoaigiao11.jpg: 416x640 2 plates, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2381568\n",
      "recognized_text:  29A-439.14\n",
      "ocr_conf:  0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092/1662\n",
      "file_name: rotatequandoi0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi0.jpg: 480x640 1 plate, 143.6ms\n",
      "Speed: 5.4ms preprocess, 143.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0081271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  STUR03-12\n",
      "ocr_conf:  0.729\n",
      "1093/1662\n",
      "file_name: rotatequandoi1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi1.jpg: 416x640 1 plate, 127.3ms\n",
      "Speed: 4.6ms preprocess, 127.3ms inference, 13.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.665526\n",
      "recognized_text:  2TR-O\n",
      "ocr_conf:  0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1662\n",
      "file_name: rotatequandoi10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi10.jpg: 448x640 1 plate, 142.4ms\n",
      "Speed: 4.7ms preprocess, 142.4ms inference, 16.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2205908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  TM-27-01\n",
      "ocr_conf:  0.854\n",
      "1095/1662\n",
      "file_name: rotatequandoi100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi100.jpg: 448x640 1 plate, 128.7ms\n",
      "Speed: 11.2ms preprocess, 128.7ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.826011\n",
      "recognized_text:  Cp.2710CP-23-19\n",
      "ocr_conf:  0.692\n",
      "1096/1662\n",
      "file_name: rotatequandoi101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi101.jpg: 416x640 2 plates, 126.3ms\n",
      "Speed: 5.1ms preprocess, 126.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7654998\n",
      "recognized_text:  BH.521032-62\n",
      "ocr_conf:  0.713\n",
      "1097/1662\n",
      "file_name: rotatequandoi11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi11.jpg: 384x640 1 plate, 146.5ms\n",
      "Speed: 4.2ms preprocess, 146.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4543712\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "1098/1662\n",
      "file_name: rotatequandoi110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi110.jpg: 448x640 1 plate, 132.5ms\n",
      "Speed: 5.3ms preprocess, 132.5ms inference, 15.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5756959\n",
      "recognized_text:  OH.500-r-38-07\n",
      "ocr_conf:  0.61\n",
      "1099/1662\n",
      "file_name: rotatequandoi20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi20.jpg: 480x640 2 plates, 136.0ms\n",
      "Speed: 4.6ms preprocess, 136.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2906151\n",
      "recognized_text:  RO1\n",
      "ocr_conf:  0.242\n",
      "1100/1662\n",
      "file_name: rotatequandoi21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi21.jpg: 416x640 1 plate, 132.9ms\n",
      "Speed: 4.4ms preprocess, 132.9ms inference, 13.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7296555\n",
      "recognized_text:  TH-31-69\n",
      "ocr_conf:  0.935\n",
      "1101/1662\n",
      "file_name: rotatequandoi30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi30.jpg: 480x640 1 plate, 136.3ms\n",
      "Speed: 7.7ms preprocess, 136.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6272094\n",
      "recognized_text:  KT.52-33-31\n",
      "ocr_conf:  0.711\n",
      "1102/1662\n",
      "file_name: rotatequandoi31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi31.jpg: 448x640 1 plate, 130.4ms\n",
      "Speed: 5.4ms preprocess, 130.4ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.685718\n",
      "recognized_text:  55-91OA-53\n",
      "ocr_conf:  0.731\n",
      "1103/1662\n",
      "file_name: rotatequandoi40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi40.jpg: 448x640 4 plates, 128.6ms\n",
      "Speed: 5.1ms preprocess, 128.6ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3288993\n",
      "recognized_text:  27.33T-2100\n",
      "ocr_conf:  0.6\n",
      "1104/1662\n",
      "file_name: rotatequandoi41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi41.jpg: 448x640 1 plate, 146.9ms\n",
      "Speed: 8.4ms preprocess, 146.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4254073\n",
      "recognized_text:  -60KP-4\n",
      "ocr_conf:  0.732\n",
      "1105/1662\n",
      "file_name: rotatequandoi50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi50.jpg: 384x640 1 plate, 128.7ms\n",
      "Speed: 6.5ms preprocess, 128.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4414593\n",
      "recognized_text:  2.80XA-835\n",
      "ocr_conf:  0.745\n",
      "1106/1662\n",
      "file_name: rotatequandoi51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi51.jpg: 480x640 1 plate, 135.4ms\n",
      "Speed: 4.8ms preprocess, 135.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0133556\n",
      "recognized_text:  STMC23-66\n",
      "ocr_conf:  0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi60.jpg: 448x640 1 plate, 131.8ms\n",
      "Speed: 4.5ms preprocess, 131.8ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107/1662\n",
      "file_name: rotatequandoi60.jpg\n",
      "aspect_ratio: 1.799964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  T5R27-01\n",
      "ocr_conf:  0.469\n",
      "1108/1662\n",
      "file_name: rotatequandoi61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi61.jpg: 384x640 1 plate, 176.8ms\n",
      "Speed: 4.7ms preprocess, 176.8ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7208198\n",
      "recognized_text:  P\n",
      "ocr_conf:  0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109/1662\n",
      "file_name: rotatequandoi70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi70.jpg: 640x608 1 plate, 177.1ms\n",
      "Speed: 6.5ms preprocess, 177.1ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 608)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3096247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  0A-52-32\n",
      "ocr_conf:  0.84\n",
      "1110/1662\n",
      "file_name: rotatequandoi71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi71.jpg: 416x640 1 plate, 130.4ms\n",
      "Speed: 4.8ms preprocess, 130.4ms inference, 14.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.177224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  TH-52-73\n",
      "ocr_conf:  0.886\n",
      "1111/1662\n",
      "file_name: rotatequandoi80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi80.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 7.7ms preprocess, 123.5ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1204875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  853-90\n",
      "ocr_conf:  0.857\n",
      "1112/1662\n",
      "file_name: rotatequandoi81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi81.jpg: 448x640 4 plates, 130.9ms\n",
      "Speed: 4.5ms preprocess, 130.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3177822\n",
      "recognized_text:  Bo\n",
      "ocr_conf:  0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi90.jpg: 448x640 1 plate, 134.8ms\n",
      "Speed: 3.8ms preprocess, 134.8ms inference, 15.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113/1662\n",
      "file_name: rotatequandoi90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4640929\n",
      "recognized_text:  B2\n",
      "ocr_conf:  0.457\n",
      "1114/1662\n",
      "file_name: rotatequandoi91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/rotatequandoi91.jpg: 448x640 2 plates, 128.9ms\n",
      "Speed: 5.1ms preprocess, 128.9ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7783506\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "1115/1662\n",
      "file_name: xemay0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay0.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.5ms preprocess, 124.9ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2263229\n",
      "recognized_text:  59-P1664.80\n",
      "ocr_conf:  0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1662\n",
      "file_name: xemay1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1.jpg: 416x640 1 plate, 130.5ms\n",
      "Speed: 4.7ms preprocess, 130.5ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1452668\n",
      "recognized_text:  59-E1215.00\n",
      "ocr_conf:  0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117/1662\n",
      "file_name: xemay10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay10.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2598041\n",
      "recognized_text:  59-H1549.86\n",
      "ocr_conf:  0.944\n",
      "1118/1662\n",
      "file_name: xemay100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay100.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.4ms preprocess, 122.7ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.225148\n",
      "recognized_text:  59-U1598.97\n",
      "ocr_conf:  0.875\n",
      "1119/1662\n",
      "file_name: xemay1000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1000.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1621058\n",
      "recognized_text:  59-C2316.01\n",
      "ocr_conf:  0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120/1662\n",
      "file_name: xemay1001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1001.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 8.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.193034\n",
      "recognized_text:  62-H57108\n",
      "ocr_conf:  0.908\n",
      "1121/1662\n",
      "file_name: xemay101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay101.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.4ms preprocess, 122.1ms inference, 13.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0879912\n",
      "recognized_text:  63-Y10200\n",
      "ocr_conf:  0.886\n",
      "1122/1662\n",
      "file_name: xemay1010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1010.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 4.3ms preprocess, 122.4ms inference, 9.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.167855\n",
      "recognized_text:  59-S1098.41\n",
      "ocr_conf:  0.897\n",
      "1123/1662\n",
      "file_name: xemay1011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1011.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2204033\n",
      "recognized_text:  59-S2470.61\n",
      "ocr_conf:  0.911\n",
      "1124/1662\n",
      "file_name: xemay1020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1020.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1650387\n",
      "recognized_text:  55-x86970\n",
      "ocr_conf:  0.869\n",
      "1125/1662\n",
      "file_name: xemay1021.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1021.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.6ms preprocess, 124.1ms inference, 9.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2144458\n",
      "recognized_text:  67-81696.60\n",
      "ocr_conf:  0.852\n",
      "1126/1662\n",
      "file_name: xemay1030.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1030.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.7ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.144256\n",
      "recognized_text:  54-R30018\n",
      "ocr_conf:  0.967\n",
      "1127/1662\n",
      "file_name: xemay1031.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1031.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.1ms preprocess, 123.2ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1946046\n",
      "recognized_text:  59-01887.28\n",
      "ocr_conf:  0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1040.jpg: 416x640 1 plate, 123.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128/1662\n",
      "file_name: xemay1040.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.4ms preprocess, 123.4ms inference, 10.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1428301\n",
      "recognized_text:  77-F79919\n",
      "ocr_conf:  0.924\n",
      "1129/1662\n",
      "file_name: xemay1041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1041.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.7ms preprocess, 124.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1245506\n",
      "recognized_text:  54-U54316\n",
      "ocr_conf:  0.922\n",
      "1130/1662\n",
      "file_name: xemay1050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1050.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1764557\n",
      "recognized_text:  59-L1165.11\n",
      "ocr_conf:  0.884\n",
      "1131/1662\n",
      "file_name: xemay1051.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1051.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.7ms preprocess, 123.7ms inference, 16.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.179591\n",
      "recognized_text:  53-211759\n",
      "ocr_conf:  0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1060.jpg: 416x640 1 plate, 125.9ms\n",
      "Speed: 5.4ms preprocess, 125.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132/1662\n",
      "file_name: xemay1060.jpg\n",
      "aspect_ratio: 1.2343745\n",
      "recognized_text:  61-G1043.05\n",
      "ocr_conf:  0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133/1662\n",
      "file_name: xemay1061.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1061.jpg: 416x640 1 plate, 183.8ms\n",
      "Speed: 4.7ms preprocess, 183.8ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1896766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  78-C1194.55\n",
      "ocr_conf:  0.905\n",
      "1134/1662\n",
      "file_name: xemay1070.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1070.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.8ms preprocess, 124.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1597453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-C2321.49\n",
      "ocr_conf:  0.945\n",
      "1135/1662\n",
      "file_name: xemay1071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1071.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.7ms preprocess, 122.9ms inference, 11.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1913228\n",
      "recognized_text:  01-G1006.65\n",
      "ocr_conf:  0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136/1662\n",
      "file_name: xemay1080.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1080.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.7ms preprocess, 123.7ms inference, 15.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1393796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P1717.56\n",
      "ocr_conf:  0.947\n",
      "1137/1662\n",
      "file_name: xemay1081.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1081.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.6ms preprocess, 126.1ms inference, 16.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1345682\n",
      "recognized_text:  54-X37676\n",
      "ocr_conf:  0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1090.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1138/1662\n",
      "file_name: xemay1090.jpg\n",
      "aspect_ratio: 1.164787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1091.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 14.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-C2300.79\n",
      "ocr_conf:  0.942\n",
      "1139/1662\n",
      "file_name: xemay1091.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1419141\n",
      "recognized_text:  69-C1007.88\n",
      "ocr_conf:  0.863\n",
      "1140/1662\n",
      "file_name: xemay11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay11.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.2ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.186459\n",
      "recognized_text:  59-F1138.60\n",
      "ocr_conf:  0.894\n",
      "1141/1662\n",
      "file_name: xemay110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay110.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2457078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-V1833.57\n",
      "ocr_conf:  0.911\n",
      "1142/1662\n",
      "file_name: xemay1100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1100.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.1ms preprocess, 123.4ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1489671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  47-D1187.16\n",
      "ocr_conf:  0.887\n",
      "1143/1662\n",
      "file_name: xemay1101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1101.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 14.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1564773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-V2486.12\n",
      "ocr_conf:  0.927\n",
      "1144/1662\n",
      "file_name: xemay111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay111.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.6ms preprocess, 126.1ms inference, 16.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1742966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60-UZ3465\n",
      "ocr_conf:  0.897\n",
      "1145/1662\n",
      "file_name: xemay1110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1110.jpg: 416x640 1 plate, 127.0ms\n",
      "Speed: 4.6ms preprocess, 127.0ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.171316\n",
      "recognized_text:  83-P1996.96\n",
      "ocr_conf:  0.918\n",
      "1146/1662\n",
      "file_name: xemay1111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1111.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 6.3ms preprocess, 121.8ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2353262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59K1440.76\n",
      "ocr_conf:  0.913\n",
      "1147/1662\n",
      "file_name: xemay1120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1120.jpg: 416x640 1 plate, 131.4ms\n",
      "Speed: 5.0ms preprocess, 131.4ms inference, 16.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1589164\n",
      "recognized_text:  60-F2045.65\n",
      "ocr_conf:  0.923\n",
      "1148/1662\n",
      "file_name: xemay1121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1121.jpg: 416x640 1 plate, 128.0ms\n",
      "Speed: 4.5ms preprocess, 128.0ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2280256\n",
      "recognized_text:  59-F1140.64\n",
      "ocr_conf:  0.892\n",
      "1149/1662\n",
      "file_name: xemay1130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1130.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1318914\n",
      "recognized_text:  71-B2726.34\n",
      "ocr_conf:  0.932\n",
      "1150/1662\n",
      "file_name: xemay1131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1131.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 5.0ms preprocess, 124.1ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1969249\n",
      "recognized_text:  59-L1387.65\n",
      "ocr_conf:  0.875\n",
      "1151/1662\n",
      "file_name: xemay1140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1140.jpg: 416x640 1 plate, 126.3ms\n",
      "Speed: 4.3ms preprocess, 126.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1800157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1141.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 5.1ms preprocess, 122.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S13034\n",
      "ocr_conf:  0.919\n",
      "1152/1662\n",
      "file_name: xemay1141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2062987\n",
      "recognized_text:  72-K1085.50\n",
      "ocr_conf:  0.932\n",
      "1153/1662\n",
      "file_name: xemay1150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1150.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.066026\n",
      "recognized_text:  54-S46869.\n",
      "ocr_conf:  0.894\n",
      "1154/1662\n",
      "file_name: xemay1151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1151.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1928898\n",
      "recognized_text:  59-U1746.75\n",
      "ocr_conf:  0.919\n",
      "1155/1662\n",
      "file_name: xemay1160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1160.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1617515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1161.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  37-H1104.01\n",
      "ocr_conf:  0.911\n",
      "1156/1662\n",
      "file_name: xemay1161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2278333\n",
      "recognized_text:  59-X1215.94\n",
      "ocr_conf:  0.846\n",
      "1157/1662\n",
      "file_name: xemay1170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1170.jpg: 416x640 1 plate, 125.7ms\n",
      "Speed: 4.7ms preprocess, 125.7ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1534448\n",
      "recognized_text:  59-T1744.43\n",
      "ocr_conf:  0.937\n",
      "1158/1662\n",
      "file_name: xemay1171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1171.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1573513\n",
      "recognized_text:  55-P23999\n",
      "ocr_conf:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159/1662\n",
      "file_name: xemay1180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1180.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 14.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1393785\n",
      "recognized_text:  59-E1531.39\n",
      "ocr_conf:  0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160/1662\n",
      "file_name: xemay1181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1181.jpg: 416x640 1 plate, 133.2ms\n",
      "Speed: 4.4ms preprocess, 133.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2235054\n",
      "recognized_text:  591082.75\n",
      "ocr_conf:  0.91\n",
      "1161/1662\n",
      "file_name: xemay1190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1190.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.7ms preprocess, 122.1ms inference, 3.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1818262\n",
      "recognized_text:  81-B1379.63\n",
      "ocr_conf:  0.904\n",
      "1162/1662\n",
      "file_name: xemay1191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1191.jpg: 416x640 1 plate, 129.3ms\n",
      "Speed: 5.5ms preprocess, 129.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1075798\n",
      "recognized_text:  59-K1225.99\n",
      "ocr_conf:  0.935\n",
      "1163/1662\n",
      "file_name: xemay120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay120.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1746778\n",
      "recognized_text:  67-L1066.69\n",
      "ocr_conf:  0.905\n",
      "1164/1662\n",
      "file_name: xemay1200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1200.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.2ms preprocess, 122.9ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1584262\n",
      "recognized_text:  59-P2147.06\n",
      "ocr_conf:  0.951\n",
      "1165/1662\n",
      "file_name: xemay1201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1201.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.2ms preprocess, 122.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1538639\n",
      "recognized_text:  59-P2365.11\n",
      "ocr_conf:  0.916\n",
      "1166/1662\n",
      "file_name: xemay121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay121.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1531273\n",
      "recognized_text:  59-S2352.05\n",
      "ocr_conf:  0.905\n",
      "1167/1662\n",
      "file_name: xemay1210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1210.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1144857\n",
      "recognized_text:  59-E1183.10\n",
      "ocr_conf:  0.816\n",
      "1168/1662\n",
      "file_name: xemay1211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1211.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.7ms preprocess, 123.9ms inference, 16.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1760747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S50882\n",
      "ocr_conf:  0.888\n",
      "1169/1662\n",
      "file_name: xemay1220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1220.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.7ms preprocess, 124.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1602302\n",
      "recognized_text:  55-P87062\n",
      "ocr_conf:  0.933\n",
      "1170/1662\n",
      "file_name: xemay1221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1221.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.6ms preprocess, 124.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1502926\n",
      "recognized_text:  59-11239.77\n",
      "ocr_conf:  0.85\n",
      "1171/1662\n",
      "file_name: xemay1230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1230.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1625092\n",
      "recognized_text:  56-P16734\n",
      "ocr_conf:  0.923\n",
      "1172/1662\n",
      "file_name: xemay1231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1231.jpg: 416x640 1 plate, 128.9ms\n",
      "Speed: 4.9ms preprocess, 128.9ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2952738\n",
      "recognized_text:  59-T1830.13\n",
      "ocr_conf:  0.889\n",
      "1173/1662\n",
      "file_name: xemay1240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1240.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1814554\n",
      "recognized_text:  59-H1194.66\n",
      "ocr_conf:  0.937\n",
      "1174/1662\n",
      "file_name: xemay1241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1241.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.1ms preprocess, 123.4ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2022314\n",
      "recognized_text:  86-C1072.61\n",
      "ocr_conf:  0.899\n",
      "1175/1662\n",
      "file_name: xemay1250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1250.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1017734\n",
      "recognized_text:  59-M1470.96\n",
      "ocr_conf:  0.878\n",
      "1176/1662\n",
      "file_name: xemay1251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1251.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.208151\n",
      "recognized_text:  79-H58812\n",
      "ocr_conf:  0.937\n",
      "1177/1662\n",
      "file_name: xemay1260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1260.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1640481\n",
      "recognized_text:  59-C1559.80\n",
      "ocr_conf:  0.94\n",
      "1178/1662\n",
      "file_name: xemay1261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1261.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1616014\n",
      "recognized_text:  70-P15900\n",
      "ocr_conf:  0.949\n",
      "1179/1662\n",
      "file_name: xemay1270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1270.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1580479\n",
      "recognized_text:  59-11732.81\n",
      "ocr_conf:  0.933\n",
      "1180/1662\n",
      "file_name: xemay1271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1271.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2245247\n",
      "recognized_text:  70-X1059.63\n",
      "ocr_conf:  0.876\n",
      "1181/1662\n",
      "file_name: xemay1280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1280.jpg: 416x640 1 plate, 127.3ms\n",
      "Speed: 4.4ms preprocess, 127.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0841465\n",
      "recognized_text:  54-F39952\n",
      "ocr_conf:  0.944\n",
      "1182/1662\n",
      "file_name: xemay1281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1281.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 15.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2210472\n",
      "recognized_text:  59-F1085.01\n",
      "ocr_conf:  0.939\n",
      "1183/1662\n",
      "file_name: xemay1290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1290.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.3ms preprocess, 124.4ms inference, 11.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2209154\n",
      "recognized_text:  54-L59913\n",
      "ocr_conf:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1662\n",
      "file_name: xemay1291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1291.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 9.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0561181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay130.jpg: 416x640 1 plate, 125.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-F28259\n",
      "ocr_conf:  0.957\n",
      "1185/1662\n",
      "file_name: xemay130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.6ms preprocess, 125.7ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1624013\n",
      "recognized_text:  59-X1544.97\n",
      "ocr_conf:  0.919\n",
      "1186/1662\n",
      "file_name: xemay1300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1300.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1670551\n",
      "recognized_text:  54-04199\n",
      "ocr_conf:  0.879\n",
      "1187/1662\n",
      "file_name: xemay1301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1301.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.7ms preprocess, 124.1ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1709425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay131.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S58960\n",
      "ocr_conf:  0.925\n",
      "1188/1662\n",
      "file_name: xemay131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1622896\n",
      "recognized_text:  59-N2090.50\n",
      "ocr_conf:  0.931\n",
      "1189/1662\n",
      "file_name: xemay1310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1310.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2449402\n",
      "recognized_text:  47-L1099.17\n",
      "ocr_conf:  0.888\n",
      "1190/1662\n",
      "file_name: xemay1311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1311.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0259387\n",
      "recognized_text:  68-LA007.76\n",
      "ocr_conf:  0.893\n",
      "1191/1662\n",
      "file_name: xemay1320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1320.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1338549\n",
      "recognized_text:  59-U1744.90\n",
      "ocr_conf:  0.905\n",
      "1192/1662\n",
      "file_name: xemay1321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1321.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.5ms preprocess, 122.6ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1632537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1330.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S2083.38\n",
      "ocr_conf:  0.875\n",
      "1193/1662\n",
      "file_name: xemay1330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1515379\n",
      "recognized_text:  59-D2171.48\n",
      "ocr_conf:  0.902\n",
      "1194/1662\n",
      "file_name: xemay1331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1331.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.160155\n",
      "recognized_text:  52-F31770\n",
      "ocr_conf:  0.906\n",
      "1195/1662\n",
      "file_name: xemay1340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1340.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1576222\n",
      "recognized_text:  59-C1471.67\n",
      "ocr_conf:  0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1341.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196/1662\n",
      "file_name: xemay1341.jpg\n",
      "aspect_ratio: 1.073772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1350.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C1236.82\n",
      "ocr_conf:  0.889\n",
      "1197/1662\n",
      "file_name: xemay1350.jpg\n",
      "aspect_ratio: 1.1808314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-S57611\n",
      "ocr_conf:  0.863\n",
      "1198/1662\n",
      "file_name: xemay1351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1351.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 4.4ms preprocess, 121.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1657974\n",
      "recognized_text:  78-E1241.13\n",
      "ocr_conf:  0.942\n",
      "1199/1662\n",
      "file_name: xemay1360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1360.jpg: 416x640 1 plate, 132.1ms\n",
      "Speed: 4.3ms preprocess, 132.1ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2330817\n",
      "recognized_text:  59-S2316.06\n",
      "ocr_conf:  0.934\n",
      "1200/1662\n",
      "file_name: xemay1361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1361.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0906496\n",
      "recognized_text:  86-86226.70\n",
      "ocr_conf:  0.858\n",
      "1201/1662\n",
      "file_name: xemay1370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1370.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2084426\n",
      "recognized_text:  59-P2111.79\n",
      "ocr_conf:  0.952\n",
      "1202/1662\n",
      "file_name: xemay1371.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1371.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1692271\n",
      "recognized_text:  59-01092.78\n",
      "ocr_conf:  0.893\n",
      "1203/1662\n",
      "file_name: xemay1380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1380.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.176985\n",
      "recognized_text:  67-M25949\n",
      "ocr_conf:  0.873\n",
      "1204/1662\n",
      "file_name: xemay1381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1381.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.1ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0643339\n",
      "recognized_text:  51-S57559\n",
      "ocr_conf:  0.863\n",
      "1205/1662\n",
      "file_name: xemay1390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1390.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0882571\n",
      "recognized_text:  63-F68411\n",
      "ocr_conf:  0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1391.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.7ms preprocess, 123.0ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206/1662\n",
      "file_name: xemay1391.jpg\n",
      "aspect_ratio: 1.177063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay140.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-X2627.21\n",
      "ocr_conf:  0.929\n",
      "1207/1662\n",
      "file_name: xemay140.jpg\n",
      "aspect_ratio: 1.0951416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1400.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.2ms preprocess, 123.2ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59K406.50\n",
      "ocr_conf:  0.961\n",
      "1208/1662\n",
      "file_name: xemay1400.jpg\n",
      "aspect_ratio: 1.1491915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1401.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.1ms preprocess, 123.6ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  62L1209.95\n",
      "ocr_conf:  0.965\n",
      "1209/1662\n",
      "file_name: xemay1401.jpg\n",
      "aspect_ratio: 1.1488851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay141.jpg: 416x640 1 plate, 129.9ms\n",
      "Speed: 4.4ms preprocess, 129.9ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-039055\n",
      "ocr_conf:  0.889\n",
      "1210/1662\n",
      "file_name: xemay141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2600201\n",
      "recognized_text:  59-S1313.86\n",
      "ocr_conf:  0.86\n",
      "1211/1662\n",
      "file_name: xemay1410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1410.jpg: 416x640 1 plate, 128.3ms\n",
      "Speed: 4.3ms preprocess, 128.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1860245\n",
      "recognized_text:  77-X69544\n",
      "ocr_conf:  0.861\n",
      "1212/1662\n",
      "file_name: xemay1411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1411.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.8ms preprocess, 124.1ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0628426\n",
      "recognized_text:  54123353\n",
      "ocr_conf:  0.894\n",
      "1213/1662\n",
      "file_name: xemay1420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1420.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.4ms preprocess, 125.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1832848\n",
      "recognized_text:  54-N6324\n",
      "ocr_conf:  0.926\n",
      "1214/1662\n",
      "file_name: xemay1421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1421.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1747335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-D1654.55\n",
      "ocr_conf:  0.913\n",
      "1215/1662\n",
      "file_name: xemay1430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1430.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.9ms preprocess, 124.9ms inference, 9.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1906066\n",
      "recognized_text:  49-B1511.83\n",
      "ocr_conf:  0.919\n",
      "1216/1662\n",
      "file_name: xemay1431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1431.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1783193\n",
      "recognized_text:  93-1264.79\n",
      "ocr_conf:  0.944\n",
      "1217/1662\n",
      "file_name: xemay1440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1440.jpg: 416x640 1 plate, 133.2ms\n",
      "Speed: 4.6ms preprocess, 133.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1913618\n",
      "recognized_text:  55-P71233\n",
      "ocr_conf:  0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1441.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218/1662\n",
      "file_name: xemay1441.jpg\n",
      "aspect_ratio: 1.0810468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1450.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S1448.95\n",
      "ocr_conf:  0.931\n",
      "1219/1662\n",
      "file_name: xemay1450.jpg\n",
      "aspect_ratio: 1.1255155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1451.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-F11765.97\n",
      "ocr_conf:  0.896\n",
      "1220/1662\n",
      "file_name: xemay1451.jpg\n",
      "aspect_ratio: 1.1756358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-V85033\n",
      "ocr_conf:  0.92\n",
      "1221/1662\n",
      "file_name: xemay1460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1460.jpg: 416x640 1 plate, 124.4ms\n",
      "Speed: 4.7ms preprocess, 124.4ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1822488\n",
      "recognized_text:  59-F1545.73\n",
      "ocr_conf:  0.955\n",
      "1222/1662\n",
      "file_name: xemay1461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1461.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2384901\n",
      "recognized_text:  59-S1418.03\n",
      "ocr_conf:  0.892\n",
      "1223/1662\n",
      "file_name: xemay1470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1470.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.5ms preprocess, 124.1ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0323505\n",
      "recognized_text:  52-S24832\n",
      "ocr_conf:  0.896\n",
      "1224/1662\n",
      "file_name: xemay1471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1471.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.2ms preprocess, 124.3ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1793841\n",
      "recognized_text:  67-C1083.47\n",
      "ocr_conf:  0.861\n",
      "1225/1662\n",
      "file_name: xemay1480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1480.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.044728\n",
      "recognized_text:  59.L1180.44\n",
      "ocr_conf:  0.863\n",
      "1226/1662\n",
      "file_name: xemay1481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1481.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 15.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1404029\n",
      "recognized_text:  1-D1478.34\n",
      "ocr_conf:  0.903\n",
      "1227/1662\n",
      "file_name: xemay1490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1490.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1946101\n",
      "recognized_text:  59-K1852.50\n",
      "ocr_conf:  0.923\n",
      "1228/1662\n",
      "file_name: xemay1491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1491.jpg: 416x640 1 plate, 126.2ms\n",
      "Speed: 4.4ms preprocess, 126.2ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1598498\n",
      "recognized_text:  59-418.19\n",
      "ocr_conf:  0.952\n",
      "1229/1662\n",
      "file_name: xemay150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay150.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2001435\n",
      "recognized_text:  83-P175.60\n",
      "ocr_conf:  0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1500.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1662\n",
      "file_name: xemay1500.jpg\n",
      "aspect_ratio: 1.1973373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1501.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-S39276\n",
      "ocr_conf:  0.917\n",
      "1231/1662\n",
      "file_name: xemay1501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.168415\n",
      "recognized_text:  62-N1369.34\n",
      "ocr_conf:  0.91\n",
      "1232/1662\n",
      "file_name: xemay151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay151.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.3ms preprocess, 124.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.103346\n",
      "recognized_text:  59-P2209.47\n",
      "ocr_conf:  0.895\n",
      "1233/1662\n",
      "file_name: xemay1510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1510.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1797467\n",
      "recognized_text:  59-X1695.92\n",
      "ocr_conf:  0.904\n",
      "1234/1662\n",
      "file_name: xemay1511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1511.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1619242\n",
      "recognized_text:  59-T1621.33\n",
      "ocr_conf:  0.78\n",
      "1235/1662\n",
      "file_name: xemay1520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1520.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 7.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1090544\n",
      "recognized_text:  78K1006.77\n",
      "ocr_conf:  0.975\n",
      "1236/1662\n",
      "file_name: xemay1521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1521.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1450965\n",
      "recognized_text:  52-U40050\n",
      "ocr_conf:  0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1530.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.7ms preprocess, 123.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237/1662\n",
      "file_name: xemay1530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2435312\n",
      "recognized_text:  53-P24531\n",
      "ocr_conf:  0.94\n",
      "1238/1662\n",
      "file_name: xemay1531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1531.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.3ms preprocess, 123.9ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2308137\n",
      "recognized_text:  50A5535\n",
      "ocr_conf:  0.913\n",
      "1239/1662\n",
      "file_name: xemay1540.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1540.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3133551\n",
      "recognized_text:  52-T85761\n",
      "ocr_conf:  0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1541.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.8ms preprocess, 122.0ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1662\n",
      "file_name: xemay1541.jpg\n",
      "aspect_ratio: 1.2069566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1550.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-P48871\n",
      "ocr_conf:  0.875\n",
      "1241/1662\n",
      "file_name: xemay1550.jpg\n",
      "aspect_ratio: 1.1193327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1551.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  81-01387.46\n",
      "ocr_conf:  0.863\n",
      "1242/1662\n",
      "file_name: xemay1551.jpg\n",
      "aspect_ratio: 1.1024139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1560.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 8.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  65L108396\n",
      "ocr_conf:  0.918\n",
      "1243/1662\n",
      "file_name: xemay1560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.180002\n",
      "recognized_text:  29-01635.16\n",
      "ocr_conf:  0.898\n",
      "1244/1662\n",
      "file_name: xemay1561.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1561.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.5ms preprocess, 124.6ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.172662\n",
      "recognized_text:  59-K163.01\n",
      "ocr_conf:  0.844\n",
      "1245/1662\n",
      "file_name: xemay1570.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1570.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1807961\n",
      "recognized_text:  68-K49407\n",
      "ocr_conf:  0.873\n",
      "1246/1662\n",
      "file_name: xemay1571.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1571.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2182372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-M1818.59\n",
      "ocr_conf:  0.883\n",
      "1247/1662\n",
      "file_name: xemay1580.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1580.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1859332\n",
      "recognized_text:  59-S1262.08\n",
      "ocr_conf:  0.9\n",
      "1248/1662\n",
      "file_name: xemay1581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1581.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0936253\n",
      "recognized_text:  59-Y1864.94\n",
      "ocr_conf:  0.914\n",
      "1249/1662\n",
      "file_name: xemay1590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1590.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.3ms preprocess, 123.9ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2316478\n",
      "recognized_text:  49-B1453.48\n",
      "ocr_conf:  0.885\n",
      "1250/1662\n",
      "file_name: xemay1591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1591.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.7ms preprocess, 122.3ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1985708\n",
      "recognized_text:  59-C1677.90\n",
      "ocr_conf:  0.943\n",
      "1251/1662\n",
      "file_name: xemay160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay160.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.2ms preprocess, 124.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.152564\n",
      "recognized_text:  59-U1254.18\n",
      "ocr_conf:  0.893\n",
      "1252/1662\n",
      "file_name: xemay1600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1600.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1477339\n",
      "recognized_text:  59-S178384\n",
      "ocr_conf:  0.88\n",
      "1253/1662\n",
      "file_name: xemay1601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1601.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.2ms preprocess, 122.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1774759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay161.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  93-C1020.79\n",
      "ocr_conf:  0.926\n",
      "1254/1662\n",
      "file_name: xemay161.jpg\n",
      "aspect_ratio: 1.2090112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1610.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.5ms preprocess, 123.9ms inference, 12.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-L2275.60\n",
      "ocr_conf:  0.898\n",
      "1255/1662\n",
      "file_name: xemay1610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1546016\n",
      "recognized_text:  54-X82567\n",
      "ocr_conf:  0.893\n",
      "1256/1662\n",
      "file_name: xemay1611.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1611.jpg: 416x640 1 plate, 121.9ms\n",
      "Speed: 4.4ms preprocess, 121.9ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2442883\n",
      "recognized_text:  59-B1291.17\n",
      "ocr_conf:  0.945\n",
      "1257/1662\n",
      "file_name: xemay1620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1620.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0785971\n",
      "recognized_text:  59-F1599.97\n",
      "ocr_conf:  0.941\n",
      "1258/1662\n",
      "file_name: xemay1621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1621.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1232042\n",
      "recognized_text:  59-P2152.70\n",
      "ocr_conf:  0.894\n",
      "1259/1662\n",
      "file_name: xemay1630.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1630.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.8ms preprocess, 124.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1292987\n",
      "recognized_text:  67-M1360.37\n",
      "ocr_conf:  0.92\n",
      "1260/1662\n",
      "file_name: xemay1631.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1631.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2340263\n",
      "recognized_text:  47-01770.40\n",
      "ocr_conf:  0.898\n",
      "1261/1662\n",
      "file_name: xemay1640.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1640.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1885358\n",
      "recognized_text:  59-K1693.23\n",
      "ocr_conf:  0.945\n",
      "1262/1662\n",
      "file_name: xemay1641.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1641.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2057419\n",
      "recognized_text:  59-Y1602.71\n",
      "ocr_conf:  0.919\n",
      "1263/1662\n",
      "file_name: xemay1650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1650.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.4ms preprocess, 124.1ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2496663\n",
      "recognized_text:  54U24957\n",
      "ocr_conf:  0.941\n",
      "1264/1662\n",
      "file_name: xemay1651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1651.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.1ms preprocess, 123.1ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2174549\n",
      "recognized_text:  59F1219.26\n",
      "ocr_conf:  0.944\n",
      "1265/1662\n",
      "file_name: xemay1660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1660.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1716485\n",
      "recognized_text:  52-U84577\n",
      "ocr_conf:  0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1661.jpg: 416x640 1 plate, 126.8ms\n",
      "Speed: 4.3ms preprocess, 126.8ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266/1662\n",
      "file_name: xemay1661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1558418\n",
      "recognized_text:  65-X44850\n",
      "ocr_conf:  0.845\n",
      "1267/1662\n",
      "file_name: xemay1670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1670.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1360832\n",
      "recognized_text:  54-T14995\n",
      "ocr_conf:  0.849\n",
      "1268/1662\n",
      "file_name: xemay1671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1671.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.6ms preprocess, 123.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.24263\n",
      "recognized_text:  59-P2131.59\n",
      "ocr_conf:  0.942\n",
      "1269/1662\n",
      "file_name: xemay1680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1680.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.7ms preprocess, 124.1ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1987929\n",
      "recognized_text:  79-N1259.90\n",
      "ocr_conf:  0.912\n",
      "1270/1662\n",
      "file_name: xemay1681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1681.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2094173\n",
      "recognized_text:  59.L1607.78\n",
      "ocr_conf:  0.902\n",
      "1271/1662\n",
      "file_name: xemay1690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1690.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1776026\n",
      "recognized_text:  50.11849.00\n",
      "ocr_conf:  0.905\n",
      "1272/1662\n",
      "file_name: xemay1691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1691.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2119745\n",
      "recognized_text:  51-55802\n",
      "ocr_conf:  0.8\n",
      "1273/1662\n",
      "file_name: xemay170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay170.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.7ms preprocess, 124.0ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1379349\n",
      "recognized_text:  59-B1000.02\n",
      "ocr_conf:  0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1700.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274/1662\n",
      "file_name: xemay1700.jpg\n",
      "aspect_ratio: 1.1860878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1701.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-1537.73\n",
      "ocr_conf:  0.927\n",
      "1275/1662\n",
      "file_name: xemay1701.jpg\n",
      "aspect_ratio: 1.1679146\n",
      "recognized_text:  60-B3220.83\n",
      "ocr_conf:  0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay171.jpg: 416x640 1 plate, 125.9ms\n",
      "Speed: 4.5ms preprocess, 125.9ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276/1662\n",
      "file_name: xemay171.jpg\n",
      "aspect_ratio: 1.2138592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1710.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  02-K37689.\n",
      "ocr_conf:  0.83\n",
      "1277/1662\n",
      "file_name: xemay1710.jpg\n",
      "aspect_ratio: 1.0765636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1711.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.7ms preprocess, 122.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-N1739.48\n",
      "ocr_conf:  0.885\n",
      "1278/1662\n",
      "file_name: xemay1711.jpg\n",
      "aspect_ratio: 1.1318852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1720.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.4ms preprocess, 124.5ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  53-R89556\n",
      "ocr_conf:  0.897\n",
      "1279/1662\n",
      "file_name: xemay1720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2531915\n",
      "recognized_text:  72-H73227\n",
      "ocr_conf:  0.964\n",
      "1280/1662\n",
      "file_name: xemay1721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1721.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2032846\n",
      "recognized_text:  59-11605.74\n",
      "ocr_conf:  0.89\n",
      "1281/1662\n",
      "file_name: xemay1730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1730.jpg: 416x640 1 plate, 131.3ms\n",
      "Speed: 4.5ms preprocess, 131.3ms inference, 15.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1789641\n",
      "recognized_text:  59-C1560.86\n",
      "ocr_conf:  0.935\n",
      "1282/1662\n",
      "file_name: xemay1731.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1731.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2304132\n",
      "recognized_text:  59-U1452.67\n",
      "ocr_conf:  0.909\n",
      "1283/1662\n",
      "file_name: xemay1740.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1740.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3533472\n",
      "recognized_text:  59-P1664.80\n",
      "ocr_conf:  0.915\n",
      "1284/1662\n",
      "file_name: xemay1741.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1741.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.4ms preprocess, 126.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3805482\n",
      "recognized_text:  59-V1074.73\n",
      "ocr_conf:  0.914\n",
      "1285/1662\n",
      "file_name: xemay1750.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1750.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.387164\n",
      "recognized_text:  43-S26463\n",
      "ocr_conf:  0.85\n",
      "1286/1662\n",
      "file_name: xemay1751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1751.jpg: 416x640 1 plate, 275.1ms\n",
      "Speed: 4.2ms preprocess, 275.1ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2252517\n",
      "recognized_text:  51-H23397\n",
      "ocr_conf:  0.898\n",
      "1287/1662\n",
      "file_name: xemay1760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1760.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3857627\n",
      "recognized_text:  59-S1313.86\n",
      "ocr_conf:  0.902\n",
      "1288/1662\n",
      "file_name: xemay1761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1761.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.4ms preprocess, 122.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2531513\n",
      "recognized_text:  59-S2366.23\n",
      "ocr_conf:  0.914\n",
      "1289/1662\n",
      "file_name: xemay1770.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1770.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.4ms preprocess, 122.1ms inference, 7.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1518892\n",
      "recognized_text:  71-S35011\n",
      "ocr_conf:  0.91\n",
      "1290/1662\n",
      "file_name: xemay1771.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1771.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2541581\n",
      "recognized_text:  60-88137.05\n",
      "ocr_conf:  0.922\n",
      "1291/1662\n",
      "file_name: xemay1780.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1780.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.8ms preprocess, 123.9ms inference, 8.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2720381\n",
      "recognized_text:  59-F1381.51\n",
      "ocr_conf:  0.915\n",
      "1292/1662\n",
      "file_name: xemay1781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1781.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3685776\n",
      "recognized_text:  59-11772.07\n",
      "ocr_conf:  0.916\n",
      "1293/1662\n",
      "file_name: xemay1790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1790.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4622135\n",
      "recognized_text:  72-F1206.13\n",
      "ocr_conf:  0.893\n",
      "1294/1662\n",
      "file_name: xemay1791.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1791.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2045603\n",
      "recognized_text:  59-P183257\n",
      "ocr_conf:  0.916\n",
      "1295/1662\n",
      "file_name: xemay180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay180.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.5ms preprocess, 124.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.192509\n",
      "recognized_text:  51-S84605\n",
      "ocr_conf:  0.903\n",
      "1296/1662\n",
      "file_name: xemay1800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1800.jpg: 416x640 1 plate, 130.9ms\n",
      "Speed: 5.0ms preprocess, 130.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1829705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1801.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.3ms preprocess, 122.9ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-N187515\n",
      "ocr_conf:  0.872\n",
      "1297/1662\n",
      "file_name: xemay1801.jpg\n",
      "aspect_ratio: 1.4169213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay181.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.3ms preprocess, 123.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S22148\n",
      "ocr_conf:  0.9\n",
      "1298/1662\n",
      "file_name: xemay181.jpg\n",
      "aspect_ratio: 1.161285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1810.jpg: 416x640 1 plate, 135.0ms\n",
      "Speed: 4.9ms preprocess, 135.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P1332.02\n",
      "ocr_conf:  0.923\n",
      "1299/1662\n",
      "file_name: xemay1810.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6970918\n",
      "recognized_text:  59-L2275.60\n",
      "ocr_conf:  0.907\n",
      "1300/1662\n",
      "file_name: xemay1811.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1811.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4259871\n",
      "recognized_text:  59-01627.87\n",
      "ocr_conf:  0.932\n",
      "1301/1662\n",
      "file_name: xemay1820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1820.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.348433\n",
      "recognized_text:  59-81000.02\n",
      "ocr_conf:  0.895\n",
      "1302/1662\n",
      "file_name: xemay1821.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1821.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.2ms preprocess, 124.6ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4132421\n",
      "recognized_text:  82-K37689.\n",
      "ocr_conf:  0.829\n",
      "1303/1662\n",
      "file_name: xemay1830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1830.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5219096\n",
      "recognized_text:  59-H1556.99\n",
      "ocr_conf:  0.927\n",
      "1304/1662\n",
      "file_name: xemay1831.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1831.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3496388\n",
      "recognized_text:  51-S84605\n",
      "ocr_conf:  0.886\n",
      "1305/1662\n",
      "file_name: xemay1840.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1840.jpg: 416x640 1 plate, 132.1ms\n",
      "Speed: 4.3ms preprocess, 132.1ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3354222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1841.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.1ms preprocess, 122.1ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  37-1079.18\n",
      "ocr_conf:  0.907\n",
      "1306/1662\n",
      "file_name: xemay1841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4136649\n",
      "recognized_text:  72-C1360.87\n",
      "ocr_conf:  0.908\n",
      "1307/1662\n",
      "file_name: xemay1850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1850.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2516412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1851.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  47-81428.72\n",
      "ocr_conf:  0.92\n",
      "1308/1662\n",
      "file_name: xemay1851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2725097\n",
      "recognized_text:  59E1215.00\n",
      "ocr_conf:  0.932\n",
      "1309/1662\n",
      "file_name: xemay1860.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1860.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.1ms preprocess, 123.7ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4647574\n",
      "recognized_text:  59-0149489\n",
      "ocr_conf:  0.872\n",
      "1310/1662\n",
      "file_name: xemay1861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1861.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4196155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1870.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 3.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P2297.29\n",
      "ocr_conf:  0.91\n",
      "1311/1662\n",
      "file_name: xemay1870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3741192\n",
      "recognized_text:  79-H1200.23\n",
      "ocr_conf:  0.89\n",
      "1312/1662\n",
      "file_name: xemay1871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1871.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.4ms preprocess, 122.8ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4149401\n",
      "recognized_text:  59-11922.70\n",
      "ocr_conf:  0.876\n",
      "1313/1662\n",
      "file_name: xemay1880.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1880.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1591837\n",
      "recognized_text:  59-H156390\n",
      "ocr_conf:  0.929\n",
      "1314/1662\n",
      "file_name: xemay1881.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1881.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4958203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-F1474.88\n",
      "ocr_conf:  0.861\n",
      "1315/1662\n",
      "file_name: xemay1890.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1890.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.4ms preprocess, 124.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2615974\n",
      "recognized_text:  64-0103247\n",
      "ocr_conf:  0.738\n",
      "1316/1662\n",
      "file_name: xemay1891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1891.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5279295\n",
      "recognized_text:  59-S1148.83\n",
      "ocr_conf:  0.903\n",
      "1317/1662\n",
      "file_name: xemay190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay190.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.6ms preprocess, 124.0ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1740766\n",
      "recognized_text:  52-279752\n",
      "ocr_conf:  0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318/1662\n",
      "file_name: xemay1900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1900.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2529672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-71272.75\n",
      "ocr_conf:  0.916\n",
      "1319/1662\n",
      "file_name: xemay1901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1901.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5701185\n",
      "recognized_text:  61-C1064.03\n",
      "ocr_conf:  0.864\n",
      "1320/1662\n",
      "file_name: xemay191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay191.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1775886\n",
      "recognized_text:  72-F1207.41\n",
      "ocr_conf:  0.897\n",
      "1321/1662\n",
      "file_name: xemay1910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1910.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.5ms preprocess, 123.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5332506\n",
      "recognized_text:  592020.84\n",
      "ocr_conf:  0.82\n",
      "1322/1662\n",
      "file_name: xemay1911.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1911.jpg: 416x640 1 plate, 131.0ms\n",
      "Speed: 4.4ms preprocess, 131.0ms inference, 15.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3001784\n",
      "recognized_text:  76-01240.27\n",
      "ocr_conf:  0.948\n",
      "1323/1662\n",
      "file_name: xemay1920.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1920.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.5ms preprocess, 124.5ms inference, 11.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4562919\n",
      "recognized_text:  59-P2313.16\n",
      "ocr_conf:  0.899\n",
      "1324/1662\n",
      "file_name: xemay1921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1921.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.3ms preprocess, 122.9ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4582086\n",
      "recognized_text:  59103640\n",
      "ocr_conf:  0.812\n",
      "1325/1662\n",
      "file_name: xemay1930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1930.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3106093\n",
      "recognized_text:  59-1540.63\n",
      "ocr_conf:  0.882\n",
      "1326/1662\n",
      "file_name: xemay1931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1931.jpg: 416x640 1 plate, 127.3ms\n",
      "Speed: 4.5ms preprocess, 127.3ms inference, 12.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.502102\n",
      "recognized_text:  57F86932\n",
      "ocr_conf:  0.874\n",
      "1327/1662\n",
      "file_name: xemay1940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1940.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.3ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4330747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1941.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.1ms preprocess, 123.1ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  52-044702\n",
      "ocr_conf:  0.867\n",
      "1328/1662\n",
      "file_name: xemay1941.jpg\n",
      "aspect_ratio: 1.5666155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1950.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.2ms preprocess, 122.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  590179751\n",
      "ocr_conf:  0.923\n",
      "1329/1662\n",
      "file_name: xemay1950.jpg\n",
      "aspect_ratio: 1.5190858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1951.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.6ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P1871.49\n",
      "ocr_conf:  0.853\n",
      "1330/1662\n",
      "file_name: xemay1951.jpg\n",
      "aspect_ratio: 1.4139923\n",
      "recognized_text:  59-M1909.77\n",
      "ocr_conf:  0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1331/1662\n",
      "file_name: xemay1960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1960.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.1ms preprocess, 125.4ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6233315\n",
      "recognized_text:  63B2227.94\n",
      "ocr_conf:  0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1961.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1662\n",
      "file_name: xemay1961.jpg\n",
      "aspect_ratio: 1.1655334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1970.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-x0354\n",
      "ocr_conf:  0.853\n",
      "1333/1662\n",
      "file_name: xemay1970.jpg\n",
      "aspect_ratio: 1.2436568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1971.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S1151.33\n",
      "ocr_conf:  0.844\n",
      "1334/1662\n",
      "file_name: xemay1971.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3444725\n",
      "recognized_text:  67F1113.17\n",
      "ocr_conf:  0.917\n",
      "1335/1662\n",
      "file_name: xemay1980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1980.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.460628\n",
      "recognized_text:  59-1608.11\n",
      "ocr_conf:  0.886\n",
      "1336/1662\n",
      "file_name: xemay1981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1981.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5663319\n",
      "recognized_text:  59-K1832.35\n",
      "ocr_conf:  0.888\n",
      "1337/1662\n",
      "file_name: xemay1990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1990.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.4ms preprocess, 125.0ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2560515\n",
      "recognized_text:  59-L2237.14\n",
      "ocr_conf:  0.875\n",
      "1338/1662\n",
      "file_name: xemay1991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay1991.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3918589\n",
      "recognized_text:  59-P2313.16\n",
      "ocr_conf:  0.944\n",
      "1339/1662\n",
      "file_name: xemay20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay20.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1248543\n",
      "recognized_text:  51-FB4779.\n",
      "ocr_conf:  0.903\n",
      "1340/1662\n",
      "file_name: xemay200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay200.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1711242\n",
      "recognized_text:  59-D1669.74\n",
      "ocr_conf:  0.91\n",
      "1341/1662\n",
      "file_name: xemay2000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2000.jpg: 416x640 1 plate, 124.7ms\n",
      "Speed: 5.8ms preprocess, 124.7ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3182768\n",
      "recognized_text:  59-11555.00\n",
      "ocr_conf:  0.882\n",
      "1342/1662\n",
      "file_name: xemay2001.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2001.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.5ms preprocess, 124.2ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2416371\n",
      "recognized_text:  77-C1393.73\n",
      "ocr_conf:  0.927\n",
      "1343/1662\n",
      "file_name: xemay201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay201.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 5.5ms preprocess, 123.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2257951\n",
      "recognized_text:  59-H1467.04\n",
      "ocr_conf:  0.946\n",
      "1344/1662\n",
      "file_name: xemay2010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2010.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.325123\n",
      "recognized_text:  15378\n",
      "ocr_conf:  0.886\n",
      "1345/1662\n",
      "file_name: xemay2011.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2011.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.8ms preprocess, 124.1ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4788582\n",
      "recognized_text:  51L33664\n",
      "ocr_conf:  0.851\n",
      "1346/1662\n",
      "file_name: xemay2020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2020.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3681245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2021.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51-H25512\n",
      "ocr_conf:  0.907\n",
      "1347/1662\n",
      "file_name: xemay2021.jpg\n",
      "aspect_ratio: 1.3424064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2030.jpg: 416x640 1 plate, 125.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  6066280.32\n",
      "ocr_conf:  0.872\n",
      "1348/1662\n",
      "file_name: xemay2030.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.4ms preprocess, 125.9ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1533898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  49-81041.82\n",
      "ocr_conf:  0.859\n",
      "1349/1662\n",
      "file_name: xemay2031.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2031.jpg: 416x640 1 plate, 125.1ms\n",
      "Speed: 4.3ms preprocess, 125.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.29479\n",
      "recognized_text:  86-H79591\n",
      "ocr_conf:  0.952\n",
      "1350/1662\n",
      "file_name: xemay2040.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2040.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.8ms preprocess, 123.0ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5210744\n",
      "recognized_text:  59-V1074.73\n",
      "ocr_conf:  0.908\n",
      "1351/1662\n",
      "file_name: xemay2041.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2041.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.6ms preprocess, 122.7ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6750406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51-Y67665\n",
      "ocr_conf:  0.916\n",
      "1352/1662\n",
      "file_name: xemay2050.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2050.jpg: 416x640 1 plate, 125.8ms\n",
      "Speed: 4.8ms preprocess, 125.8ms inference, 18.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4959149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  65-S21319\n",
      "ocr_conf:  0.879\n",
      "1353/1662\n",
      "file_name: xemay2051.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2051.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 5.1ms preprocess, 123.0ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2563175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  66-C1157.23\n",
      "ocr_conf:  0.888\n",
      "1354/1662\n",
      "file_name: xemay2060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2060.jpg: 416x640 1 plate, 129.3ms\n",
      "Speed: 4.8ms preprocess, 129.3ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5281314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2061.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  77C1393.73\n",
      "ocr_conf:  0.95\n",
      "1355/1662\n",
      "file_name: xemay2061.jpg\n",
      "aspect_ratio: 1.3478036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2070.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-145476\n",
      "ocr_conf:  0.93\n",
      "1356/1662\n",
      "file_name: xemay2070.jpg\n",
      "aspect_ratio: 1.1832185\n",
      "recognized_text:  59F1238.65\n",
      "ocr_conf:  0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1357/1662\n",
      "file_name: xemay2071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2071.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 14.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4416119\n",
      "recognized_text:  H65519\n",
      "ocr_conf:  0.87\n",
      "1358/1662\n",
      "file_name: xemay2080.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2080.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.7ms preprocess, 123.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2454705\n",
      "recognized_text:  66-P15967\n",
      "ocr_conf:  0.944\n",
      "1359/1662\n",
      "file_name: xemay2081.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2081.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4802856\n",
      "recognized_text:  54-T16084\n",
      "ocr_conf:  0.778\n",
      "1360/1662\n",
      "file_name: xemay2090.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2090.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3814011\n",
      "recognized_text:  51M21719\n",
      "ocr_conf:  0.858\n",
      "1361/1662\n",
      "file_name: xemay2091.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2091.jpg: 416x640 1 plate, 134.3ms\n",
      "Speed: 4.5ms preprocess, 134.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.154195\n",
      "recognized_text:  54-L64897\n",
      "ocr_conf:  0.908\n",
      "1362/1662\n",
      "file_name: xemay21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay21.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1968508\n",
      "recognized_text:  60-B5314.02\n",
      "ocr_conf:  0.903\n",
      "1363/1662\n",
      "file_name: xemay210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay210.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2159182\n",
      "recognized_text:  60-FP1469\n",
      "ocr_conf:  0.958\n",
      "1364/1662\n",
      "file_name: xemay2100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2100.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2762386\n",
      "recognized_text:  59-N1255.21\n",
      "ocr_conf:  0.91\n",
      "1365/1662\n",
      "file_name: xemay2101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2101.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2603073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-8217757\n",
      "ocr_conf:  0.896\n",
      "1366/1662\n",
      "file_name: xemay211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay211.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1867268\n",
      "recognized_text:  59-C1497.44\n",
      "ocr_conf:  0.887\n",
      "1367/1662\n",
      "file_name: xemay2110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2110.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.0ms preprocess, 123.3ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.138163\n",
      "recognized_text:  59-51387.31\n",
      "ocr_conf:  0.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368/1662\n",
      "file_name: xemay2111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2111.jpg: 416x640 1 plate, 128.2ms\n",
      "Speed: 4.3ms preprocess, 128.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3487504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  591217.04\n",
      "ocr_conf:  0.97\n",
      "1369/1662\n",
      "file_name: xemay2120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2120.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 14.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4832048\n",
      "recognized_text:  59X2773.99\n",
      "ocr_conf:  0.925\n",
      "1370/1662\n",
      "file_name: xemay2121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2121.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.9ms preprocess, 123.1ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3170359\n",
      "recognized_text:  51-K28501\n",
      "ocr_conf:  0.911\n",
      "1371/1662\n",
      "file_name: xemay2130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2130.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.7ms preprocess, 122.1ms inference, 14.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4200637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2131.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P243.79\n",
      "ocr_conf:  0.901\n",
      "1372/1662\n",
      "file_name: xemay2131.jpg\n",
      "aspect_ratio: 1.2885474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2140.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C2455.33\n",
      "ocr_conf:  0.785\n",
      "1373/1662\n",
      "file_name: xemay2140.jpg\n",
      "aspect_ratio: 1.2204483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2141.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  72-C1125.11\n",
      "ocr_conf:  0.931\n",
      "1374/1662\n",
      "file_name: xemay2141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1398729\n",
      "recognized_text:  9-F108660\n",
      "ocr_conf:  0.799\n",
      "1375/1662\n",
      "file_name: xemay2150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2150.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3932159\n",
      "recognized_text:  86-H79591\n",
      "ocr_conf:  0.92\n",
      "1376/1662\n",
      "file_name: xemay2151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2151.jpg: 416x640 1 plate, 129.9ms\n",
      "Speed: 4.6ms preprocess, 129.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.390287\n",
      "recognized_text:  54L24264\n",
      "ocr_conf:  0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377/1662\n",
      "file_name: xemay2160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2160.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3218502\n",
      "recognized_text:  50-HB2282\n",
      "ocr_conf:  0.93\n",
      "1378/1662\n",
      "file_name: xemay2161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2161.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2298783\n",
      "recognized_text:  66-S1C90.18\n",
      "ocr_conf:  0.804\n",
      "1379/1662\n",
      "file_name: xemay2170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2170.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 3.9ms preprocess, 123.5ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4935783\n",
      "recognized_text:  49-81208.07\n",
      "ocr_conf:  0.846\n",
      "1380/1662\n",
      "file_name: xemay2171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2171.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1161262\n",
      "recognized_text:  62-V16814\n",
      "ocr_conf:  0.929\n",
      "1381/1662\n",
      "file_name: xemay2180.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2180.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.7ms preprocess, 124.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.92754865\n",
      "recognized_text:  72-10179\n",
      "ocr_conf:  0.887\n",
      "1382/1662\n",
      "file_name: xemay2181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2181.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.7ms preprocess, 123.2ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0632215\n",
      "recognized_text:  71-H19657\n",
      "ocr_conf:  0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383/1662\n",
      "file_name: xemay2190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2190.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 6.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3752782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2191.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.5ms preprocess, 122.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59V00884\n",
      "ocr_conf:  0.901\n",
      "1384/1662\n",
      "file_name: xemay2191.jpg\n",
      "aspect_ratio: 1.1404817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  66-1206.70\n",
      "ocr_conf:  0.893\n",
      "1385/1662\n",
      "file_name: xemay220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay220.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.3ms preprocess, 123.9ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1902198\n",
      "recognized_text:  59-C2459.28\n",
      "ocr_conf:  0.913\n",
      "1386/1662\n",
      "file_name: xemay2200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2200.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 7.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2276565\n",
      "recognized_text:  60-82063.70\n",
      "ocr_conf:  0.8\n",
      "1387/1662\n",
      "file_name: xemay2201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2201.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.4ms preprocess, 124.6ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1836038\n",
      "recognized_text:  591873.04\n",
      "ocr_conf:  0.973\n",
      "1388/1662\n",
      "file_name: xemay221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay221.jpg: 416x640 1 plate, 125.2ms\n",
      "Speed: 5.0ms preprocess, 125.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2393156\n",
      "recognized_text:  59-E1129.03\n",
      "ocr_conf:  0.888\n",
      "1389/1662\n",
      "file_name: xemay2210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2210.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.8ms preprocess, 123.6ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1448174\n",
      "recognized_text:  59.E1341.92\n",
      "ocr_conf:  0.822\n",
      "1390/1662\n",
      "file_name: xemay2211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2211.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.7ms preprocess, 123.4ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5767951\n",
      "recognized_text:  59-52235.46\n",
      "ocr_conf:  0.904\n",
      "1391/1662\n",
      "file_name: xemay2220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2220.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2212946\n",
      "recognized_text:  50N1074.28\n",
      "ocr_conf:  0.935\n",
      "1392/1662\n",
      "file_name: xemay2221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2221.jpg: 416x640 1 plate, 120.0ms\n",
      "Speed: 4.5ms preprocess, 120.0ms inference, 2.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3040705\n",
      "recognized_text:  55-P62004\n",
      "ocr_conf:  0.87\n",
      "1393/1662\n",
      "file_name: xemay2230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2230.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2781372\n",
      "recognized_text:  61-01079.11\n",
      "ocr_conf:  0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2231.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.4ms preprocess, 123.4ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394/1662\n",
      "file_name: xemay2231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1917653\n",
      "recognized_text:  60-94808\n",
      "ocr_conf:  0.837\n",
      "1395/1662\n",
      "file_name: xemay2240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2240.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.1ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2190166\n",
      "recognized_text:  54-787524\n",
      "ocr_conf:  0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1662\n",
      "file_name: xemay2241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2241.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5049388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-142110\n",
      "ocr_conf:  0.844\n",
      "1397/1662\n",
      "file_name: xemay2250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2250.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.3ms preprocess, 124.3ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5796185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59123.09\n",
      "ocr_conf:  0.935\n",
      "1398/1662\n",
      "file_name: xemay2251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2251.jpg: 416x640 1 plate, 130.6ms\n",
      "Speed: 4.6ms preprocess, 130.6ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3484828\n",
      "recognized_text:  62-V16814\n",
      "ocr_conf:  0.885\n",
      "1399/1662\n",
      "file_name: xemay2260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2260.jpg: 416x640 1 plate, 130.2ms\n",
      "Speed: 4.6ms preprocess, 130.2ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5262607\n",
      "recognized_text:  59-N1766.54\n",
      "ocr_conf:  0.929\n",
      "1400/1662\n",
      "file_name: xemay2261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2261.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6131248\n",
      "recognized_text:  59-F1035.68\n",
      "ocr_conf:  0.944\n",
      "1401/1662\n",
      "file_name: xemay2270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2270.jpg: 416x640 1 plate, 126.4ms\n",
      "Speed: 4.4ms preprocess, 126.4ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2876574\n",
      "recognized_text:  56-P25963\n",
      "ocr_conf:  0.94\n",
      "1402/1662\n",
      "file_name: xemay2271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2271.jpg: 416x640 1 plate, 131.1ms\n",
      "Speed: 4.2ms preprocess, 131.1ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4015678\n",
      "recognized_text:  54K48147\n",
      "ocr_conf:  0.787\n",
      "1403/1662\n",
      "file_name: xemay2280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2280.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1481946\n",
      "recognized_text:  86-C1331.39\n",
      "ocr_conf:  0.85\n",
      "1404/1662\n",
      "file_name: xemay2281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2281.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.14419\n",
      "recognized_text:  33-33\n",
      "ocr_conf:  0.597\n",
      "1405/1662\n",
      "file_name: xemay2290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2290.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.6ms preprocess, 123.7ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3208224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2291.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S1742.03\n",
      "ocr_conf:  0.905\n",
      "1406/1662\n",
      "file_name: xemay2291.jpg\n",
      "aspect_ratio: 1.5609547\n",
      "recognized_text:  59-158405\n",
      "ocr_conf:  0.911\n",
      "1407/1662\n",
      "file_name: xemay230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay230.jpg: 416x640 1 plate, 127.8ms\n",
      "Speed: 4.3ms preprocess, 127.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1946102\n",
      "recognized_text:  54-T30255\n",
      "ocr_conf:  0.895\n",
      "1408/1662\n",
      "file_name: xemay2300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2300.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 4.4ms preprocess, 126.0ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.864974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-T1655.50\n",
      "ocr_conf:  0.872\n",
      "1409/1662\n",
      "file_name: xemay2301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2301.jpg: 416x640 1 plate, 125.4ms\n",
      "Speed: 4.7ms preprocess, 125.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3670088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay231.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.5ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  6-H1175.50\n",
      "ocr_conf:  0.899\n",
      "1410/1662\n",
      "file_name: xemay231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2498266\n",
      "recognized_text:  59-x1602.10\n",
      "ocr_conf:  0.897\n",
      "1411/1662\n",
      "file_name: xemay2310.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2310.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.6ms preprocess, 124.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1207044\n",
      "recognized_text:  59997\n",
      "ocr_conf:  0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2311.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 16.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412/1662\n",
      "file_name: xemay2311.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4314933\n",
      "recognized_text:  59T1052.97\n",
      "ocr_conf:  0.942\n",
      "1413/1662\n",
      "file_name: xemay2320.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2320.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6078596\n",
      "recognized_text:  591567.20\n",
      "ocr_conf:  0.882\n",
      "1414/1662\n",
      "file_name: xemay2321.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2321.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 4.6ms preprocess, 124.3ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1953399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2330.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.7ms preprocess, 123.1ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-585489\n",
      "ocr_conf:  0.809\n",
      "1415/1662\n",
      "file_name: xemay2330.jpg\n",
      "aspect_ratio: 1.7965809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2331.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 8.0ms preprocess, 122.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-1Z2179\n",
      "ocr_conf:  0.815\n",
      "1416/1662\n",
      "file_name: xemay2331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5180434\n",
      "recognized_text:  59-1550.40\n",
      "ocr_conf:  0.891\n",
      "1417/1662\n",
      "file_name: xemay2340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2340.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.3ms preprocess, 124.0ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2252578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  65-F1315.32\n",
      "ocr_conf:  0.886\n",
      "1418/1662\n",
      "file_name: xemay2341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2341.jpg: 416x640 1 plate, 139.5ms\n",
      "Speed: 4.5ms preprocess, 139.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8421772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  591266.26\n",
      "ocr_conf:  0.923\n",
      "1419/1662\n",
      "file_name: xemay2350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2350.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.7ms preprocess, 123.5ms inference, 8.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6113131\n",
      "recognized_text:  59P2112.06\n",
      "ocr_conf:  0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420/1662\n",
      "file_name: xemay2351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2351.jpg: 416x640 1 plate, 128.0ms\n",
      "Speed: 4.3ms preprocess, 128.0ms inference, 14.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2387761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C1162.74\n",
      "ocr_conf:  0.92\n",
      "1421/1662\n",
      "file_name: xemay2360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2360.jpg: 416x640 1 plate, 127.2ms\n",
      "Speed: 4.4ms preprocess, 127.2ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2581207\n",
      "recognized_text:  54-R22733\n",
      "ocr_conf:  0.91\n",
      "1422/1662\n",
      "file_name: xemay2361.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2361.jpg: 416x640 1 plate, 127.9ms\n",
      "Speed: 9.0ms preprocess, 127.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.85364753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  67-H1-036.55\n",
      "ocr_conf:  0.86\n",
      "1423/1662\n",
      "file_name: xemay2370.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2370.jpg: 416x640 1 plate, 133.6ms\n",
      "Speed: 4.5ms preprocess, 133.6ms inference, 10.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5257655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2371.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 7.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-H1677.91\n",
      "ocr_conf:  0.939\n",
      "1424/1662\n",
      "file_name: xemay2371.jpg\n",
      "aspect_ratio: 1.1398392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-73400\n",
      "ocr_conf:  0.908\n",
      "1425/1662\n",
      "file_name: xemay2380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2380.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.0ms preprocess, 123.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0631206\n",
      "recognized_text:  591082.75\n",
      "ocr_conf:  0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2381.jpg: 416x640 1 plate, 126.0ms\n",
      "Speed: 7.1ms preprocess, 126.0ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1426/1662\n",
      "file_name: xemay2381.jpg\n",
      "aspect_ratio: 1.3832732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-H1677.91\n",
      "ocr_conf:  0.872\n",
      "1427/1662\n",
      "file_name: xemay2390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2390.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 5.1ms preprocess, 123.8ms inference, 11.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3369278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2391.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.6ms preprocess, 122.8ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  81-H12204\n",
      "ocr_conf:  0.864\n",
      "1428/1662\n",
      "file_name: xemay2391.jpg\n",
      "aspect_ratio: 1.4029279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  55-X17546\n",
      "ocr_conf:  0.858\n",
      "1429/1662\n",
      "file_name: xemay240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay240.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1648625\n",
      "recognized_text:  59-51594.84\n",
      "ocr_conf:  0.885\n",
      "1430/1662\n",
      "file_name: xemay2400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2400.jpg: 416x640 1 plate, 124.9ms\n",
      "Speed: 4.6ms preprocess, 124.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3017476\n",
      "recognized_text:  459530\n",
      "ocr_conf:  0.759\n",
      "1431/1662\n",
      "file_name: xemay2401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2401.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0662726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay241.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-P72138\n",
      "ocr_conf:  0.914\n",
      "1432/1662\n",
      "file_name: xemay241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2707912\n",
      "recognized_text:  59-P1631.38\n",
      "ocr_conf:  0.904\n",
      "1433/1662\n",
      "file_name: xemay2410.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2410.jpg: 416x640 1 plate, 126.4ms\n",
      "Speed: 4.5ms preprocess, 126.4ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2577175\n",
      "recognized_text:  59077.90\n",
      "ocr_conf:  0.946\n",
      "1434/1662\n",
      "file_name: xemay2411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2411.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.7ms preprocess, 123.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6200761\n",
      "recognized_text:  52F41035\n",
      "ocr_conf:  0.955\n",
      "1435/1662\n",
      "file_name: xemay2420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2420.jpg: 416x640 1 plate, 122.1ms\n",
      "Speed: 4.3ms preprocess, 122.1ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1765966\n",
      "recognized_text:  5669\n",
      "ocr_conf:  0.556\n",
      "1436/1662\n",
      "file_name: xemay2421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2421.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.5ms preprocess, 123.2ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4607993\n",
      "recognized_text:  47HZ5226\n",
      "ocr_conf:  0.895\n",
      "1437/1662\n",
      "file_name: xemay2430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2430.jpg: 416x640 1 plate, 131.9ms\n",
      "Speed: 5.0ms preprocess, 131.9ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0568471\n",
      "recognized_text:  59-S1554.83\n",
      "ocr_conf:  0.809\n",
      "1438/1662\n",
      "file_name: xemay2431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2431.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.2ms preprocess, 124.1ms inference, 8.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3951606\n",
      "recognized_text:  83-717113\n",
      "ocr_conf:  0.751\n",
      "1439/1662\n",
      "file_name: xemay2440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2440.jpg: 416x640 1 plate, 128.3ms\n",
      "Speed: 4.7ms preprocess, 128.3ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2565292\n",
      "recognized_text:  59-B1351.99\n",
      "ocr_conf:  0.889\n",
      "1440/1662\n",
      "file_name: xemay2441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2441.jpg: 416x640 1 plate, 131.3ms\n",
      "Speed: 4.7ms preprocess, 131.3ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.256139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2450.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 9.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  51-H58092\n",
      "ocr_conf:  0.828\n",
      "1441/1662\n",
      "file_name: xemay2450.jpg\n",
      "aspect_ratio: 1.8076423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2451.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.4ms preprocess, 123.5ms inference, 9.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71-88426\n",
      "ocr_conf:  0.809\n",
      "1442/1662\n",
      "file_name: xemay2451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4214352\n",
      "recognized_text:  54-U52813\n",
      "ocr_conf:  0.876\n",
      "1443/1662\n",
      "file_name: xemay2460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2460.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.2ms preprocess, 125.0ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.091395\n",
      "recognized_text:  59-H1044.25\n",
      "ocr_conf:  0.92\n",
      "1444/1662\n",
      "file_name: xemay2461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2461.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.2ms preprocess, 123.7ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3729008\n",
      "recognized_text:  59-N1014.25\n",
      "ocr_conf:  0.927\n",
      "1445/1662\n",
      "file_name: xemay2470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2470.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4180856\n",
      "recognized_text:  51-R56273\n",
      "ocr_conf:  0.941\n",
      "1446/1662\n",
      "file_name: xemay2471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2471.jpg: 416x640 1 plate, 135.5ms\n",
      "Speed: 4.4ms preprocess, 135.5ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4822817\n",
      "recognized_text:  59-L1974.57\n",
      "ocr_conf:  0.902\n",
      "1447/1662\n",
      "file_name: xemay2480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2480.jpg: 416x640 1 plate, 135.7ms\n",
      "Speed: 4.7ms preprocess, 135.7ms inference, 16.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3456627\n",
      "recognized_text:  5941877.60\n",
      "ocr_conf:  0.847\n",
      "1448/1662\n",
      "file_name: xemay2481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay2481.jpg: 416x640 1 plate, 129.6ms\n",
      "Speed: 4.5ms preprocess, 129.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4384207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay250.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-X2683.27\n",
      "ocr_conf:  0.928\n",
      "1449/1662\n",
      "file_name: xemay250.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1860329\n",
      "recognized_text:  76-01240.27\n",
      "ocr_conf:  0.941\n",
      "1450/1662\n",
      "file_name: xemay251.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay251.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.1ms preprocess, 123.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1889396\n",
      "recognized_text:  59-L2020.84\n",
      "ocr_conf:  0.923\n",
      "1451/1662\n",
      "file_name: xemay260.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay260.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2872496\n",
      "recognized_text:  59-P2313.16\n",
      "ocr_conf:  0.957\n",
      "1452/1662\n",
      "file_name: xemay261.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay261.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.1ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2096295\n",
      "recognized_text:  59-E1036.40\n",
      "ocr_conf:  0.84\n",
      "1453/1662\n",
      "file_name: xemay270.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay270.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1883593\n",
      "recognized_text:  52-F86932\n",
      "ocr_conf:  0.921\n",
      "1454/1662\n",
      "file_name: xemay271.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay271.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1837217\n",
      "recognized_text:  95-0B011.79\n",
      "ocr_conf:  0.855\n",
      "1455/1662\n",
      "file_name: xemay280.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay280.jpg: 416x640 1 plate, 132.8ms\n",
      "Speed: 4.2ms preprocess, 132.8ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1672926\n",
      "recognized_text:  59-T1616.54\n",
      "ocr_conf:  0.89\n",
      "1456/1662\n",
      "file_name: xemay281.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay281.jpg: 416x640 1 plate, 122.5ms\n",
      "Speed: 4.2ms preprocess, 122.5ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1343901\n",
      "recognized_text:  53-V97976\n",
      "ocr_conf:  0.925\n",
      "1457/1662\n",
      "file_name: xemay290.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay290.jpg: 416x640 1 plate, 121.4ms\n",
      "Speed: 4.3ms preprocess, 121.4ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1873245\n",
      "recognized_text:  50-C1237.74\n",
      "ocr_conf:  0.831\n",
      "1458/1662\n",
      "file_name: xemay291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay291.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 3.9ms preprocess, 123.8ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2007793\n",
      "recognized_text:  47-N69618\n",
      "ocr_conf:  0.817\n",
      "1459/1662\n",
      "file_name: xemay30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay30.jpg: 416x640 1 plate, 121.3ms\n",
      "Speed: 4.0ms preprocess, 121.3ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1652238\n",
      "recognized_text:  59-V1840.31\n",
      "ocr_conf:  0.901\n",
      "1460/1662\n",
      "file_name: xemay300.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay300.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 5.9ms preprocess, 123.5ms inference, 13.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.150387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay301.jpg: 416x640 1 plate, 131.1ms\n",
      "Speed: 5.0ms preprocess, 131.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-39902\n",
      "ocr_conf:  0.915\n",
      "1461/1662\n",
      "file_name: xemay301.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1601167\n",
      "recognized_text:  52-F39280\n",
      "ocr_conf:  0.906\n",
      "1462/1662\n",
      "file_name: xemay31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay31.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 5.0ms preprocess, 123.4ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1639766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay310.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 10.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-1134.17\n",
      "ocr_conf:  0.954\n",
      "1463/1662\n",
      "file_name: xemay310.jpg\n",
      "aspect_ratio: 1.1731172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay311.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S112.89\n",
      "ocr_conf:  0.918\n",
      "1464/1662\n",
      "file_name: xemay311.jpg\n",
      "aspect_ratio: 1.159363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay320.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.4ms preprocess, 122.7ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  591035.19\n",
      "ocr_conf:  0.942\n",
      "1465/1662\n",
      "file_name: xemay320.jpg\n",
      "aspect_ratio: 1.1771964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay321.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  70-81471.89\n",
      "ocr_conf:  0.869\n",
      "1466/1662\n",
      "file_name: xemay321.jpg\n",
      "aspect_ratio: 1.1847668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay330.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-V2436.54\n",
      "ocr_conf:  0.904\n",
      "1467/1662\n",
      "file_name: xemay330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1969944\n",
      "recognized_text:  59-C2019.09\n",
      "ocr_conf:  0.916\n",
      "1468/1662\n",
      "file_name: xemay331.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay331.jpg: 416x640 1 plate, 131.6ms\n",
      "Speed: 4.5ms preprocess, 131.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2333115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay340.jpg: 416x640 1 plate, 128.8ms\n",
      "Speed: 4.5ms preprocess, 128.8ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  71C2364.23\n",
      "ocr_conf:  0.968\n",
      "1469/1662\n",
      "file_name: xemay340.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1957183\n",
      "recognized_text:  54-P11782\n",
      "ocr_conf:  0.959\n",
      "1470/1662\n",
      "file_name: xemay341.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay341.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 6.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1864684\n",
      "recognized_text:  85-S15378\n",
      "ocr_conf:  0.892\n",
      "1471/1662\n",
      "file_name: xemay350.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay350.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1595112\n",
      "recognized_text:  51-H25512\n",
      "ocr_conf:  0.923\n",
      "1472/1662\n",
      "file_name: xemay351.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay351.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.1ms preprocess, 123.4ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1904558\n",
      "recognized_text:  6086280.32\n",
      "ocr_conf:  0.879\n",
      "1473/1662\n",
      "file_name: xemay360.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay360.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.5ms preprocess, 123.5ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1858382\n",
      "recognized_text:  86-H79591\n",
      "ocr_conf:  0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay361.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.7ms preprocess, 122.8ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1474/1662\n",
      "file_name: xemay361.jpg\n",
      "aspect_ratio: 1.1876466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay370.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.3ms preprocess, 122.8ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S14959\n",
      "ocr_conf:  0.878\n",
      "1475/1662\n",
      "file_name: xemay370.jpg\n",
      "aspect_ratio: 1.164636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay371.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 6.5ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  55-P44641\n",
      "ocr_conf:  0.912\n",
      "1476/1662\n",
      "file_name: xemay371.jpg\n",
      "aspect_ratio: 1.1224996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay380.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-S14959\n",
      "ocr_conf:  0.885\n",
      "1477/1662\n",
      "file_name: xemay380.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2054856\n",
      "recognized_text:  70-SA0367\n",
      "ocr_conf:  0.942\n",
      "1478/1662\n",
      "file_name: xemay381.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay381.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1650158\n",
      "recognized_text:  54-U51223\n",
      "ocr_conf:  0.888\n",
      "1479/1662\n",
      "file_name: xemay390.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay390.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1526296\n",
      "recognized_text:  70-EA005.57\n",
      "ocr_conf:  0.943\n",
      "1480/1662\n",
      "file_name: xemay391.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay391.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.3ms preprocess, 123.0ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2252436\n",
      "recognized_text:  86-B6246.82\n",
      "ocr_conf:  0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481/1662\n",
      "file_name: xemay40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay40.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1959312\n",
      "recognized_text:  85-F1004.17\n",
      "ocr_conf:  0.918\n",
      "1482/1662\n",
      "file_name: xemay400.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay400.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1909592\n",
      "recognized_text:  59-H1439.86\n",
      "ocr_conf:  0.921\n",
      "1483/1662\n",
      "file_name: xemay401.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay401.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2357657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay41.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  61-D1079.11\n",
      "ocr_conf:  0.938\n",
      "1484/1662\n",
      "file_name: xemay41.jpg\n",
      "aspect_ratio: 1.2051095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay410.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.5ms preprocess, 123.1ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  65-S21319\n",
      "ocr_conf:  0.905\n",
      "1485/1662\n",
      "file_name: xemay410.jpg\n",
      "aspect_ratio: 1.249031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-V2158.00\n",
      "ocr_conf:  0.915\n",
      "1486/1662\n",
      "file_name: xemay411.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay411.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.7ms preprocess, 122.6ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1914122\n",
      "recognized_text:  65.H90714\n",
      "ocr_conf:  0.906\n",
      "1487/1662\n",
      "file_name: xemay420.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay420.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.2ms preprocess, 126.1ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2290874\n",
      "recognized_text:  62-N1327.46\n",
      "ocr_conf:  0.879\n",
      "1488/1662\n",
      "file_name: xemay421.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay421.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1891139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  81-01613.86\n",
      "ocr_conf:  0.86\n",
      "1489/1662\n",
      "file_name: xemay430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay430.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1065954\n",
      "recognized_text:  60-B2235.67\n",
      "ocr_conf:  0.889\n",
      "1490/1662\n",
      "file_name: xemay431.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay431.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.6ms preprocess, 122.8ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1902422\n",
      "recognized_text:  59-S1387.31\n",
      "ocr_conf:  0.887\n",
      "1491/1662\n",
      "file_name: xemay440.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay440.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.8ms preprocess, 123.2ms inference, 8.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1126112\n",
      "recognized_text:  59-X2773.99\n",
      "ocr_conf:  0.907\n",
      "1492/1662\n",
      "file_name: xemay441.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay441.jpg: 416x640 1 plate, 124.3ms\n",
      "Speed: 5.2ms preprocess, 124.3ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2394451\n",
      "recognized_text:  51-K28501\n",
      "ocr_conf:  0.94\n",
      "1493/1662\n",
      "file_name: xemay450.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay450.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.2ms preprocess, 123.8ms inference, 6.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1548542\n",
      "recognized_text:  59-C2456.33\n",
      "ocr_conf:  0.901\n",
      "1494/1662\n",
      "file_name: xemay451.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay451.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.126348\n",
      "recognized_text:  83-H66954\n",
      "ocr_conf:  0.864\n",
      "1495/1662\n",
      "file_name: xemay460.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay460.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 15.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1034517\n",
      "recognized_text:  72-L63974\n",
      "ocr_conf:  0.93\n",
      "1496/1662\n",
      "file_name: xemay461.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay461.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 16.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1466222\n",
      "recognized_text:  54-S73211\n",
      "ocr_conf:  0.916\n",
      "1497/1662\n",
      "file_name: xemay470.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay470.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.320235\n",
      "recognized_text:  59-C1324.28\n",
      "ocr_conf:  0.924\n",
      "1498/1662\n",
      "file_name: xemay471.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay471.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.2ms preprocess, 122.9ms inference, 7.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.264371\n",
      "recognized_text:  59-X2788.48\n",
      "ocr_conf:  0.92\n",
      "1499/1662\n",
      "file_name: xemay480.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay480.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.2ms preprocess, 122.0ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1730049\n",
      "recognized_text:  59-E1341.92\n",
      "ocr_conf:  0.872\n",
      "1500/1662\n",
      "file_name: xemay481.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay481.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.4ms preprocess, 123.1ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1953548\n",
      "recognized_text:  59-11848.07\n",
      "ocr_conf:  0.859\n",
      "1501/1662\n",
      "file_name: xemay490.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay490.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2435335\n",
      "recognized_text:  60-C2366.87\n",
      "ocr_conf:  0.912\n",
      "1502/1662\n",
      "file_name: xemay491.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay491.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 6.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2479347\n",
      "recognized_text:  59-C1311.62\n",
      "ocr_conf:  0.929\n",
      "1503/1662\n",
      "file_name: xemay50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay50.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.4ms preprocess, 123.7ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1558253\n",
      "recognized_text:  84-G1225.93\n",
      "ocr_conf:  0.909\n",
      "1504/1662\n",
      "file_name: xemay500.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay500.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.1ms preprocess, 124.8ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2103361\n",
      "recognized_text:  94-D1047.71\n",
      "ocr_conf:  0.904\n",
      "1505/1662\n",
      "file_name: xemay501.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay501.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 3.9ms preprocess, 123.5ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2365105\n",
      "recognized_text:  59-N1255.21\n",
      "ocr_conf:  0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay51.jpg: 416x640 1 plate, 129.8ms\n",
      "Speed: 4.5ms preprocess, 129.8ms inference, 10.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506/1662\n",
      "file_name: xemay51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2127044\n",
      "recognized_text:  59-M1035.19\n",
      "ocr_conf:  0.905\n",
      "1507/1662\n",
      "file_name: xemay510.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay510.jpg: 416x640 1 plate, 125.2ms\n",
      "Speed: 5.4ms preprocess, 125.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2022308\n",
      "recognized_text:  59-L1916.51\n",
      "ocr_conf:  0.916\n",
      "1508/1662\n",
      "file_name: xemay511.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay511.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1050129\n",
      "recognized_text:  7-R14301\n",
      "ocr_conf:  0.894\n",
      "1509/1662\n",
      "file_name: xemay520.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay520.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.9ms preprocess, 123.2ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1807287\n",
      "recognized_text:  52-S37078\n",
      "ocr_conf:  0.898\n",
      "1510/1662\n",
      "file_name: xemay521.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay521.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1983795\n",
      "recognized_text:  59-E1341.92\n",
      "ocr_conf:  0.834\n",
      "1511/1662\n",
      "file_name: xemay530.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay530.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.3ms preprocess, 123.5ms inference, 4.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2486343\n",
      "recognized_text:  50-N1074.28\n",
      "ocr_conf:  0.913\n",
      "1512/1662\n",
      "file_name: xemay531.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay531.jpg: 416x640 1 plate, 130.7ms\n",
      "Speed: 4.6ms preprocess, 130.7ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1967208\n",
      "recognized_text:  55-P62004\n",
      "ocr_conf:  0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay540.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513/1662\n",
      "file_name: xemay540.jpg\n",
      "aspect_ratio: 1.1904662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60-X94808\n",
      "ocr_conf:  0.877\n",
      "1514/1662\n",
      "file_name: xemay541.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay541.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.4ms preprocess, 122.9ms inference, 12.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2213925\n",
      "recognized_text:  63-B1320.04\n",
      "ocr_conf:  0.854\n",
      "1515/1662\n",
      "file_name: xemay550.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay550.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.6ms preprocess, 123.6ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2015013\n",
      "recognized_text:  59-01576.74\n",
      "ocr_conf:  0.924\n",
      "1516/1662\n",
      "file_name: xemay551.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay551.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 5.7ms preprocess, 123.1ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1958557\n",
      "recognized_text:  86-C1072.61\n",
      "ocr_conf:  0.897\n",
      "1517/1662\n",
      "file_name: xemay560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay560.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 7.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1760312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay561.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-F1030.55\n",
      "ocr_conf:  0.913\n",
      "1518/1662\n",
      "file_name: xemay561.jpg\n",
      "aspect_ratio: 1.1992908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay570.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.2ms preprocess, 122.7ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-E1645.16\n",
      "ocr_conf:  0.907\n",
      "1519/1662\n",
      "file_name: xemay570.jpg\n",
      "aspect_ratio: 1.2039393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay571.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79.N1791.17\n",
      "ocr_conf:  0.912\n",
      "1520/1662\n",
      "file_name: xemay571.jpg\n",
      "aspect_ratio: 1.188088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay580.jpg: 416x640 1 plate, 124.6ms\n",
      "Speed: 4.2ms preprocess, 124.6ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  92-01427.05\n",
      "ocr_conf:  0.91\n",
      "1521/1662\n",
      "file_name: xemay580.jpg\n",
      "aspect_ratio: 1.1880442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  63-H31295\n",
      "ocr_conf:  0.902\n",
      "1522/1662\n",
      "file_name: xemay581.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay581.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.5ms preprocess, 123.0ms inference, 7.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.193109\n",
      "recognized_text:  51-K61392\n",
      "ocr_conf:  0.934\n",
      "1523/1662\n",
      "file_name: xemay590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay590.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1269319\n",
      "recognized_text:  67-E1054.20\n",
      "ocr_conf:  0.862\n",
      "1524/1662\n",
      "file_name: xemay591.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay591.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1457849\n",
      "recognized_text:  51-Z30606\n",
      "ocr_conf:  0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay60.jpg: 416x640 1 plate, 128.4ms\n",
      "Speed: 4.5ms preprocess, 128.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525/1662\n",
      "file_name: xemay60.jpg\n",
      "aspect_ratio: 1.1103584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay600.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C1622.93\n",
      "ocr_conf:  0.894\n",
      "1526/1662\n",
      "file_name: xemay600.jpg\n",
      "aspect_ratio: 1.1610224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay601.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.2ms preprocess, 123.2ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-R24924\n",
      "ocr_conf:  0.95\n",
      "1527/1662\n",
      "file_name: xemay601.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1985738\n",
      "recognized_text:  60-B2361.61\n",
      "ocr_conf:  0.92\n",
      "1528/1662\n",
      "file_name: xemay61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay61.jpg: 416x640 1 plate, 129.2ms\n",
      "Speed: 4.4ms preprocess, 129.2ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1885655\n",
      "recognized_text:  59-01396.19\n",
      "ocr_conf:  0.898\n",
      "1529/1662\n",
      "file_name: xemay610.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay610.jpg: 416x640 1 plate, 130.9ms\n",
      "Speed: 4.5ms preprocess, 130.9ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2235171\n",
      "recognized_text:  59T1183.62\n",
      "ocr_conf:  0.919\n",
      "1530/1662\n",
      "file_name: xemay611.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay611.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.0ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2008396\n",
      "recognized_text:  59-01399.97\n",
      "ocr_conf:  0.901\n",
      "1531/1662\n",
      "file_name: xemay620.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay620.jpg: 416x640 1 plate, 125.2ms\n",
      "Speed: 5.6ms preprocess, 125.2ms inference, 4.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1821872\n",
      "recognized_text:  59-L1567.20\n",
      "ocr_conf:  0.888\n",
      "1532/1662\n",
      "file_name: xemay621.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay621.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.184819\n",
      "recognized_text:  54-S85489\n",
      "ocr_conf:  0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay630.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.1ms preprocess, 123.2ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533/1662\n",
      "file_name: xemay630.jpg\n",
      "aspect_ratio: 1.1793118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay631.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.7ms preprocess, 122.9ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-E1550.40\n",
      "ocr_conf:  0.932\n",
      "1534/1662\n",
      "file_name: xemay631.jpg\n",
      "aspect_ratio: 1.2077351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay640.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.6ms preprocess, 123.2ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S1394.87\n",
      "ocr_conf:  0.861\n",
      "1535/1662\n",
      "file_name: xemay640.jpg\n",
      "aspect_ratio: 1.1858205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay641.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.4ms preprocess, 122.7ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  8686218.90\n",
      "ocr_conf:  0.924\n",
      "1536/1662\n",
      "file_name: xemay641.jpg\n",
      "aspect_ratio: 1.14568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay650.jpg: 416x640 1 plate, 123.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79.C13221.77\n",
      "ocr_conf:  0.87\n",
      "1537/1662\n",
      "file_name: xemay650.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.7ms preprocess, 123.4ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1802318\n",
      "recognized_text:  62-K1179.29\n",
      "ocr_conf:  0.901\n",
      "1538/1662\n",
      "file_name: xemay651.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay651.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 5.6ms preprocess, 123.6ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1909251\n",
      "recognized_text:  59-E1179.36\n",
      "ocr_conf:  0.888\n",
      "1539/1662\n",
      "file_name: xemay660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay660.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1741111\n",
      "recognized_text:  49-E115383\n",
      "ocr_conf:  0.905\n",
      "1540/1662\n",
      "file_name: xemay661.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay661.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.4ms preprocess, 123.8ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1511482\n",
      "recognized_text:  59-T1052.97\n",
      "ocr_conf:  0.864\n",
      "1541/1662\n",
      "file_name: xemay670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay670.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.2ms preprocess, 124.0ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2361342\n",
      "recognized_text:  54-P72138\n",
      "ocr_conf:  0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542/1662\n",
      "file_name: xemay671.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay671.jpg: 416x640 1 plate, 127.5ms\n",
      "Speed: 4.4ms preprocess, 127.5ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2158788\n",
      "recognized_text:  59-H1193.74\n",
      "ocr_conf:  0.935\n",
      "1543/1662\n",
      "file_name: xemay680.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay680.jpg: 416x640 1 plate, 121.1ms\n",
      "Speed: 4.5ms preprocess, 121.1ms inference, 8.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1062281\n",
      "recognized_text:  53-211759\n",
      "ocr_conf:  0.925\n",
      "1544/1662\n",
      "file_name: xemay681.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay681.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.6ms preprocess, 122.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2030696\n",
      "recognized_text:  59-L1459.00\n",
      "ocr_conf:  0.873\n",
      "1545/1662\n",
      "file_name: xemay690.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay690.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.2ms preprocess, 122.7ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2667367\n",
      "recognized_text:  59K1130.99\n",
      "ocr_conf:  0.928\n",
      "1546/1662\n",
      "file_name: xemay691.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay691.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.1ms preprocess, 123.7ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1771309\n",
      "recognized_text:  63-B2163.53\n",
      "ocr_conf:  0.901\n",
      "1547/1662\n",
      "file_name: xemay70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay70.jpg: 416x640 1 plate, 122.2ms\n",
      "Speed: 4.7ms preprocess, 122.2ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1794432\n",
      "recognized_text:  54L24264\n",
      "ocr_conf:  0.931\n",
      "1548/1662\n",
      "file_name: xemay700.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay700.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2109058\n",
      "recognized_text:  59M1077.90\n",
      "ocr_conf:  0.857\n",
      "1549/1662\n",
      "file_name: xemay701.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay701.jpg: 416x640 1 plate, 133.3ms\n",
      "Speed: 4.1ms preprocess, 133.3ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1596347\n",
      "recognized_text:  52-F41035\n",
      "ocr_conf:  0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay71.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 4.6ms preprocess, 121.8ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550/1662\n",
      "file_name: xemay71.jpg\n",
      "aspect_ratio: 1.1468189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay710.jpg: 416x640 1 plate, 121.8ms\n",
      "Speed: 4.5ms preprocess, 121.8ms inference, 3.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59.C1653.31\n",
      "ocr_conf:  0.903\n",
      "1551/1662\n",
      "file_name: xemay710.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2216107\n",
      "recognized_text:  47-H25226\n",
      "ocr_conf:  0.864\n",
      "1552/1662\n",
      "file_name: xemay711.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay711.jpg: 416x640 1 plate, 124.1ms\n",
      "Speed: 4.3ms preprocess, 124.1ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1955774\n",
      "recognized_text:  59-P2323.34\n",
      "ocr_conf:  0.933\n",
      "1553/1662\n",
      "file_name: xemay720.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay720.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2090241\n",
      "recognized_text:  52-U62655\n",
      "ocr_conf:  0.936\n",
      "1554/1662\n",
      "file_name: xemay721.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay721.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.5ms preprocess, 123.8ms inference, 5.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2253587\n",
      "recognized_text:  54V38314\n",
      "ocr_conf:  0.952\n",
      "1555/1662\n",
      "file_name: xemay730.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay730.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.6ms preprocess, 123.8ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.178922\n",
      "recognized_text:  54-K16483\n",
      "ocr_conf:  0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay731.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.7ms preprocess, 122.6ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1662\n",
      "file_name: xemay731.jpg\n",
      "aspect_ratio: 1.1785082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay740.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.9ms preprocess, 122.9ms inference, 4.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-F30096\n",
      "ocr_conf:  0.912\n",
      "1557/1662\n",
      "file_name: xemay740.jpg\n",
      "aspect_ratio: 1.248387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay741.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.1ms preprocess, 123.1ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C2492.00\n",
      "ocr_conf:  0.896\n",
      "1558/1662\n",
      "file_name: xemay741.jpg\n",
      "aspect_ratio: 1.1302506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-U1517.71\n",
      "ocr_conf:  0.912\n",
      "1559/1662\n",
      "file_name: xemay750.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay750.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.2ms preprocess, 123.6ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1040618\n",
      "recognized_text:  59-P1479.69\n",
      "ocr_conf:  0.938\n",
      "1560/1662\n",
      "file_name: xemay751.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay751.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2199682\n",
      "recognized_text:  60B8499.28\n",
      "ocr_conf:  0.861\n",
      "1561/1662\n",
      "file_name: xemay760.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay760.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.2ms preprocess, 123.4ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1590544\n",
      "recognized_text:  51X91894\n",
      "ocr_conf:  0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1662\n",
      "file_name: xemay761.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay761.jpg: 416x640 1 plate, 122.3ms\n",
      "Speed: 4.4ms preprocess, 122.3ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1945974\n",
      "recognized_text:  52-S24832\n",
      "ocr_conf:  0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay770.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.3ms preprocess, 123.3ms inference, 4.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1662\n",
      "file_name: xemay770.jpg\n",
      "aspect_ratio: 1.2155405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay771.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.3ms preprocess, 123.2ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-D1202.55\n",
      "ocr_conf:  0.872\n",
      "1564/1662\n",
      "file_name: xemay771.jpg\n",
      "aspect_ratio: 1.1836455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay780.jpg: 416x640 1 plate, 122.6ms\n",
      "Speed: 4.5ms preprocess, 122.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-Y1713.64\n",
      "ocr_conf:  0.93\n",
      "1565/1662\n",
      "file_name: xemay780.jpg\n",
      "aspect_ratio: 1.1790985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-Z1206.81\n",
      "ocr_conf:  0.925\n",
      "1566/1662\n",
      "file_name: xemay781.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay781.jpg: 416x640 1 plate, 124.2ms\n",
      "Speed: 4.4ms preprocess, 124.2ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1505729\n",
      "recognized_text:  54-119588\n",
      "ocr_conf:  0.9\n",
      "1567/1662\n",
      "file_name: xemay790.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay790.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.2ms preprocess, 123.8ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1522136\n",
      "recognized_text:  49-E1153.83\n",
      "ocr_conf:  0.909\n",
      "1568/1662\n",
      "file_name: xemay791.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay791.jpg: 416x640 1 plate, 123.9ms\n",
      "Speed: 4.6ms preprocess, 123.9ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2107018\n",
      "recognized_text:  59-Y1919.82\n",
      "ocr_conf:  0.903\n",
      "1569/1662\n",
      "file_name: xemay80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay80.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.5ms preprocess, 123.6ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2987285\n",
      "recognized_text:  51-R56273\n",
      "ocr_conf:  0.953\n",
      "1570/1662\n",
      "file_name: xemay800.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay800.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1705419\n",
      "recognized_text:  59-1138.26\n",
      "ocr_conf:  0.893\n",
      "1571/1662\n",
      "file_name: xemay801.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay801.jpg: 416x640 1 plate, 125.0ms\n",
      "Speed: 4.2ms preprocess, 125.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2168604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay81.jpg: 416x640 1 plate, 121.5ms\n",
      "Speed: 4.6ms preprocess, 121.5ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P1972.55\n",
      "ocr_conf:  0.93\n",
      "1572/1662\n",
      "file_name: xemay81.jpg\n",
      "aspect_ratio: 1.2897708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay810.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-L1974.57\n",
      "ocr_conf:  0.931\n",
      "1573/1662\n",
      "file_name: xemay810.jpg\n",
      "aspect_ratio: 1.18418\n",
      "recognized_text:  79-N16788\n",
      "ocr_conf:  0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay811.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574/1662\n",
      "file_name: xemay811.jpg\n",
      "aspect_ratio: 1.2031276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay820.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.3ms preprocess, 123.1ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-L1810.06\n",
      "ocr_conf:  0.924\n",
      "1575/1662\n",
      "file_name: xemay820.jpg\n",
      "aspect_ratio: 1.175158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay821.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-L1894.75\n",
      "ocr_conf:  0.89\n",
      "1576/1662\n",
      "file_name: xemay821.jpg\n",
      "aspect_ratio: 1.2810488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  81-H12204\n",
      "ocr_conf:  0.95\n",
      "1577/1662\n",
      "file_name: xemay830.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay830.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1401459\n",
      "recognized_text:  60-F2019.49\n",
      "ocr_conf:  0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay831.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 4.3ms preprocess, 122.4ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578/1662\n",
      "file_name: xemay831.jpg\n",
      "aspect_ratio: 1.2391834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay840.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  54-P81515\n",
      "ocr_conf:  0.918\n",
      "1579/1662\n",
      "file_name: xemay840.jpg\n",
      "aspect_ratio: 1.230209\n",
      "recognized_text:  59K2012.24\n",
      "ocr_conf:  0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580/1662\n",
      "file_name: xemay841.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay841.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.6ms preprocess, 122.8ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1586924\n",
      "recognized_text:  82-81197.89\n",
      "ocr_conf:  0.895\n",
      "1581/1662\n",
      "file_name: xemay850.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay850.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.5ms preprocess, 123.7ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.190612\n",
      "recognized_text:  59-P1837.38\n",
      "ocr_conf:  0.909\n",
      "1582/1662\n",
      "file_name: xemay851.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay851.jpg: 416x640 1 plate, 124.0ms\n",
      "Speed: 4.4ms preprocess, 124.0ms inference, 7.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.219446\n",
      "recognized_text:  59-H1354.60\n",
      "ocr_conf:  0.876\n",
      "1583/1662\n",
      "file_name: xemay860.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay860.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1503143\n",
      "recognized_text:  59-G1152.55\n",
      "ocr_conf:  0.884\n",
      "1584/1662\n",
      "file_name: xemay861.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay861.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 6.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2070851\n",
      "recognized_text:  51-R52701\n",
      "ocr_conf:  0.949\n",
      "1585/1662\n",
      "file_name: xemay870.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay870.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.2ms preprocess, 123.3ms inference, 5.6ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1798818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay871.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.6ms preprocess, 123.0ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-1001.79\n",
      "ocr_conf:  0.933\n",
      "1586/1662\n",
      "file_name: xemay871.jpg\n",
      "aspect_ratio: 1.111678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay880.jpg: 416x640 1 plate, 123.1ms\n",
      "Speed: 4.2ms preprocess, 123.1ms inference, 5.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-P1972.55\n",
      "ocr_conf:  0.94\n",
      "1587/1662\n",
      "file_name: xemay880.jpg\n",
      "aspect_ratio: 1.1991354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay881.jpg: 416x640 1 plate, 122.7ms\n",
      "Speed: 4.4ms preprocess, 122.7ms inference, 4.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-S1944.22\n",
      "ocr_conf:  0.846\n",
      "1588/1662\n",
      "file_name: xemay881.jpg\n",
      "aspect_ratio: 1.1993253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay890.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.8ms preprocess, 123.5ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-C1230.83\n",
      "ocr_conf:  0.932\n",
      "1589/1662\n",
      "file_name: xemay890.jpg\n",
      "aspect_ratio: 1.1552898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay891.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 4.4ms preprocess, 123.2ms inference, 13.9ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  60-85118.27\n",
      "ocr_conf:  0.916\n",
      "1590/1662\n",
      "file_name: xemay891.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2744924\n",
      "recognized_text:  59-C2527.95\n",
      "ocr_conf:  0.945\n",
      "1591/1662\n",
      "file_name: xemay90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay90.jpg: 416x640 1 plate, 124.8ms\n",
      "Speed: 4.6ms preprocess, 124.8ms inference, 9.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1724367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-X2683.27\n",
      "ocr_conf:  0.883\n",
      "1592/1662\n",
      "file_name: xemay900.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay900.jpg: 416x640 1 plate, 123.8ms\n",
      "Speed: 4.3ms preprocess, 123.8ms inference, 6.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2072641\n",
      "recognized_text:  59-H1547.92\n",
      "ocr_conf:  0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593/1662\n",
      "file_name: xemay901.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay901.jpg: 416x640 1 plate, 124.5ms\n",
      "Speed: 4.5ms preprocess, 124.5ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1475307\n",
      "recognized_text:  59-P2323.34\n",
      "ocr_conf:  0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay91.jpg: 416x640 1 plate, 123.3ms\n",
      "Speed: 4.4ms preprocess, 123.3ms inference, 4.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1662\n",
      "file_name: xemay91.jpg\n",
      "aspect_ratio: 1.1953638\n",
      "recognized_text:  67-B1818.46\n",
      "ocr_conf:  0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay910.jpg: 416x640 1 plate, 127.4ms\n",
      "Speed: 4.5ms preprocess, 127.4ms inference, 4.8ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595/1662\n",
      "file_name: xemay910.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1661991\n",
      "recognized_text:  59-L1481.83\n",
      "ocr_conf:  0.929\n",
      "1596/1662\n",
      "file_name: xemay911.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay911.jpg: 416x640 1 plate, 122.9ms\n",
      "Speed: 4.5ms preprocess, 122.9ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.210827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay920.jpg: 416x640 1 plate, 126.1ms\n",
      "Speed: 4.5ms preprocess, 126.1ms inference, 5.1ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-E1029.93\n",
      "ocr_conf:  0.887\n",
      "1597/1662\n",
      "file_name: xemay920.jpg\n",
      "aspect_ratio: 1.2125671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  52-F73840\n",
      "ocr_conf:  0.946\n",
      "1598/1662\n",
      "file_name: xemay921.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay921.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 13.4ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1593463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  49-L1044.56\n",
      "ocr_conf:  0.872\n",
      "1599/1662\n",
      "file_name: xemay930.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay930.jpg: 416x640 1 plate, 123.2ms\n",
      "Speed: 5.6ms preprocess, 123.2ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2525609\n",
      "recognized_text:  75-F1029.91\n",
      "ocr_conf:  0.911\n",
      "1600/1662\n",
      "file_name: xemay931.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay931.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 4.3ms preprocess, 123.7ms inference, 6.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1816212\n",
      "recognized_text:  59-P2083.24\n",
      "ocr_conf:  0.943\n",
      "1601/1662\n",
      "file_name: xemay940.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay940.jpg: 416x640 1 plate, 122.8ms\n",
      "Speed: 4.3ms preprocess, 122.8ms inference, 5.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1435729\n",
      "recognized_text:  77-H1068.30\n",
      "ocr_conf:  0.886\n",
      "1602/1662\n",
      "file_name: xemay941.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay941.jpg: 416x640 1 plate, 123.7ms\n",
      "Speed: 5.3ms preprocess, 123.7ms inference, 4.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1682228\n",
      "recognized_text:  77-C1226.97\n",
      "ocr_conf:  0.921\n",
      "1603/1662\n",
      "file_name: xemay950.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay950.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 6.0ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2069863\n",
      "recognized_text:  59-P1857.00\n",
      "ocr_conf:  0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604/1662\n",
      "file_name: xemay951.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay951.jpg: 416x640 1 plate, 122.4ms\n",
      "Speed: 4.4ms preprocess, 122.4ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2443945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  59-FA009.82\n",
      "ocr_conf:  0.929\n",
      "1605/1662\n",
      "file_name: xemay960.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay960.jpg: 416x640 1 plate, 123.0ms\n",
      "Speed: 4.4ms preprocess, 123.0ms inference, 4.1ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2951922\n",
      "recognized_text:  51-L68446\n",
      "ocr_conf:  0.908\n",
      "1606/1662\n",
      "file_name: xemay961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay961.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.6ms preprocess, 123.4ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1981583\n",
      "recognized_text:  67-N1208.86\n",
      "ocr_conf:  0.932\n",
      "1607/1662\n",
      "file_name: xemay970.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay970.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.6ms preprocess, 123.5ms inference, 5.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2127975\n",
      "recognized_text:  71-B2079.99\n",
      "ocr_conf:  0.913\n",
      "1608/1662\n",
      "file_name: xemay971.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay971.jpg: 416x640 1 plate, 128.1ms\n",
      "Speed: 5.3ms preprocess, 128.1ms inference, 89.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1671481\n",
      "recognized_text:  60-B1491.39\n",
      "ocr_conf:  0.918\n",
      "1609/1662\n",
      "file_name: xemay980.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay980.jpg: 416x640 1 plate, 123.5ms\n",
      "Speed: 4.2ms preprocess, 123.5ms inference, 6.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1787384\n",
      "recognized_text:  54-H44091\n",
      "ocr_conf:  0.891\n",
      "1610/1662\n",
      "file_name: xemay981.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay981.jpg: 416x640 1 plate, 123.6ms\n",
      "Speed: 4.4ms preprocess, 123.6ms inference, 5.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1360388\n",
      "recognized_text:  54-23213\n",
      "ocr_conf:  0.958\n",
      "1611/1662\n",
      "file_name: xemay990.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay990.jpg: 416x640 1 plate, 122.0ms\n",
      "Speed: 4.2ms preprocess, 122.0ms inference, 5.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3354065\n",
      "recognized_text:  54-S25505\n",
      "ocr_conf:  0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemay991.jpg: 416x640 1 plate, 123.4ms\n",
      "Speed: 4.3ms preprocess, 123.4ms inference, 14.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612/1662\n",
      "file_name: xemay991.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1846515\n",
      "recognized_text:  54-S16830\n",
      "ocr_conf:  0.908\n",
      "1613/1662\n",
      "file_name: xemayBigPlate0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate0.jpg: 480x640 1 plate, 135.0ms\n",
      "Speed: 8.2ms preprocess, 135.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3760766\n",
      "recognized_text:  65-L1007.80\n",
      "ocr_conf:  0.921\n",
      "1614/1662\n",
      "file_name: xemayBigPlate1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate1.jpg: 480x640 1 plate, 124.9ms\n",
      "Speed: 6.3ms preprocess, 124.9ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3726482\n",
      "recognized_text:  83-FD9972\n",
      "ocr_conf:  0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate10.jpg: 480x640 1 plate, 132.9ms\n",
      "Speed: 7.9ms preprocess, 132.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1615/1662\n",
      "file_name: xemayBigPlate10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4294302\n",
      "recognized_text:  67-V15283\n",
      "ocr_conf:  0.93\n",
      "1616/1662\n",
      "file_name: xemayBigPlate100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate100.jpg: 480x640 1 plate, 132.7ms\n",
      "Speed: 4.7ms preprocess, 132.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3719512\n",
      "recognized_text:  83-F74166\n",
      "ocr_conf:  0.933\n",
      "1617/1662\n",
      "file_name: xemayBigPlate101.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate101.jpg: 480x640 1 plate, 132.7ms\n",
      "Speed: 5.2ms preprocess, 132.7ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4145008\n",
      "recognized_text:  83-P1649.32\n",
      "ocr_conf:  0.956\n",
      "1618/1662\n",
      "file_name: xemayBigPlate11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate11.jpg: 480x640 1 plate, 133.1ms\n",
      "Speed: 5.1ms preprocess, 133.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3745906\n",
      "recognized_text:  65-X45189\n",
      "ocr_conf:  0.941\n",
      "1619/1662\n",
      "file_name: xemayBigPlate110.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate110.jpg: 480x640 1 plate, 132.9ms\n",
      "Speed: 5.1ms preprocess, 132.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3945487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  64-H60496\n",
      "ocr_conf:  0.958\n",
      "1620/1662\n",
      "file_name: xemayBigPlate111.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate111.jpg: 480x640 1 plate, 133.4ms\n",
      "Speed: 4.8ms preprocess, 133.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4293612\n",
      "recognized_text:  67-L96914\n",
      "ocr_conf:  0.956\n",
      "1621/1662\n",
      "file_name: xemayBigPlate120.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate120.jpg: 480x640 1 plate, 133.2ms\n",
      "Speed: 5.3ms preprocess, 133.2ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3788245\n",
      "recognized_text:  65-P96067\n",
      "ocr_conf:  0.935\n",
      "1622/1662\n",
      "file_name: xemayBigPlate121.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate121.jpg: 480x640 1 plate, 135.1ms\n",
      "Speed: 4.9ms preprocess, 135.1ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3453267\n",
      "recognized_text:  65-V13038\n",
      "ocr_conf:  0.939\n",
      "1623/1662\n",
      "file_name: xemayBigPlate130.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate130.jpg: 480x640 1 plate, 133.6ms\n",
      "Speed: 6.9ms preprocess, 133.6ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4066484\n",
      "recognized_text:  71-FM0430\n",
      "ocr_conf:  0.931\n",
      "1624/1662\n",
      "file_name: xemayBigPlate131.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate131.jpg: 480x640 1 plate, 133.2ms\n",
      "Speed: 5.4ms preprocess, 133.2ms inference, 13.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.333448\n",
      "recognized_text:  94-E1022.09\n",
      "ocr_conf:  0.952\n",
      "1625/1662\n",
      "file_name: xemayBigPlate140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate140.jpg: 480x640 2 plates, 125.3ms\n",
      "Speed: 5.2ms preprocess, 125.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3151593\n",
      "recognized_text:  67-M65297\n",
      "ocr_conf:  0.932\n",
      "1626/1662\n",
      "file_name: xemayBigPlate141.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate141.jpg: 480x640 2 plates, 130.4ms\n",
      "Speed: 5.2ms preprocess, 130.4ms inference, 14.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3661458\n",
      "recognized_text:  68-P27299\n",
      "ocr_conf:  0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1627/1662\n",
      "file_name: xemayBigPlate150.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate150.jpg: 480x640 1 plate, 141.7ms\n",
      "Speed: 5.3ms preprocess, 141.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3854932\n",
      "recognized_text:  69-010561\n",
      "ocr_conf:  0.931\n",
      "1628/1662\n",
      "file_name: xemayBigPlate151.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate151.jpg: 480x640 1 plate, 133.6ms\n",
      "Speed: 5.0ms preprocess, 133.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4306098\n",
      "recognized_text:  71-FM0430\n",
      "ocr_conf:  0.939\n",
      "1629/1662\n",
      "file_name: xemayBigPlate160.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate160.jpg: 480x640 1 plate, 133.5ms\n",
      "Speed: 4.7ms preprocess, 133.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3941599\n",
      "recognized_text:  83H92735\n",
      "ocr_conf:  0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate161.jpg: 480x640 1 plate, 132.8ms\n",
      "Speed: 5.4ms preprocess, 132.8ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630/1662\n",
      "file_name: xemayBigPlate161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4510299\n",
      "recognized_text:  66L43551\n",
      "ocr_conf:  0.956\n",
      "1631/1662\n",
      "file_name: xemayBigPlate170.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate170.jpg: 480x640 1 plate, 132.8ms\n",
      "Speed: 5.6ms preprocess, 132.8ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4192513\n",
      "recognized_text:  65-K1041.14\n",
      "ocr_conf:  0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632/1662\n",
      "file_name: xemayBigPlate171.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate171.jpg: 480x640 1 plate, 133.5ms\n",
      "Speed: 9.5ms preprocess, 133.5ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4455975\n",
      "recognized_text:  69-T13141\n",
      "ocr_conf:  0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate180.jpg: 480x640 1 plate, 133.0ms\n",
      "Speed: 5.4ms preprocess, 133.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633/1662\n",
      "file_name: xemayBigPlate180.jpg\n",
      "aspect_ratio: 1.3002031\n",
      "recognized_text:  84-V10819\n",
      "ocr_conf:  0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate181.jpg: 480x640 1 plate, 131.5ms\n",
      "Speed: 5.0ms preprocess, 131.5ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634/1662\n",
      "file_name: xemayBigPlate181.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3255988\n",
      "recognized_text:  66-V1089.13\n",
      "ocr_conf:  0.932\n",
      "1635/1662\n",
      "file_name: xemayBigPlate190.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate190.jpg: 512x640 1 plate, 143.5ms\n",
      "Speed: 5.2ms preprocess, 143.5ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.2987615\n",
      "recognized_text:  68-M70753\n",
      "ocr_conf:  0.919\n",
      "1636/1662\n",
      "file_name: xemayBigPlate191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate191.jpg: 512x640 1 plate, 139.7ms\n",
      "Speed: 5.3ms preprocess, 139.7ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3111206\n",
      "recognized_text:  83-K170496\n",
      "ocr_conf:  0.917\n",
      "1637/1662\n",
      "file_name: xemayBigPlate20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate20.jpg: 480x640 2 plates, 136.0ms\n",
      "Speed: 5.1ms preprocess, 136.0ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3815509\n",
      "recognized_text:  65P77280\n",
      "ocr_conf:  0.98\n",
      "1638/1662\n",
      "file_name: xemayBigPlate200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate200.jpg: 512x640 1 plate, 138.2ms\n",
      "Speed: 5.2ms preprocess, 138.2ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3357288\n",
      "recognized_text:  65-F82907\n",
      "ocr_conf:  0.924\n",
      "1639/1662\n",
      "file_name: xemayBigPlate201.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate201.jpg: 512x640 1 plate, 140.6ms\n",
      "Speed: 5.2ms preprocess, 140.6ms inference, 5.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3244894\n",
      "recognized_text:  83-N11216\n",
      "ocr_conf:  0.972\n",
      "1640/1662\n",
      "file_name: xemayBigPlate21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate21.jpg: 480x640 1 plate, 138.2ms\n",
      "Speed: 4.8ms preprocess, 138.2ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3886073\n",
      "recognized_text:  67-M22526\n",
      "ocr_conf:  0.95\n",
      "1641/1662\n",
      "file_name: xemayBigPlate210.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate210.jpg: 512x640 2 plates, 142.9ms\n",
      "Speed: 5.2ms preprocess, 142.9ms inference, 10.5ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3287812\n",
      "recognized_text:  65.P79679\n",
      "ocr_conf:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate211.jpg: 512x640 1 plate, 134.7ms\n",
      "Speed: 5.2ms preprocess, 134.7ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642/1662\n",
      "file_name: xemayBigPlate211.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3357002\n",
      "recognized_text:  65-R177326\n",
      "ocr_conf:  0.899\n",
      "1643/1662\n",
      "file_name: xemayBigPlate220.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate220.jpg: 512x640 1 plate, 140.1ms\n",
      "Speed: 5.2ms preprocess, 140.1ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3513001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  95-H15032\n",
      "ocr_conf:  0.956\n",
      "1644/1662\n",
      "file_name: xemayBigPlate221.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate221.jpg: 512x640 1 plate, 140.3ms\n",
      "Speed: 5.1ms preprocess, 140.3ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3511912\n",
      "recognized_text:  65-B1045.66\n",
      "ocr_conf:  0.965\n",
      "1645/1662\n",
      "file_name: xemayBigPlate230.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate230.jpg: 512x640 1 plate, 140.3ms\n",
      "Speed: 4.9ms preprocess, 140.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4250435\n",
      "recognized_text:  65-R22520\n",
      "ocr_conf:  0.964\n",
      "1646/1662\n",
      "file_name: xemayBigPlate231.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate231.jpg: 512x640 1 plate, 140.4ms\n",
      "Speed: 5.2ms preprocess, 140.4ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3663487\n",
      "recognized_text:  83.C1032.43\n",
      "ocr_conf:  0.927\n",
      "1647/1662\n",
      "file_name: xemayBigPlate240.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate240.jpg: 512x640 1 plate, 140.4ms\n",
      "Speed: 5.2ms preprocess, 140.4ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3613923\n",
      "recognized_text:  65-P73835\n",
      "ocr_conf:  0.938\n",
      "1648/1662\n",
      "file_name: xemayBigPlate241.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate241.jpg: 512x640 1 plate, 140.0ms\n",
      "Speed: 5.6ms preprocess, 140.0ms inference, 6.4ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3882194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  69-F1023.41\n",
      "ocr_conf:  0.929\n",
      "1649/1662\n",
      "file_name: xemayBigPlate30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate30.jpg: 480x640 2 plates, 135.3ms\n",
      "Speed: 9.0ms preprocess, 135.3ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4104972\n",
      "recognized_text:  65-HC1012\n",
      "ocr_conf:  0.945\n",
      "1650/1662\n",
      "file_name: xemayBigPlate31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate31.jpg: 480x640 1 plate, 133.6ms\n",
      "Speed: 5.1ms preprocess, 133.6ms inference, 15.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3439577\n",
      "recognized_text:  63-B1056.06\n",
      "ocr_conf:  0.923\n",
      "1651/1662\n",
      "file_name: xemayBigPlate40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate40.jpg: 480x640 2 plates, 133.4ms\n",
      "Speed: 5.3ms preprocess, 133.4ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3709346\n",
      "recognized_text:  66-N17071.10\n",
      "ocr_conf:  0.903\n",
      "1652/1662\n",
      "file_name: xemayBigPlate41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate41.jpg: 480x640 1 plate, 133.4ms\n",
      "Speed: 5.0ms preprocess, 133.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.409283\n",
      "recognized_text:  66-M28530\n",
      "ocr_conf:  0.975\n",
      "1653/1662\n",
      "file_name: xemayBigPlate50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate50.jpg: 480x640 1 plate, 133.3ms\n",
      "Speed: 5.1ms preprocess, 133.3ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4896262\n",
      "recognized_text:  94-H34198\n",
      "ocr_conf:  0.905\n",
      "1654/1662\n",
      "file_name: xemayBigPlate51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate51.jpg: 480x640 2 plates, 142.1ms\n",
      "Speed: 5.4ms preprocess, 142.1ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4109823\n",
      "recognized_text:  65-M21617\n",
      "ocr_conf:  0.943\n",
      "1655/1662\n",
      "file_name: xemayBigPlate60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate60.jpg: 480x640 1 plate, 133.5ms\n",
      "Speed: 5.2ms preprocess, 133.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.504555\n",
      "recognized_text:  69-K65604\n",
      "ocr_conf:  0.94\n",
      "1656/1662\n",
      "file_name: xemayBigPlate61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate61.jpg: 480x640 1 plate, 320.6ms\n",
      "Speed: 5.3ms preprocess, 320.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4202236\n",
      "recognized_text:  95-018284\n",
      "ocr_conf:  0.885\n",
      "1657/1662\n",
      "file_name: xemayBigPlate70.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate70.jpg: 480x640 1 plate, 134.2ms\n",
      "Speed: 5.1ms preprocess, 134.2ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5866383\n",
      "recognized_text:  69-F68587\n",
      "ocr_conf:  0.951\n",
      "1658/1662\n",
      "file_name: xemayBigPlate71.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate71.jpg: 480x640 1 plate, 129.0ms\n",
      "Speed: 5.1ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5088599\n",
      "recognized_text:  83-S58378\n",
      "ocr_conf:  0.94\n",
      "1659/1662\n",
      "file_name: xemayBigPlate80.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate80.jpg: 480x640 1 plate, 131.1ms\n",
      "Speed: 5.5ms preprocess, 131.1ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.4660844\n",
      "recognized_text:  83-S63309\n",
      "ocr_conf:  0.909\n",
      "1660/1662\n",
      "file_name: xemayBigPlate81.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate81.jpg: 480x640 2 plates, 133.5ms\n",
      "Speed: 4.9ms preprocess, 133.5ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3247019\n",
      "recognized_text:  94-F1042.17\n",
      "ocr_conf:  0.928\n",
      "1661/1662\n",
      "file_name: xemayBigPlate90.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate90.jpg: 480x640 1 plate, 133.0ms\n",
      "Speed: 5.5ms preprocess, 133.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.404232\n",
      "recognized_text:  64-H69743\n",
      "ocr_conf:  0.962\n",
      "1662/1662\n",
      "file_name: xemayBigPlate91.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /mnt/d/BKHN/alpr_project/learnopencv/images/images_val/xemayBigPlate91.jpg: 480x640 1 plate, 133.4ms\n",
      "Speed: 4.9ms preprocess, 133.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.3883362\n",
      "recognized_text:  67T34461\n",
      "ocr_conf:  0.97\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Usage example\n",
    "files = glob.glob('./images/images_val/*.jpg', recursive = True)\n",
    "\n",
    "x = 0\n",
    "y = len(files)\n",
    "for file in files:\n",
    "    x = x + 1\n",
    "    print(str(x) + \"/\" + str(y))\n",
    "    test_img_yolov8(file, './results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgcAjQ8QwGWI"
   },
   "source": [
    "## Function for inferencing on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "IEZjmmAX9pDJ"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8/alpr_yolov8n_8000img_100epochs.pt\") \n",
    "\n",
    "def test_vid_yolov8(vid_dir, out_path):\n",
    "    # Declaring variables for video processing.\n",
    "    cap = cv2.VideoCapture(vid_dir)\n",
    "    # Get the total frame count\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # file_name = os.path.join(out_path, 'out_' + vid_dir.split('/')[-1] + )\n",
    "    # out = cv2.VideoWriter(file_name, codec, fps, (width, height))\n",
    "    out = cv2.VideoWriter(out_path, codec, fps, (width, height))\n",
    "\n",
    "    # Frame count variable.\n",
    "    ct = 0\n",
    "    \n",
    "    # Reading video frame by frame.\n",
    "    while(cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        if ret == True:\n",
    "            print(str(ct) + \"/\" + str(total_frames))\n",
    "\n",
    "            # Noting time for calculating FPS.\n",
    "            prev_time = time.time()\n",
    "\n",
    "            # Use the model\n",
    "            results = model(img)  # predict on an image\n",
    "        \n",
    "            for result in results:\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    # Get the bounding boxes and image for each result\n",
    "                    bboxes = result.boxes[0].cpu().numpy()\n",
    "                    # img = cv2.imread(input)  # Đảm bảo bạn đã định nghĩa biến 'input'\n",
    "            \n",
    "                    # Loop through bboxes and apply OCR, then draw on the image\n",
    "                    for bbox in bboxes:\n",
    "                        xyxy = bbox.xyxy\n",
    "                        x1, y1, x2, y2 = xyxy[0]\n",
    "            \n",
    "                        # Kiểm tra xem biển số xe có gần vuông không (ví dụ: tỷ lệ 1:1)\n",
    "                        width = x2 - x1\n",
    "                        height = y2 - y1\n",
    "                        aspect_ratio = width / height\n",
    "                        print(\"aspect_ratio:\", aspect_ratio)\n",
    "            \n",
    "                        if 0 <= aspect_ratio <= 1.5:\n",
    "                            # Biển số xe gần vuông hoặc hình vuông\n",
    "            \n",
    "                            # Tính toán điểm chia ảnh thành hai phần trên và dưới\n",
    "                            split_point = y1 + (y2 - y1) // 2\n",
    "\n",
    "                            \n",
    "                            # Tạo hai phần ảnh con từ ảnh cr_img\n",
    "                            upper_part = img[int(y1):int(split_point), int(x1):int(x2)]\n",
    "                            lower_part = img[int(split_point):int(y2), int(x1):int(x2)]\n",
    "                            \n",
    "                            image_upper=cv2.resize(upper_part,(int(width),int(height/2)))\n",
    "                            image_lower=cv2.resize(lower_part,(int(width),int(height/2)))\n",
    "\n",
    "                            image_collage_horizontal =np.hstack([image_upper, image_lower])\n",
    "                            image_filename = str(ct) + \".jpg\"  # Tên file ảnh đầu ra\n",
    "                            cv2.imwrite(\"results/crop_image/\" + image_filename, image_collage_horizontal)\n",
    "            \n",
    "                            # Tiếp tục xử lý ảnh chữ nhật cr_img ở đây\n",
    "                            ocr_res = perform_ocr(image_collage_horizontal)\n",
    "            \n",
    "                            # Lưu hai phần ảnh\n",
    "                            # cv2.imwrite(\"results/upper_part.jpg\", upper_part)\n",
    "                            # cv2.imwrite(\"results/\" + str(ct) + \".jpg\", lower_part)\n",
    "                        else:\n",
    "                            # Biển số xe không gần vuông\n",
    "                            # Xử lý ảnh bình thường ở đây (cr_img = img[int(y1):int(y2), int(x1):int(x2)])\n",
    "                            cr_img = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "                            image_filename = str(ct) + \".jpg\"  # Tên file ảnh đầu ra\n",
    "                            cv2.imwrite(\"results/crop_image/\" + image_filename, cr_img)\n",
    "                            ocr_res = perform_ocr(cr_img)\n",
    "                        recognized_text = ocr_res[0][0][0] if ocr_res else \"No Text\"\n",
    "                        print(\"recognized_text: \",recognized_text)\n",
    "                        \n",
    "                        ocr_conf = ocr_res[0][0][1] if ocr_res else \"No Conf\"\n",
    "                        ocr_conf = round(ocr_conf,3)\n",
    "                        print(\"ocr_conf: \",ocr_conf)\n",
    "                        # Draw on the image\n",
    "                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)  # Red bounding box\n",
    "                        cv2.putText(img, recognized_text, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                        cv2.putText(img, str(ocr_conf), (int(x1) + 150, int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    # If there are no bounding boxes or the result is empty, skip this result\n",
    "                    continue\n",
    "\n",
    "            # Calculating time taken and FPS for the whole process.\n",
    "            tot_time = time.time() - prev_time\n",
    "            fps = round(1 / tot_time,2)\n",
    "\n",
    "            # Writing information onto the frame and saving it to be processed in a video.\n",
    "            cv2.putText(img, 'frame: %d fps: %s' % (ct, fps),\n",
    "                        (0, int(100 * 1)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)\n",
    "            out.write(img)\n",
    "\n",
    "            ct = ct + 1\n",
    "        else:\n",
    "            break\n",
    "def perform_ocr(image):\n",
    "    ocr_res = ocr.ocr(image, cls=False, det=False)\n",
    "    return ocr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ll_hQhdsrRGD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 77.4ms\n",
      "Speed: 300.4ms preprocess, 77.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.51499\n",
      "recognized_text:  BAY\n",
      "ocr_conf:  0.313\n",
      "1/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.1ms\n",
      "Speed: 4.7ms preprocess, 161.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5208719\n",
      "recognized_text:  Wye\n",
      "ocr_conf:  0.258\n",
      "2/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 154.0ms\n",
      "Speed: 4.5ms preprocess, 154.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.6ms\n",
      "Speed: 4.7ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 3.1ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/1162\n",
      "4/1162\n",
      "5/1162\n",
      "6/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.6ms preprocess, 26.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/1162\n",
      "8/1162\n",
      "aspect_ratio: 2.306135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 142.8ms\n",
      "Speed: 4.6ms preprocess, 142.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  CA\n",
      "ocr_conf:  0.413\n",
      "9/1162\n",
      "aspect_ratio: 2.4830503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 7.0ms preprocess, 164.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  C\n",
      "ocr_conf:  0.224\n",
      "10/1162\n",
      "aspect_ratio: 2.5402699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  C\n",
      "ocr_conf:  0.176\n",
      "11/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.586605\n",
      "recognized_text:  C\n",
      "ocr_conf:  0.488\n",
      "12/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.5ms preprocess, 164.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.758573\n",
      "recognized_text:  COT\n",
      "ocr_conf:  0.478\n",
      "13/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.9ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.552874\n",
      "recognized_text:  BR\n",
      "ocr_conf:  0.191\n",
      "14/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.6ms preprocess, 164.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5969954\n",
      "recognized_text:  D\n",
      "ocr_conf:  0.251\n",
      "15/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.1ms\n",
      "Speed: 7.3ms preprocess, 161.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5682364\n",
      "recognized_text:  CA\n",
      "ocr_conf:  0.175\n",
      "16/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 144.0ms\n",
      "Speed: 5.2ms preprocess, 144.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.856741\n",
      "recognized_text:  S\n",
      "ocr_conf:  0.343\n",
      "17/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.6ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6984642\n",
      "recognized_text:  SS\n",
      "ocr_conf:  0.154\n",
      "18/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5825484\n",
      "recognized_text:  B\n",
      "ocr_conf:  0.126\n",
      "19/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.7ms preprocess, 164.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7828312\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "20/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.1ms preprocess, 163.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7883093\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "21/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.8ms preprocess, 163.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7372708\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "22/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 171.9ms\n",
      "Speed: 5.6ms preprocess, 171.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6855652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  E\n",
      "ocr_conf:  0.105\n",
      "23/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.1ms preprocess, 165.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.467129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 127.6ms\n",
      "Speed: 6.6ms preprocess, 127.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "24/1162\n",
      "aspect_ratio: 2.6854355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 35.2ms\n",
      "Speed: 19.1ms preprocess, 35.2ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "25/1162\n",
      "aspect_ratio: 2.6902654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.2ms\n",
      "Speed: 4.4ms preprocess, 26.2ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  D\n",
      "ocr_conf:  0.173\n",
      "26/1162\n",
      "aspect_ratio: 2.755094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  DA\n",
      "ocr_conf:  0.217\n",
      "27/1162\n",
      "aspect_ratio: 2.882984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.6ms\n",
      "Speed: 3.8ms preprocess, 25.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "28/1162\n",
      "aspect_ratio: 2.9341905\n",
      "recognized_text:  E\n",
      "ocr_conf:  0.208\n",
      "29/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 28.0ms\n",
      "Speed: 3.7ms preprocess, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7879078\n",
      "recognized_text:  G\n",
      "ocr_conf:  0.129\n",
      "30/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 25.6ms\n",
      "Speed: 2.4ms preprocess, 25.6ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.724448\n",
      "recognized_text:  TE\n",
      "ocr_conf:  0.18\n",
      "31/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 30.1ms\n",
      "Speed: 2.8ms preprocess, 30.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 2.5ms preprocess, 25.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7510412\n",
      "recognized_text:  G\n",
      "ocr_conf:  0.216\n",
      "32/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 3.9ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7508752\n",
      "recognized_text:  2\n",
      "ocr_conf:  0.116\n",
      "33/1162\n",
      "aspect_ratio: 2.772062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  2\n",
      "ocr_conf:  0.197\n",
      "34/1162\n",
      "aspect_ratio: 2.8106215\n",
      "recognized_text:  2\n",
      "ocr_conf:  0.136\n",
      "35/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 29.3ms\n",
      "Speed: 4.4ms preprocess, 29.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 3.7ms preprocess, 25.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7068114\n",
      "recognized_text:  Z\n",
      "ocr_conf:  0.172\n",
      "36/1162\n",
      "aspect_ratio: 2.6126313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  Z\n",
      "ocr_conf:  0.145\n",
      "37/1162\n",
      "aspect_ratio: 2.5608351\n",
      "recognized_text:  EA\n",
      "ocr_conf:  0.426\n",
      "38/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 27.3ms\n",
      "Speed: 3.5ms preprocess, 27.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6382215\n",
      "recognized_text:  EO\n",
      "ocr_conf:  0.26\n",
      "39/1162\n",
      "aspect_ratio: 2.6914008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 35.5ms\n",
      "Speed: 5.4ms preprocess, 35.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  DO\n",
      "ocr_conf:  0.296\n",
      "40/1162\n",
      "aspect_ratio: 2.6130857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 30.2ms\n",
      "Speed: 5.5ms preprocess, 30.2ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  E7\n",
      "ocr_conf:  0.265\n",
      "41/1162\n",
      "aspect_ratio: 2.5149791\n",
      "recognized_text:  E\n",
      "ocr_conf:  0.244\n",
      "42/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.8ms\n",
      "Speed: 4.8ms preprocess, 164.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7176461\n",
      "recognized_text:  N\n",
      "ocr_conf:  0.271\n",
      "43/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 141.4ms\n",
      "Speed: 4.4ms preprocess, 141.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.738607\n",
      "recognized_text:  EZ\n",
      "ocr_conf:  0.198\n",
      "44/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 5.8ms preprocess, 164.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7134244\n",
      "recognized_text:  MASPANO\n",
      "ocr_conf:  0.5\n",
      "45/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 6.0ms preprocess, 164.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7370725\n",
      "recognized_text:  S0\n",
      "ocr_conf:  0.233\n",
      "46/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 5.0ms preprocess, 164.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6543863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 137.7ms\n",
      "Speed: 5.2ms preprocess, 137.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  NLIO\n",
      "ocr_conf:  0.229\n",
      "47/1162\n",
      "aspect_ratio: 2.6077418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  O\n",
      "ocr_conf:  0.358\n",
      "48/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.7ms preprocess, 163.1ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7018518\n",
      "recognized_text:  OANO\n",
      "ocr_conf:  0.333\n",
      "49/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 148.5ms\n",
      "Speed: 4.4ms preprocess, 148.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6082914\n",
      "recognized_text:  NEONO\n",
      "ocr_conf:  0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 167.1ms\n",
      "Speed: 4.4ms preprocess, 167.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1162\n",
      "aspect_ratio: 2.6223044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 42.7ms\n",
      "Speed: 3.4ms preprocess, 42.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  EANO\n",
      "ocr_conf:  0.383\n",
      "51/1162\n",
      "aspect_ratio: 2.538925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  B390\n",
      "ocr_conf:  0.239\n",
      "52/1162\n",
      "aspect_ratio: 2.500958\n",
      "recognized_text:  EANE\n",
      "ocr_conf:  0.229\n",
      "53/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 25.8ms\n",
      "Speed: 11.3ms preprocess, 25.8ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7314906\n",
      "recognized_text:  ANO\n",
      "ocr_conf:  0.317\n",
      "54/1162\n",
      "aspect_ratio: 2.7180884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.7ms\n",
      "Speed: 3.4ms preprocess, 26.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  EAO\n",
      "ocr_conf:  0.279\n",
      "55/1162\n",
      "aspect_ratio: 2.6297932\n",
      "recognized_text:  ETANO\n",
      "ocr_conf:  0.265\n",
      "56/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 29.0ms\n",
      "Speed: 2.9ms preprocess, 29.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.721293\n",
      "recognized_text:  003430\n",
      "ocr_conf:  0.521\n",
      "57/1162\n",
      "aspect_ratio: 2.7931874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 4.2ms preprocess, 25.9ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  303190\n",
      "ocr_conf:  0.531\n",
      "58/1162\n",
      "aspect_ratio: 2.7811644\n",
      "recognized_text:  30E3290\n",
      "ocr_conf:  0.512\n",
      "59/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 25.8ms\n",
      "Speed: 3.3ms preprocess, 25.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 41.7ms\n",
      "Speed: 3.5ms preprocess, 41.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6489806\n",
      "recognized_text:  308330\n",
      "ocr_conf:  0.632\n",
      "60/1162\n",
      "aspect_ratio: 2.8591652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 32.1ms\n",
      "Speed: 3.0ms preprocess, 32.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  3083230\n",
      "ocr_conf:  0.655\n",
      "61/1162\n",
      "aspect_ratio: 2.729006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 28.2ms\n",
      "Speed: 3.5ms preprocess, 28.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  303290\n",
      "ocr_conf:  0.683\n",
      "62/1162\n",
      "aspect_ratio: 2.8029642\n",
      "recognized_text:  3083290\n",
      "ocr_conf:  0.773\n",
      "63/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6511874\n",
      "recognized_text:  308390\n",
      "ocr_conf:  0.767\n",
      "64/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.5ms preprocess, 164.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6731594\n",
      "recognized_text:  308-32490\n",
      "ocr_conf:  0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 145.9ms\n",
      "Speed: 5.0ms preprocess, 145.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/1162\n",
      "aspect_ratio: 2.7830126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.5ms preprocess, 164.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30-32490\n",
      "ocr_conf:  0.694\n",
      "66/1162\n",
      "aspect_ratio: 2.7640212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.7ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  3083490\n",
      "ocr_conf:  0.655\n",
      "67/1162\n",
      "aspect_ratio: 2.6079545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 7.8ms preprocess, 163.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E3490\n",
      "ocr_conf:  0.674\n",
      "68/1162\n",
      "aspect_ratio: 2.7444603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 128.6ms\n",
      "Speed: 5.3ms preprocess, 128.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E3490\n",
      "ocr_conf:  0.748\n",
      "69/1162\n",
      "aspect_ratio: 2.6899383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-36.90\n",
      "ocr_conf:  0.805\n",
      "70/1162\n",
      "aspect_ratio: 2.735404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 5.0ms preprocess, 163.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E36.90\n",
      "ocr_conf:  0.834\n",
      "71/1162\n",
      "aspect_ratio: 2.7823384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.7ms preprocess, 163.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-36.90\n",
      "ocr_conf:  0.811\n",
      "72/1162\n",
      "aspect_ratio: 2.8327994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.5ms preprocess, 163.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-324.90\n",
      "ocr_conf:  0.88\n",
      "73/1162\n",
      "aspect_ratio: 2.6977117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 158.9ms\n",
      "Speed: 4.8ms preprocess, 158.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-34.90\n",
      "ocr_conf:  0.876\n",
      "74/1162\n",
      "aspect_ratio: 2.7945845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 150.0ms\n",
      "Speed: 5.0ms preprocess, 150.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-34.90\n",
      "ocr_conf:  0.906\n",
      "75/1162\n",
      "aspect_ratio: 2.7461388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-34.90\n",
      "ocr_conf:  0.942\n",
      "76/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.5ms preprocess, 164.5ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6163564\n",
      "recognized_text:  30E-374.90\n",
      "ocr_conf:  0.893\n",
      "77/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.9ms preprocess, 164.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.677301\n",
      "recognized_text:  30E-37490\n",
      "ocr_conf:  0.861\n",
      "78/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.9ms\n",
      "Speed: 4.9ms preprocess, 164.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.553878\n",
      "recognized_text:  30E-304.90\n",
      "ocr_conf:  0.8\n",
      "79/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 4.5ms preprocess, 164.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4918864\n",
      "recognized_text:  30E-30490\n",
      "ocr_conf:  0.715\n",
      "80/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 7.4ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3835566\n",
      "recognized_text:  30-3040\n",
      "ocr_conf:  0.609\n",
      "81/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.1ms\n",
      "Speed: 5.0ms preprocess, 161.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3100257\n",
      "recognized_text:  RIE3ARD\n",
      "ocr_conf:  0.417\n",
      "82/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 150.9ms\n",
      "Speed: 4.9ms preprocess, 150.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.3874404\n",
      "recognized_text:  T\n",
      "ocr_conf:  0.283\n",
      "83/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 5.2ms preprocess, 163.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.313607\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "84/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1891217\n",
      "recognized_text:  SOD\n",
      "ocr_conf:  0.238\n",
      "85/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 5.4ms preprocess, 164.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.006224\n",
      "recognized_text:  OT\n",
      "ocr_conf:  0.379\n",
      "86/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.0ms\n",
      "Speed: 4.6ms preprocess, 165.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8191882\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "87/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.2ms\n",
      "Speed: 5.2ms preprocess, 164.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 66.3ms\n",
      "Speed: 4.9ms preprocess, 66.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.8ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 6.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/1162\n",
      "89/1162\n",
      "90/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 144.0ms\n",
      "Speed: 3.7ms preprocess, 144.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/1162\n",
      "aspect_ratio: 1.9076153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 8.0ms preprocess, 163.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  AXE\n",
      "ocr_conf:  0.605\n",
      "92/1162\n",
      "93/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.9ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.3ms\n",
      "Speed: 4.6ms preprocess, 163.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/1162\n",
      "95/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 39.4ms\n",
      "Speed: 5.7ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.9ms preprocess, 29.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.4ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/1162\n",
      "97/1162\n",
      "98/1162\n",
      "99/1162\n",
      "100/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 3.1ms preprocess, 27.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.3ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 10.9ms preprocess, 28.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/1162\n",
      "102/1162\n",
      "103/1162\n",
      "104/1162\n",
      "105/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 3.8ms preprocess, 26.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0791423\n",
      "recognized_text:  RAXE\n",
      "ocr_conf:  0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.3ms\n",
      "Speed: 4.6ms preprocess, 161.3ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/1162\n",
      "aspect_ratio: 0.87781537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 145.9ms\n",
      "Speed: 4.8ms preprocess, 145.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  RUAXE-\n",
      "ocr_conf:  0.915\n",
      "107/1162\n",
      "aspect_ratio: 0.9420797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.1ms\n",
      "Speed: 4.9ms preprocess, 164.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  RUAXE- \n",
      "ocr_conf:  0.846\n",
      "108/1162\n",
      "109/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 36.0ms\n",
      "Speed: 4.7ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.4ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 5.3ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/1162\n",
      "111/1162\n",
      "112/1162\n",
      "113/1162\n",
      "114/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.0ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/1162\n",
      "116/1162\n",
      "117/1162\n",
      "118/1162\n",
      "119/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.7ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.0ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.9ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/1162\n",
      "121/1162\n",
      "122/1162\n",
      "123/1162\n",
      "124/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.5ms preprocess, 25.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.1ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.4ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.6ms preprocess, 28.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/1162\n",
      "126/1162\n",
      "127/1162\n",
      "128/1162\n",
      "129/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 7.3ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 3.7ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.2ms\n",
      "Speed: 2.9ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/1162\n",
      "131/1162\n",
      "132/1162\n",
      "133/1162\n",
      "134/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 3.0ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.8ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/1162\n",
      "136/1162\n",
      "137/1162\n",
      "138/1162\n",
      "139/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.6ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.5ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.6ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/1162\n",
      "141/1162\n",
      "142/1162\n",
      "143/1162\n",
      "144/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.8ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.1ms preprocess, 26.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.6ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/1162\n",
      "146/1162\n",
      "147/1162\n",
      "148/1162\n",
      "149/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 4.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 3.1ms preprocess, 26.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/1162\n",
      "151/1162\n",
      "152/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 4.3ms preprocess, 163.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 7.1ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.6ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/1162\n",
      "154/1162\n",
      "155/1162\n",
      "156/1162\n",
      "157/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.6ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.5ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.9ms preprocess, 27.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/1162\n",
      "159/1162\n",
      "160/1162\n",
      "161/1162\n",
      "162/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.3ms preprocess, 27.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.0ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.5ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/1162\n",
      "164/1162\n",
      "165/1162\n",
      "166/1162\n",
      "167/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.3ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 3.1ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/1162\n",
      "169/1162\n",
      "170/1162\n",
      "171/1162\n",
      "172/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.7ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 3.3ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.7ms preprocess, 27.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/1162\n",
      "174/1162\n",
      "175/1162\n",
      "176/1162\n",
      "aspect_ratio: 1.2418181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.6ms\n",
      "Speed: 8.3ms preprocess, 159.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C1195.8\n",
      "ocr_conf:  0.722\n",
      "177/1162\n",
      "aspect_ratio: 1.2418177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 150.3ms\n",
      "Speed: 4.5ms preprocess, 150.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C7195.0\n",
      "ocr_conf:  0.79\n",
      "178/1162\n",
      "aspect_ratio: 1.215452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C7195.1N\n",
      "ocr_conf:  0.861\n",
      "179/1162\n",
      "aspect_ratio: 1.1698251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C7195.\n",
      "ocr_conf:  0.861\n",
      "180/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.4ms\n",
      "Speed: 4.2ms preprocess, 164.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 96.2ms\n",
      "Speed: 4.9ms preprocess, 96.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/1162\n",
      "aspect_ratio: 1.1224364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.9ms preprocess, 164.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C1195.08\n",
      "ocr_conf:  0.736\n",
      "182/1162\n",
      "aspect_ratio: 1.1161245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.0ms preprocess, 163.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C1195.\n",
      "ocr_conf:  0.759\n",
      "183/1162\n",
      "aspect_ratio: 1.1312542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 6.2ms preprocess, 163.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C1195.\n",
      "ocr_conf:  0.686\n",
      "184/1162\n",
      "aspect_ratio: 1.1343992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 5.3ms preprocess, 164.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-C1195.0\n",
      "ocr_conf:  0.728\n",
      "185/1162\n",
      "aspect_ratio: 1.1648213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-C1195.\n",
      "ocr_conf:  0.709\n",
      "186/1162\n",
      "aspect_ratio: 1.161561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 137.5ms\n",
      "Speed: 4.6ms preprocess, 137.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C1195.\n",
      "ocr_conf:  0.728\n",
      "187/1162\n",
      "aspect_ratio: 1.1898574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-C195.\n",
      "ocr_conf:  0.788\n",
      "188/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.7ms\n",
      "Speed: 4.4ms preprocess, 164.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 98.3ms\n",
      "Speed: 4.7ms preprocess, 98.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/1162\n",
      "aspect_ratio: 1.197108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 155.8ms\n",
      "Speed: 5.1ms preprocess, 155.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  70-C1195.1\n",
      "ocr_conf:  0.684\n",
      "190/1162\n",
      "aspect_ratio: 1.2014372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 5.5ms preprocess, 164.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  0-C1195.1\n",
      "ocr_conf:  0.78\n",
      "191/1162\n",
      "aspect_ratio: 1.1893528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 5.1ms preprocess, 163.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  70-1/195.1\n",
      "ocr_conf:  0.802\n",
      "192/1162\n",
      "aspect_ratio: 1.1906507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.8ms preprocess, 163.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-1195.1\n",
      "ocr_conf:  0.783\n",
      "193/1162\n",
      "aspect_ratio: 1.1873779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 5.1ms preprocess, 164.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-1195.1\n",
      "ocr_conf:  0.904\n",
      "194/1162\n",
      "aspect_ratio: 1.2372466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.5ms\n",
      "Speed: 4.6ms preprocess, 164.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  179-01195.1\n",
      "ocr_conf:  0.807\n",
      "195/1162\n",
      "196/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 92.8ms\n",
      "Speed: 4.7ms preprocess, 92.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.7ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/1162\n",
      "198/1162\n",
      "199/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 161.1ms\n",
      "Speed: 4.7ms preprocess, 161.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/1162\n",
      "201/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 100.7ms\n",
      "Speed: 4.9ms preprocess, 100.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 4.8ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/1162\n",
      "203/1162\n",
      "204/1162\n",
      "205/1162\n",
      "206/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 26.8ms\n",
      "Speed: 3.3ms preprocess, 26.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.34662503\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "207/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 144.2ms\n",
      "Speed: 4.9ms preprocess, 144.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 4.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/1162\n",
      "209/1162\n",
      "210/1162\n",
      "211/1162\n",
      "212/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/1162\n",
      "214/1162\n",
      "215/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/1162\n",
      "217/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 4.8ms preprocess, 48.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 5.7ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.7ms preprocess, 36.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/1162\n",
      "219/1162\n",
      "220/1162\n",
      "221/1162\n",
      "222/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.9ms preprocess, 25.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/1162\n",
      "224/1162\n",
      "225/1162\n",
      "226/1162\n",
      "227/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.5ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/1162\n",
      "229/1162\n",
      "230/1162\n",
      "231/1162\n",
      "232/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.8ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.7ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/1162\n",
      "234/1162\n",
      "235/1162\n",
      "236/1162\n",
      "237/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 28.6ms\n",
      "Speed: 2.9ms preprocess, 28.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/1162\n",
      "239/1162\n",
      "240/1162\n",
      "aspect_ratio: 0.8381902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  20-P1710489\n",
      "ocr_conf:  0.687\n",
      "241/1162\n",
      "aspect_ratio: 0.8382611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 165.0ms\n",
      "Speed: 4.9ms preprocess, 165.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  20-P1710489\n",
      "ocr_conf:  0.629\n",
      "242/1162\n",
      "243/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 43.5ms\n",
      "Speed: 5.0ms preprocess, 43.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.87295336\n",
      "recognized_text:  29-P1104.85\n",
      "ocr_conf:  0.698\n",
      "244/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.8808231\n",
      "recognized_text:  29-P1710485\n",
      "ocr_conf:  0.803\n",
      "245/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.86455506\n",
      "recognized_text:  29-P1710485\n",
      "ocr_conf:  0.737\n",
      "246/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.4ms\n",
      "Speed: 4.9ms preprocess, 164.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.9ms\n",
      "Speed: 5.9ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/1162\n",
      "248/1162\n",
      "aspect_ratio: 0.8954324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 6.5ms preprocess, 163.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1710489\n",
      "ocr_conf:  0.705\n",
      "249/1162\n",
      "aspect_ratio: 0.9225983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 152.3ms\n",
      "Speed: 4.9ms preprocess, 152.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P17704.83\n",
      "ocr_conf:  0.674\n",
      "250/1162\n",
      "aspect_ratio: 0.9168909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 166.3ms\n",
      "Speed: 5.1ms preprocess, 166.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1710489\n",
      "ocr_conf:  0.627\n",
      "251/1162\n",
      "aspect_ratio: 0.92776144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1710489\n",
      "ocr_conf:  0.624\n",
      "252/1162\n",
      "aspect_ratio: 0.98107165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.1ms\n",
      "Speed: 4.8ms preprocess, 165.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1710489\n",
      "ocr_conf:  0.553\n",
      "253/1162\n",
      "aspect_ratio: 0.97665596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.4ms preprocess, 163.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1010483\n",
      "ocr_conf:  0.632\n",
      "254/1162\n",
      "aspect_ratio: 0.96802884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.0ms\n",
      "Speed: 4.6ms preprocess, 161.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-PTR10483\n",
      "ocr_conf:  0.616\n",
      "255/1162\n",
      "aspect_ratio: 0.9712267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 126.6ms\n",
      "Speed: 5.3ms preprocess, 126.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1R104.8\n",
      "ocr_conf:  0.611\n",
      "256/1162\n",
      "aspect_ratio: 1.0017983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 4.8ms preprocess, 164.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  09-P1810483\n",
      "ocr_conf:  0.619\n",
      "257/1162\n",
      "aspect_ratio: 0.9942797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 5.9ms preprocess, 163.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P19104.83\n",
      "ocr_conf:  0.624\n",
      "258/1162\n",
      "aspect_ratio: 0.98469746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.8ms\n",
      "Speed: 4.6ms preprocess, 165.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1010483\n",
      "ocr_conf:  0.615\n",
      "259/1162\n",
      "aspect_ratio: 0.97423303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29.P1104.03\n",
      "ocr_conf:  0.736\n",
      "260/1162\n",
      "aspect_ratio: 0.9569401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 126.0ms\n",
      "Speed: 4.2ms preprocess, 126.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1104.03\n",
      "ocr_conf:  0.763\n",
      "261/1162\n",
      "aspect_ratio: 0.99567074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.9ms\n",
      "Speed: 5.7ms preprocess, 164.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P1104.63\n",
      "ocr_conf:  0.736\n",
      "262/1162\n",
      "aspect_ratio: 1.0171236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.8ms\n",
      "Speed: 4.7ms preprocess, 164.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-P19104.03\n",
      "ocr_conf:  0.671\n",
      "263/1162\n",
      "aspect_ratio: 1.0046585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.3ms preprocess, 164.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-19104.03\n",
      "ocr_conf:  0.71\n",
      "264/1162\n",
      "aspect_ratio: 1.0148273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.5ms preprocess, 163.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-1104.03\n",
      "ocr_conf:  0.797\n",
      "265/1162\n",
      "aspect_ratio: 1.0108399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.2ms\n",
      "Speed: 4.6ms preprocess, 161.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-p19104.0\n",
      "ocr_conf:  0.794\n",
      "266/1162\n",
      "aspect_ratio: 1.0455537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-P192104.09\n",
      "ocr_conf:  0.723\n",
      "267/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 4.5ms preprocess, 164.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1116377\n",
      "recognized_text:  29-P192104.00\n",
      "ocr_conf:  0.721\n",
      "268/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.0ms\n",
      "Speed: 4.7ms preprocess, 160.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.018323\n",
      "recognized_text:  29-p1104.03\n",
      "ocr_conf:  0.724\n",
      "269/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 5.3ms preprocess, 164.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.92121315\n",
      "recognized_text:  9-P19104.03\n",
      "ocr_conf:  0.753\n",
      "270/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.81178725\n",
      "recognized_text:  -P104.05\n",
      "ocr_conf:  0.762\n",
      "271/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.3ms preprocess, 164.3ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.7435055\n",
      "recognized_text:  P1004.85\n",
      "ocr_conf:  0.7\n",
      "272/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 163.3ms\n",
      "Speed: 4.5ms preprocess, 163.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.4ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.4ms preprocess, 26.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.6ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/1162\n",
      "274/1162\n",
      "275/1162\n",
      "276/1162\n",
      "277/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.7ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.7ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.1ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/1162\n",
      "279/1162\n",
      "280/1162\n",
      "281/1162\n",
      "282/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 4.9ms preprocess, 26.4ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/1162\n",
      "284/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.1ms\n",
      "Speed: 4.9ms preprocess, 164.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 4.4ms preprocess, 80.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/1162\n",
      "286/1162\n",
      "287/1162\n",
      "288/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.9ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.1ms\n",
      "Speed: 3.4ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 4.0ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/1162\n",
      "290/1162\n",
      "291/1162\n",
      "292/1162\n",
      "293/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 4.8ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 4.1ms preprocess, 25.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/1162\n",
      "295/1162\n",
      "296/1162\n",
      "297/1162\n",
      "298/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.7ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.3ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/1162\n",
      "300/1162\n",
      "301/1162\n",
      "302/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 3.1ms preprocess, 27.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.4ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.7ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/1162\n",
      "304/1162\n",
      "305/1162\n",
      "306/1162\n",
      "307/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 3.2ms preprocess, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/1162\n",
      "309/1162\n",
      "310/1162\n",
      "311/1162\n",
      "312/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.4ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.3ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.6ms preprocess, 26.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.8ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.1ms preprocess, 25.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/1162\n",
      "314/1162\n",
      "315/1162\n",
      "316/1162\n",
      "317/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 5.7ms preprocess, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 2.6ms preprocess, 28.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.9ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318/1162\n",
      "319/1162\n",
      "320/1162\n",
      "321/1162\n",
      "322/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.3ms preprocess, 26.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/1162\n",
      "324/1162\n",
      "325/1162\n",
      "326/1162\n",
      "327/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.8ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/1162\n",
      "329/1162\n",
      "330/1162\n",
      "331/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 3.1ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.2ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/1162\n",
      "333/1162\n",
      "334/1162\n",
      "335/1162\n",
      "336/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.7ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/1162\n",
      "338/1162\n",
      "339/1162\n",
      "340/1162\n",
      "341/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.7ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.6ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 2.6ms preprocess, 26.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/1162\n",
      "343/1162\n",
      "344/1162\n",
      "345/1162\n",
      "aspect_ratio: 7.4043884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 165.0ms\n",
      "Speed: 5.1ms preprocess, 165.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "346/1162\n",
      "347/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 63.6ms\n",
      "Speed: 4.5ms preprocess, 63.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 5.143597\n",
      "recognized_text:  COU-ECAS\n",
      "ocr_conf:  0.535\n",
      "348/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 4.298707\n",
      "recognized_text:  23012210\n",
      "ocr_conf:  0.806\n",
      "349/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.097173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 148.1ms\n",
      "Speed: 4.5ms preprocess, 148.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29032210\n",
      "ocr_conf:  0.89\n",
      "350/1162\n",
      "aspect_ratio: 2.5097237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.6ms\n",
      "Speed: 5.0ms preprocess, 165.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.927\n",
      "351/1162\n",
      "aspect_ratio: 2.6672432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.9ms preprocess, 164.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.957\n",
      "352/1162\n",
      "aspect_ratio: 2.7490528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.931\n",
      "353/1162\n",
      "aspect_ratio: 2.7131207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 139.2ms\n",
      "Speed: 4.4ms preprocess, 139.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.939\n",
      "354/1162\n",
      "aspect_ratio: 2.7935154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.3ms preprocess, 164.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.933\n",
      "355/1162\n",
      "aspect_ratio: 2.6963477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.879\n",
      "356/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 174.3ms\n",
      "Speed: 4.4ms preprocess, 174.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8065913\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.88\n",
      "357/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.8ms\n",
      "Speed: 5.1ms preprocess, 164.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8328125\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.908\n",
      "358/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6773715\n",
      "recognized_text:  29D-122 10\n",
      "ocr_conf:  0.846\n",
      "359/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 5.0ms preprocess, 164.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8755195\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.904\n",
      "360/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.3ms preprocess, 164.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5703347\n",
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.911\n",
      "361/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 166.6ms\n",
      "Speed: 4.5ms preprocess, 166.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7637599\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 156.5ms\n",
      "Speed: 4.9ms preprocess, 156.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/1162\n",
      "aspect_ratio: 2.81121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.4ms preprocess, 163.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.88\n",
      "363/1162\n",
      "aspect_ratio: 2.8485494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.878\n",
      "364/1162\n",
      "aspect_ratio: 2.6918178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29D-122.10\n",
      "ocr_conf:  0.876\n",
      "365/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 6.4ms preprocess, 163.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.681292\n",
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.916\n",
      "366/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.5ms preprocess, 164.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8688705\n",
      "recognized_text:  29D-12210\n",
      "ocr_conf:  0.931\n",
      "367/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7986832\n",
      "recognized_text:  29D-12210\n",
      "ocr_conf:  0.908\n",
      "368/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.4ms preprocess, 163.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7365427\n",
      "recognized_text:  29D-12210\n",
      "ocr_conf:  0.936\n",
      "369/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 171.0ms\n",
      "Speed: 6.2ms preprocess, 171.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7615063\n",
      "recognized_text:  29D-12210\n",
      "ocr_conf:  0.95\n",
      "370/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 128.0ms\n",
      "Speed: 4.7ms preprocess, 128.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6651127\n",
      "recognized_text:  29D-12210\n",
      "ocr_conf:  0.904\n",
      "371/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7011242\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.799\n",
      "372/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 145.8ms\n",
      "Speed: 4.5ms preprocess, 145.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8207064\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.957\n",
      "373/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 6.0ms preprocess, 163.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7333999\n",
      "recognized_text:  29D-122.10\n",
      "ocr_conf:  0.881\n",
      "374/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.2ms preprocess, 164.0ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6829605\n",
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.871\n",
      "375/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.4ms preprocess, 164.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6426697\n",
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.94\n",
      "376/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.8ms preprocess, 164.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6487896\n",
      "recognized_text:  290-122.10\n",
      "ocr_conf:  0.918\n",
      "377/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5476468\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.945\n",
      "378/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.9ms preprocess, 164.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5903738\n",
      "recognized_text:  290-12210\n",
      "ocr_conf:  0.932\n",
      "379/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.4ms\n",
      "Speed: 4.6ms preprocess, 165.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.437323\n",
      "recognized_text:  290-1220\n",
      "ocr_conf:  0.835\n",
      "380/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.4ms preprocess, 160.6ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.5649247\n",
      "recognized_text:  MA\n",
      "ocr_conf:  0.256\n",
      "381/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 140.1ms\n",
      "Speed: 4.6ms preprocess, 140.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.5968678\n",
      "recognized_text:  F4\n",
      "ocr_conf:  0.165\n",
      "382/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 156.7ms\n",
      "Speed: 4.4ms preprocess, 156.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.5ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 4.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/1162\n",
      "384/1162\n",
      "385/1162\n",
      "386/1162\n",
      "387/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 3.1ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 29.7ms\n",
      "Speed: 2.8ms preprocess, 29.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/1162\n",
      "389/1162\n",
      "390/1162\n",
      "aspect_ratio: 1.352894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.7ms\n",
      "Speed: 5.3ms preprocess, 164.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  e\n",
      "ocr_conf:  0.206\n",
      "391/1162\n",
      "392/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 79.5ms\n",
      "Speed: 4.6ms preprocess, 79.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 4.5ms preprocess, 25.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.6ms preprocess, 27.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/1162\n",
      "394/1162\n",
      "395/1162\n",
      "396/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.7ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.4ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 4.1ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/1162\n",
      "398/1162\n",
      "399/1162\n",
      "400/1162\n",
      "401/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.7ms preprocess, 34.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 41.9ms\n",
      "Speed: 3.1ms preprocess, 41.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 5.0ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/1162\n",
      "403/1162\n",
      "404/1162\n",
      "405/1162\n",
      "406/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.8ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.9ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.5ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/1162\n",
      "408/1162\n",
      "409/1162\n",
      "410/1162\n",
      "411/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.6551008\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "412/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 plates, 164.4ms\n",
      "Speed: 5.9ms preprocess, 164.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7607102\n",
      "recognized_text:  -13094\n",
      "ocr_conf:  0.768\n",
      "413/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 5.1ms preprocess, 163.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.50426\n",
      "recognized_text:  E0013050\n",
      "ocr_conf:  0.456\n",
      "414/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 161.5ms\n",
      "Speed: 4.7ms preprocess, 161.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5063157\n",
      "recognized_text:  608T3093\n",
      "ocr_conf:  0.453\n",
      "415/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.7ms\n",
      "Speed: 4.6ms preprocess, 164.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5342174\n",
      "recognized_text:  E0EE2094\n",
      "ocr_conf:  0.52\n",
      "416/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.9ms\n",
      "Speed: 4.7ms preprocess, 163.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5254574\n",
      "recognized_text:  E0LN090\n",
      "ocr_conf:  0.284\n",
      "417/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 plates, 130.1ms\n",
      "Speed: 4.5ms preprocess, 130.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.644511\n",
      "recognized_text:  012090\n",
      "ocr_conf:  0.455\n",
      "418/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.4ms\n",
      "Speed: 4.5ms preprocess, 164.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6815863\n",
      "recognized_text:  ESET2190\n",
      "ocr_conf:  0.25\n",
      "419/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 152.9ms\n",
      "Speed: 4.6ms preprocess, 152.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.738505\n",
      "recognized_text:  60E72090\n",
      "ocr_conf:  0.553\n",
      "420/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 8.8ms preprocess, 164.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5248153\n",
      "recognized_text:  CONSO\n",
      "ocr_conf:  0.44\n",
      "421/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.9ms\n",
      "Speed: 4.7ms preprocess, 164.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6201975\n",
      "recognized_text:  E90\n",
      "ocr_conf:  0.33\n",
      "422/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.4ms preprocess, 163.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6762228\n",
      "recognized_text:  E130.90\n",
      "ocr_conf:  0.696\n",
      "423/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.1ms\n",
      "Speed: 4.9ms preprocess, 164.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7360647\n",
      "recognized_text:  30130.94\n",
      "ocr_conf:  0.864\n",
      "424/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.4ms\n",
      "Speed: 4.6ms preprocess, 162.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4945042\n",
      "recognized_text:  30E13094\n",
      "ocr_conf:  0.912\n",
      "425/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 149.0ms\n",
      "Speed: 6.1ms preprocess, 149.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7608106\n",
      "recognized_text:  30E13094\n",
      "ocr_conf:  0.918\n",
      "426/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9554868\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.952\n",
      "427/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.8ms preprocess, 163.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1048272\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.931\n",
      "428/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.5ms preprocess, 164.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.905814\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.942\n",
      "429/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 5.6ms preprocess, 163.4ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7789192\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.938\n",
      "430/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.5ms preprocess, 163.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7454667\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.911\n",
      "431/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.766188\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.893\n",
      "432/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7300315\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.94\n",
      "433/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.6ms preprocess, 163.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4735394\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.887\n",
      "434/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.0ms\n",
      "Speed: 5.3ms preprocess, 139.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7264585\n",
      "recognized_text:  30E130.94\n",
      "ocr_conf:  0.967\n",
      "435/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.7ms preprocess, 164.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.791449\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.924\n",
      "436/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 142.8ms\n",
      "Speed: 5.4ms preprocess, 142.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.677415\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.924\n",
      "437/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 144.3ms\n",
      "Speed: 4.3ms preprocess, 144.3ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6528776\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.961\n",
      "438/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.5ms preprocess, 164.0ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6314204\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.971\n",
      "439/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6340628\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.948\n",
      "440/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 5.0ms preprocess, 164.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6168952\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.928\n",
      "441/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.9ms preprocess, 163.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.589353\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.915\n",
      "442/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.1ms preprocess, 163.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5540476\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.93\n",
      "443/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.2ms preprocess, 163.8ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5666223\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.933\n",
      "444/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 127.7ms\n",
      "Speed: 5.2ms preprocess, 127.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6061263\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.937\n",
      "445/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 6.0ms preprocess, 163.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6709776\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.946\n",
      "446/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.501895\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.921\n",
      "447/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5698395\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.895\n",
      "448/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4590778\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.969\n",
      "449/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 5.1ms preprocess, 164.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2641282\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.891\n",
      "450/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.9ms\n",
      "Speed: 4.4ms preprocess, 164.9ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.2791877\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.928\n",
      "451/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 137.3ms\n",
      "Speed: 4.3ms preprocess, 137.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.1102602\n",
      "recognized_text:  30E-130.94\n",
      "ocr_conf:  0.94\n",
      "452/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 165.1ms\n",
      "Speed: 6.1ms preprocess, 165.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.8975691\n",
      "recognized_text:  0930E13033\n",
      "ocr_conf:  0.493\n",
      "453/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 150.0ms\n",
      "Speed: 4.7ms preprocess, 150.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.7257128\n",
      "recognized_text:  0930E13\n",
      "ocr_conf:  0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.0ms\n",
      "Speed: 5.1ms preprocess, 161.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454/1162\n",
      "aspect_ratio: 1.5835152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 149.7ms\n",
      "Speed: 5.0ms preprocess, 149.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  Yng30E\n",
      "ocr_conf:  0.277\n",
      "455/1162\n",
      "aspect_ratio: 1.4349306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 5.5ms preprocess, 163.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "456/1162\n",
      "aspect_ratio: 1.2907596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.6ms preprocess, 163.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "457/1162\n",
      "aspect_ratio: 1.1610764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "458/1162\n",
      "459/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.5ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.8ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.5ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460/1162\n",
      "461/1162\n",
      "462/1162\n",
      "463/1162\n",
      "464/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 5.9ms preprocess, 27.3ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 4.5ms preprocess, 25.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/1162\n",
      "466/1162\n",
      "467/1162\n",
      "aspect_ratio: 2.0213742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 160.8ms\n",
      "Speed: 5.0ms preprocess, 160.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  I\n",
      "ocr_conf:  0.134\n",
      "468/1162\n",
      "469/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 107.5ms\n",
      "Speed: 4.8ms preprocess, 107.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.8ms preprocess, 27.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/1162\n",
      "471/1162\n",
      "472/1162\n",
      "473/1162\n",
      "474/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.6ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 27.7ms\n",
      "Speed: 3.2ms preprocess, 27.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475/1162\n",
      "aspect_ratio: 1.1199261\n",
      "recognized_text:  5E\n",
      "ocr_conf:  0.271\n",
      "476/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.7ms preprocess, 163.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1282545\n",
      "recognized_text:  5\n",
      "ocr_conf:  0.14\n",
      "477/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 161.1ms\n",
      "Speed: 4.8ms preprocess, 161.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.1ms\n",
      "Speed: 4.7ms preprocess, 108.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/1162\n",
      "479/1162\n",
      "480/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 3.2ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 4.4ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 29.1ms\n",
      "Speed: 3.6ms preprocess, 29.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/1162\n",
      "482/1162\n",
      "483/1162\n",
      "aspect_ratio: 1.1081023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 5.1ms preprocess, 163.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "484/1162\n",
      "aspect_ratio: 1.1149484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.8ms\n",
      "Speed: 5.2ms preprocess, 160.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  B\n",
      "ocr_conf:  0.146\n",
      "485/1162\n",
      "aspect_ratio: 1.1260222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 159.0ms\n",
      "Speed: 4.7ms preprocess, 159.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  5100\n",
      "ocr_conf:  0.378\n",
      "486/1162\n",
      "487/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 113.1ms\n",
      "Speed: 4.4ms preprocess, 113.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.7ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/1162\n",
      "489/1162\n",
      "aspect_ratio: 1.1802946\n",
      "recognized_text:  R\n",
      "ocr_conf:  0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.4ms\n",
      "Speed: 5.0ms preprocess, 160.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/1162\n",
      "aspect_ratio: 1.2290524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 142.9ms\n",
      "Speed: 5.1ms preprocess, 142.9ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "491/1162\n",
      "aspect_ratio: 1.1316862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  P\n",
      "ocr_conf:  0.08\n",
      "492/1162\n",
      "aspect_ratio: 1.005253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.4ms\n",
      "Speed: 5.6ms preprocess, 163.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  S\n",
      "ocr_conf:  0.06\n",
      "493/1162\n",
      "494/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 63.2ms\n",
      "Speed: 4.5ms preprocess, 63.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.1ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.0ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/1162\n",
      "496/1162\n",
      "497/1162\n",
      "498/1162\n",
      "499/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.1ms preprocess, 26.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/1162\n",
      "501/1162\n",
      "502/1162\n",
      "503/1162\n",
      "504/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 5.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/1162\n",
      "506/1162\n",
      "507/1162\n",
      "508/1162\n",
      "509/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.5ms preprocess, 26.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.4ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.0ms\n",
      "Speed: 2.5ms preprocess, 37.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.0ms\n",
      "Speed: 3.4ms preprocess, 34.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/1162\n",
      "511/1162\n",
      "512/1162\n",
      "513/1162\n",
      "514/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 3.3ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 3.2ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/1162\n",
      "516/1162\n",
      "517/1162\n",
      "518/1162\n",
      "519/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.7ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.4ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/1162\n",
      "521/1162\n",
      "aspect_ratio: 0.7899765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-81865.8\n",
      "ocr_conf:  0.788\n",
      "522/1162\n",
      "aspect_ratio: 0.7713457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 132.3ms\n",
      "Speed: 4.8ms preprocess, 132.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-B1865.00\n",
      "ocr_conf:  0.801\n",
      "523/1162\n",
      "aspect_ratio: 0.8041915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-B1865.60\n",
      "ocr_conf:  0.799\n",
      "524/1162\n",
      "aspect_ratio: 0.81564164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 167.1ms\n",
      "Speed: 4.7ms preprocess, 167.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-B1865.60\n",
      "ocr_conf:  0.748\n",
      "525/1162\n",
      "aspect_ratio: 0.84157765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.1ms preprocess, 163.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-81865.60\n",
      "ocr_conf:  0.821\n",
      "526/1162\n",
      "aspect_ratio: 0.8286604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-81865.00\n",
      "ocr_conf:  0.775\n",
      "527/1162\n",
      "aspect_ratio: 0.8137429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-81865.80\n",
      "ocr_conf:  0.689\n",
      "528/1162\n",
      "aspect_ratio: 0.81394035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 158.5ms\n",
      "Speed: 4.8ms preprocess, 158.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-1865.0\n",
      "ocr_conf:  0.8\n",
      "529/1162\n",
      "aspect_ratio: 0.8613714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 154.4ms\n",
      "Speed: 4.9ms preprocess, 154.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-B1865.80\n",
      "ocr_conf:  0.815\n",
      "530/1162\n",
      "aspect_ratio: 0.87129825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-81865.80\n",
      "ocr_conf:  0.778\n",
      "531/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.2ms\n",
      "Speed: 4.7ms preprocess, 163.2ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.891767\n",
      "recognized_text:  29-B1865.0\n",
      "ocr_conf:  0.762\n",
      "532/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.7ms\n",
      "Speed: 5.3ms preprocess, 163.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.89512455\n",
      "recognized_text:  79-B1865.60\n",
      "ocr_conf:  0.786\n",
      "533/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.7ms\n",
      "Speed: 4.4ms preprocess, 163.7ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.89346516\n",
      "recognized_text:  79-81865.60\n",
      "ocr_conf:  0.829\n",
      "534/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.0ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.90438575\n",
      "recognized_text:  79-81865.60\n",
      "ocr_conf:  0.797\n",
      "535/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.5ms\n",
      "Speed: 4.6ms preprocess, 161.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.9105068\n",
      "recognized_text:  79-81865.0\n",
      "ocr_conf:  0.871\n",
      "536/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 147.2ms\n",
      "Speed: 4.5ms preprocess, 147.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.9325159\n",
      "recognized_text:  79-81865.00\n",
      "ocr_conf:  0.802\n",
      "537/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.9450339\n",
      "recognized_text:  79-B1865.60\n",
      "ocr_conf:  0.83\n",
      "538/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 5.6ms preprocess, 163.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.9668044\n",
      "recognized_text:  79.B1865.80\n",
      "ocr_conf:  0.831\n",
      "539/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.3ms preprocess, 163.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.987672\n",
      "recognized_text:  79-81865.80\n",
      "ocr_conf:  0.87\n",
      "540/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.0ms\n",
      "Speed: 4.5ms preprocess, 165.0ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0452764\n",
      "recognized_text:  79-8186580\n",
      "ocr_conf:  0.794\n",
      "541/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.4ms preprocess, 164.7ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.070549\n",
      "recognized_text:  79-81865.80\n",
      "ocr_conf:  0.799\n",
      "542/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.9ms\n",
      "Speed: 4.9ms preprocess, 165.9ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0732554\n",
      "recognized_text:  79.81865.80\n",
      "ocr_conf:  0.863\n",
      "543/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.90498084\n",
      "recognized_text:  79.81865.80\n",
      "ocr_conf:  0.828\n",
      "544/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.9ms preprocess, 163.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 0.64045143\n",
      "recognized_text:  B1A5.68\n",
      "ocr_conf:  0.632\n",
      "545/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 132.0ms\n",
      "Speed: 4.8ms preprocess, 132.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.1ms preprocess, 26.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.5ms preprocess, 25.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/1162\n",
      "547/1162\n",
      "548/1162\n",
      "549/1162\n",
      "550/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.6ms preprocess, 30.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.7ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551/1162\n",
      "552/1162\n",
      "553/1162\n",
      "554/1162\n",
      "555/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.5ms preprocess, 25.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 4.6ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/1162\n",
      "557/1162\n",
      "558/1162\n",
      "559/1162\n",
      "560/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.6ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.8ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.3ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561/1162\n",
      "562/1162\n",
      "563/1162\n",
      "564/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 4.4ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.9ms\n",
      "Speed: 3.1ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.2ms\n",
      "Speed: 12.2ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.7ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/1162\n",
      "566/1162\n",
      "567/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/1162\n",
      "569/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 4.6ms preprocess, 84.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.9ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/1162\n",
      "571/1162\n",
      "572/1162\n",
      "573/1162\n",
      "574/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.8ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575/1162\n",
      "576/1162\n",
      "577/1162\n",
      "578/1162\n",
      "579/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.5ms preprocess, 26.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.8ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/1162\n",
      "581/1162\n",
      "582/1162\n",
      "583/1162\n",
      "584/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 4.5ms preprocess, 26.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 3.4ms preprocess, 27.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/1162\n",
      "586/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.1ms\n",
      "Speed: 4.7ms preprocess, 164.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 4.9ms preprocess, 47.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.3ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/1162\n",
      "588/1162\n",
      "589/1162\n",
      "590/1162\n",
      "591/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.9ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.9ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.3ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.2ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 2.5ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/1162\n",
      "593/1162\n",
      "594/1162\n",
      "595/1162\n",
      "aspect_ratio: 1.1698204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 150.3ms\n",
      "Speed: 4.5ms preprocess, 150.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.88\n",
      "596/1162\n",
      "aspect_ratio: 1.0859894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.855\n",
      "597/1162\n",
      "aspect_ratio: 1.1186805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.837\n",
      "598/1162\n",
      "aspect_ratio: 1.1098542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.14\n",
      "ocr_conf:  0.889\n",
      "599/1162\n",
      "aspect_ratio: 1.1085712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-H1939.1Z\n",
      "ocr_conf:  0.876\n",
      "600/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1620669\n",
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.877\n",
      "601/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.6ms preprocess, 163.8ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1549498\n",
      "recognized_text:  29-H1939.1Z\n",
      "ocr_conf:  0.86\n",
      "602/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.4ms preprocess, 163.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1710789\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.858\n",
      "603/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.7ms preprocess, 164.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1298655\n",
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.893\n",
      "604/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1442809\n",
      "recognized_text:  29-H1939.12\n",
      "ocr_conf:  0.889\n",
      "605/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.3ms\n",
      "Speed: 4.7ms preprocess, 165.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1522466\n",
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.871\n",
      "606/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 141.9ms\n",
      "Speed: 5.0ms preprocess, 141.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1635958\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.875\n",
      "607/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 4.3ms preprocess, 164.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1097075\n",
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.4ms preprocess, 164.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/1162\n",
      "aspect_ratio: 1.1104399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.9ms\n",
      "Speed: 4.7ms preprocess, 160.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.898\n",
      "609/1162\n",
      "aspect_ratio: 1.1368755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 148.4ms\n",
      "Speed: 4.9ms preprocess, 148.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12Z\n",
      "ocr_conf:  0.865\n",
      "610/1162\n",
      "aspect_ratio: 1.1573744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 6.8ms preprocess, 163.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.912\n",
      "611/1162\n",
      "aspect_ratio: 1.1494719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.8ms preprocess, 163.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.929\n",
      "612/1162\n",
      "aspect_ratio: 1.1165067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  29-H1939.12\n",
      "ocr_conf:  0.854\n",
      "613/1162\n",
      "aspect_ratio: 1.1272953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.907\n",
      "614/1162\n",
      "aspect_ratio: 1.1545968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.9ms preprocess, 163.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.926\n",
      "615/1162\n",
      "aspect_ratio: 1.1519649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 134.8ms\n",
      "Speed: 4.6ms preprocess, 134.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12)\n",
      "ocr_conf:  0.929\n",
      "616/1162\n",
      "aspect_ratio: 1.1464463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12y\n",
      "ocr_conf:  0.862\n",
      "617/1162\n",
      "aspect_ratio: 1.1570766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.905\n",
      "618/1162\n",
      "aspect_ratio: 1.1430415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12)\n",
      "ocr_conf:  0.85\n",
      "619/1162\n",
      "aspect_ratio: 1.10215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 6.4ms preprocess, 163.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.93\n",
      "620/1162\n",
      "aspect_ratio: 1.0980712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 130.5ms\n",
      "Speed: 4.5ms preprocess, 130.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.921\n",
      "621/1162\n",
      "aspect_ratio: 1.1231822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.898\n",
      "622/1162\n",
      "aspect_ratio: 1.1119244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.919\n",
      "623/1162\n",
      "aspect_ratio: 1.106788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.913\n",
      "624/1162\n",
      "aspect_ratio: 1.0668309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.4ms\n",
      "Speed: 5.3ms preprocess, 160.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.901\n",
      "625/1162\n",
      "aspect_ratio: 1.1170362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 146.5ms\n",
      "Speed: 4.4ms preprocess, 146.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.935\n",
      "626/1162\n",
      "aspect_ratio: 1.0670388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.955\n",
      "627/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.9ms\n",
      "Speed: 5.4ms preprocess, 167.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0937043\n",
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.887\n",
      "628/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 148.9ms\n",
      "Speed: 4.6ms preprocess, 148.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.108497\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.917\n",
      "629/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.100143\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.925\n",
      "630/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 169.5ms\n",
      "Speed: 4.5ms preprocess, 169.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0900052\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.937\n",
      "631/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 5.1ms preprocess, 164.3ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0988142\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.938\n",
      "632/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.4ms preprocess, 164.5ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.6ms\n",
      "Speed: 3.4ms preprocess, 25.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0773125\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.91\n",
      "633/1162\n",
      "aspect_ratio: 1.0973077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.951\n",
      "634/1162\n",
      "aspect_ratio: 1.141543\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.927\n",
      "635/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.0862151\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.927\n",
      "636/1162\n",
      "aspect_ratio: 1.0823721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.925\n",
      "637/1162\n",
      "aspect_ratio: 1.1242858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 4.2ms preprocess, 26.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.909\n",
      "638/1162\n",
      "aspect_ratio: 1.1036643\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/1162\n",
      "aspect_ratio: 1.1022105\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.946\n",
      "640/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.6ms preprocess, 26.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1308578\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.932\n",
      "641/1162\n",
      "aspect_ratio: 1.149865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 2.6ms preprocess, 25.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.935\n",
      "642/1162\n",
      "aspect_ratio: 1.1421148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.917\n",
      "643/1162\n",
      "aspect_ratio: 1.1357485\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.922\n",
      "644/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 1.1717892\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.949\n",
      "645/1162\n",
      "aspect_ratio: 1.1015503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 35.1ms\n",
      "Speed: 2.6ms preprocess, 35.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.1Z\n",
      "ocr_conf:  0.912\n",
      "646/1162\n",
      "aspect_ratio: 1.1248018\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 27.4ms\n",
      "Speed: 3.6ms preprocess, 27.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/1162\n",
      "aspect_ratio: 1.1008245\n",
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 156.1ms\n",
      "Speed: 4.6ms preprocess, 156.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/1162\n",
      "aspect_ratio: 1.0991886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.5ms preprocess, 163.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.959\n",
      "649/1162\n",
      "aspect_ratio: 1.0781277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 6.1ms preprocess, 163.9ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.95\n",
      "650/1162\n",
      "aspect_ratio: 1.0654924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.8ms preprocess, 164.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  79-H1939.12\n",
      "ocr_conf:  0.963\n",
      "651/1162\n",
      "aspect_ratio: 0.8641963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.5ms preprocess, 164.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  9-H139.12\n",
      "ocr_conf:  0.962\n",
      "652/1162\n",
      "aspect_ratio: 0.81032425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 143.6ms\n",
      "Speed: 6.2ms preprocess, 143.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  -H19.12\n",
      "ocr_conf:  0.905\n",
      "653/1162\n",
      "aspect_ratio: 0.7958342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  4117\n",
      "ocr_conf:  0.72\n",
      "654/1162\n",
      "aspect_ratio: 0.7222486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  1\n",
      "ocr_conf:  0.369\n",
      "655/1162\n",
      "656/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 40.3ms\n",
      "Speed: 4.6ms preprocess, 40.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 56.0ms\n",
      "Speed: 2.8ms preprocess, 56.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.6ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/1162\n",
      "658/1162\n",
      "659/1162\n",
      "660/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.5ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.5ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661/1162\n",
      "662/1162\n",
      "663/1162\n",
      "664/1162\n",
      "665/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.4ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.4ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.5ms\n",
      "Speed: 3.0ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/1162\n",
      "667/1162\n",
      "668/1162\n",
      "669/1162\n",
      "670/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 4.6ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/1162\n",
      "672/1162\n",
      "aspect_ratio: 2.781789\n",
      "recognized_text:  22628\n",
      "ocr_conf:  0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.5ms preprocess, 163.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/1162\n",
      "aspect_ratio: 3.0973985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  R0F-27623\n",
      "ocr_conf:  0.789\n",
      "674/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9493442\n",
      "recognized_text:  2623\n",
      "ocr_conf:  0.889\n",
      "675/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.6ms preprocess, 163.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.893802\n",
      "recognized_text:  827623\n",
      "ocr_conf:  0.723\n",
      "676/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 136.9ms\n",
      "Speed: 4.7ms preprocess, 136.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7796786\n",
      "recognized_text:  00-27623\n",
      "ocr_conf:  0.759\n",
      "677/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.7ms preprocess, 164.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9556255\n",
      "recognized_text:  88627623\n",
      "ocr_conf:  0.639\n",
      "678/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.4ms preprocess, 163.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.791766\n",
      "recognized_text:  8627623\n",
      "ocr_conf:  0.658\n",
      "679/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 169.6ms\n",
      "Speed: 4.3ms preprocess, 169.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8730621\n",
      "recognized_text:  20627673\n",
      "ocr_conf:  0.617\n",
      "680/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.3ms preprocess, 164.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1281943\n",
      "recognized_text:  8527673\n",
      "ocr_conf:  0.686\n",
      "681/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.7ms preprocess, 160.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0037804\n",
      "recognized_text:  85-20623\n",
      "ocr_conf:  0.599\n",
      "682/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 150.5ms\n",
      "Speed: 4.6ms preprocess, 150.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8852324\n",
      "recognized_text:  30-28623\n",
      "ocr_conf:  0.642\n",
      "683/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8130522\n",
      "recognized_text:  27623\n",
      "ocr_conf:  0.708\n",
      "684/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 173.8ms\n",
      "Speed: 13.0ms preprocess, 173.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8698196\n",
      "recognized_text:  27623\n",
      "ocr_conf:  0.761\n",
      "685/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.8ms preprocess, 164.3ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9255626\n",
      "recognized_text:  3527623\n",
      "ocr_conf:  0.724\n",
      "686/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 5.2ms preprocess, 164.2ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0284467\n",
      "recognized_text:  327623\n",
      "ocr_conf:  0.657\n",
      "687/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 159.4ms\n",
      "Speed: 4.7ms preprocess, 159.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8429968\n",
      "recognized_text:  382723\n",
      "ocr_conf:  0.568\n",
      "688/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 158.6ms\n",
      "Speed: 4.6ms preprocess, 158.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.115215\n",
      "recognized_text:  2527623\n",
      "ocr_conf:  0.575\n",
      "689/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.2ms\n",
      "Speed: 4.9ms preprocess, 161.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.070692\n",
      "recognized_text:  2227623\n",
      "ocr_conf:  0.582\n",
      "690/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.5ms\n",
      "Speed: 4.9ms preprocess, 163.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9420004\n",
      "recognized_text:  222623\n",
      "ocr_conf:  0.552\n",
      "691/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.2ms\n",
      "Speed: 4.7ms preprocess, 163.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8707936\n",
      "recognized_text:  22623\n",
      "ocr_conf:  0.517\n",
      "692/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.5ms preprocess, 163.0ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0663521\n",
      "recognized_text:  527623\n",
      "ocr_conf:  0.698\n",
      "693/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 131.8ms\n",
      "Speed: 4.8ms preprocess, 131.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8689895\n",
      "recognized_text:  2527623\n",
      "ocr_conf:  0.568\n",
      "694/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 5.3ms preprocess, 164.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0888407\n",
      "recognized_text:  9927623\n",
      "ocr_conf:  0.601\n",
      "695/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.7ms preprocess, 164.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2211795\n",
      "recognized_text:  28527623\n",
      "ocr_conf:  0.554\n",
      "696/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 5.2ms preprocess, 163.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.206509\n",
      "recognized_text:  0528\n",
      "ocr_conf:  0.383\n",
      "697/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 5.2ms preprocess, 164.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1285853\n",
      "recognized_text:  22528\n",
      "ocr_conf:  0.45\n",
      "698/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 132.0ms\n",
      "Speed: 10.7ms preprocess, 132.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9489565\n",
      "recognized_text:  20528\n",
      "ocr_conf:  0.352\n",
      "699/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.4ms preprocess, 164.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3065698\n",
      "recognized_text:  38-227523\n",
      "ocr_conf:  0.447\n",
      "700/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.3ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2854974\n",
      "recognized_text:  3OF-27623\n",
      "ocr_conf:  0.779\n",
      "701/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.9ms preprocess, 163.8ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0944414\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.897\n",
      "702/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.8ms\n",
      "Speed: 4.5ms preprocess, 164.8ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0323362\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.944\n",
      "703/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.5ms\n",
      "Speed: 4.7ms preprocess, 139.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0522408\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.92\n",
      "704/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2821388\n",
      "recognized_text:  EOF-27623\n",
      "ocr_conf:  0.873\n",
      "705/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.1ms\n",
      "Speed: 4.2ms preprocess, 167.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.193384\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.815\n",
      "706/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.0ms preprocess, 163.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.112737\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.95\n",
      "707/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.4ms preprocess, 164.1ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2079816\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.893\n",
      "708/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.2ms preprocess, 164.0ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9511895\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.858\n",
      "709/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.9ms preprocess, 164.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1786785\n",
      "recognized_text:  305-27623\n",
      "ocr_conf:  0.786\n",
      "710/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.8ms\n",
      "Speed: 4.6ms preprocess, 162.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1547198\n",
      "recognized_text:  820623\n",
      "ocr_conf:  0.608\n",
      "711/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1954927\n",
      "recognized_text:  0F-27623\n",
      "ocr_conf:  0.828\n",
      "712/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2662227\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.913\n",
      "713/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 6.5ms preprocess, 163.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.305583\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.917\n",
      "714/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 133.2ms\n",
      "Speed: 4.6ms preprocess, 133.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.341843\n",
      "recognized_text:  30F27623\n",
      "ocr_conf:  0.825\n",
      "715/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 11.7ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2333746\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.952\n",
      "716/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.7ms preprocess, 163.9ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1129868\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.943\n",
      "717/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.9ms preprocess, 164.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1996236\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.967\n",
      "718/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 161.5ms\n",
      "Speed: 5.0ms preprocess, 161.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.339841\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.932\n",
      "719/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 149.9ms\n",
      "Speed: 4.6ms preprocess, 149.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.212524\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.913\n",
      "720/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.3ms preprocess, 163.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1175911\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.949\n",
      "721/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2495823\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.918\n",
      "722/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.2ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4412863\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.947\n",
      "723/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.1ms preprocess, 164.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.24206\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.913\n",
      "724/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.8ms preprocess, 164.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3950276\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.815\n",
      "725/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2758975\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.915\n",
      "726/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.3ms\n",
      "Speed: 4.7ms preprocess, 161.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.262933\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.873\n",
      "727/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 140.9ms\n",
      "Speed: 4.5ms preprocess, 140.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1899881\n",
      "recognized_text:  EOF-27623\n",
      "ocr_conf:  0.837\n",
      "728/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2224996\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.92\n",
      "729/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2890725\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.934\n",
      "730/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.9ms\n",
      "Speed: 4.7ms preprocess, 162.9ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2716787\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.951\n",
      "731/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.6ms preprocess, 164.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.410344\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.907\n",
      "732/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 162.0ms\n",
      "Speed: 4.9ms preprocess, 162.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4236124\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.929\n",
      "733/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 152.9ms\n",
      "Speed: 5.4ms preprocess, 152.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3500857\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 5.5ms preprocess, 163.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734/1162\n",
      "aspect_ratio: 3.5122454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.8ms\n",
      "Speed: 4.5ms preprocess, 160.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.948\n",
      "735/1162\n",
      "aspect_ratio: 3.2830155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 151.7ms\n",
      "Speed: 4.7ms preprocess, 151.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.955\n",
      "736/1162\n",
      "aspect_ratio: 3.4712276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.1ms\n",
      "Speed: 4.4ms preprocess, 159.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.922\n",
      "737/1162\n",
      "aspect_ratio: 3.3586507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.8ms preprocess, 163.7ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.96\n",
      "738/1162\n",
      "aspect_ratio: 3.3346946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.4ms preprocess, 163.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.898\n",
      "739/1162\n",
      "aspect_ratio: 3.4050453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.944\n",
      "740/1162\n",
      "aspect_ratio: 3.2441378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 136.1ms\n",
      "Speed: 4.4ms preprocess, 136.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  3DF-276.23\n",
      "ocr_conf:  0.867\n",
      "741/1162\n",
      "aspect_ratio: 3.493701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30E-27525\n",
      "ocr_conf:  0.634\n",
      "742/1162\n",
      "aspect_ratio: 3.3178835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.4ms preprocess, 163.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.91\n",
      "743/1162\n",
      "aspect_ratio: 3.2914689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.3ms preprocess, 163.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.96\n",
      "744/1162\n",
      "aspect_ratio: 3.4711916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 164.1ms\n",
      "Speed: 4.6ms preprocess, 164.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.952\n",
      "745/1162\n",
      "aspect_ratio: 3.3020492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 127.9ms\n",
      "Speed: 4.6ms preprocess, 127.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.967\n",
      "746/1162\n",
      "aspect_ratio: 3.303962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.6ms preprocess, 163.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.93\n",
      "747/1162\n",
      "aspect_ratio: 3.35781\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/1162\n",
      "aspect_ratio: 3.383344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-275.23\n",
      "ocr_conf:  0.85\n",
      "749/1162\n",
      "aspect_ratio: 3.3246167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.3ms preprocess, 163.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.929\n",
      "750/1162\n",
      "aspect_ratio: 3.3296926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 126.7ms\n",
      "Speed: 4.7ms preprocess, 126.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.951\n",
      "751/1162\n",
      "aspect_ratio: 3.4412937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.941\n",
      "752/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 177.1ms\n",
      "Speed: 4.2ms preprocess, 177.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.459302\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.931\n",
      "753/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.2ms preprocess, 163.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3610194\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.964\n",
      "754/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 7.2ms preprocess, 164.3ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2940784\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.931\n",
      "755/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.8ms preprocess, 164.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2202096\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.913\n",
      "756/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 5.5ms preprocess, 163.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3715072\n",
      "recognized_text:  B0F-27623\n",
      "ocr_conf:  0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 145.1ms\n",
      "Speed: 4.8ms preprocess, 145.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757/1162\n",
      "aspect_ratio: 3.435389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.7ms preprocess, 163.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.96\n",
      "758/1162\n",
      "aspect_ratio: 3.3018563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.919\n",
      "759/1162\n",
      "aspect_ratio: 3.496174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.7ms preprocess, 163.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "760/1162\n",
      "aspect_ratio: 3.6033502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.3ms preprocess, 163.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.958\n",
      "761/1162\n",
      "aspect_ratio: 3.5598114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.968\n",
      "762/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 170.0ms\n",
      "Speed: 4.8ms preprocess, 170.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5071247\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.948\n",
      "763/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.0ms preprocess, 164.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.279592\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.943\n",
      "764/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 126.5ms\n",
      "Speed: 4.6ms preprocess, 126.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.343259\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.953\n",
      "765/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 158.9ms\n",
      "Speed: 5.1ms preprocess, 158.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3760598\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.948\n",
      "766/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.6ms\n",
      "Speed: 4.3ms preprocess, 165.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3557038\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.964\n",
      "767/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 6.1ms preprocess, 163.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5432706\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.961\n",
      "768/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 4.8ms preprocess, 163.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.583352\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.924\n",
      "769/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 155.6ms\n",
      "Speed: 4.4ms preprocess, 155.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4344\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.917\n",
      "770/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.8ms\n",
      "Speed: 4.6ms preprocess, 162.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4998584\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.925\n",
      "771/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4496422\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.925\n",
      "772/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.3ms preprocess, 163.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4325452\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.934\n",
      "773/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.3ms preprocess, 164.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6110585\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.964\n",
      "774/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.7ms preprocess, 163.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5778487\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/1162\n",
      "aspect_ratio: 3.5926363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.3ms preprocess, 163.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.949\n",
      "776/1162\n",
      "aspect_ratio: 3.455964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.7ms\n",
      "Speed: 4.4ms preprocess, 165.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.943\n",
      "777/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.351836\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.932\n",
      "778/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5961707\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.942\n",
      "779/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.5ms preprocess, 163.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6075323\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.946\n",
      "780/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.9ms\n",
      "Speed: 5.0ms preprocess, 162.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4727943\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.93\n",
      "781/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.5ms preprocess, 163.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.523168\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.937\n",
      "782/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.4ms preprocess, 163.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.466734\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.94\n",
      "783/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.4ms preprocess, 163.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.491969\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.915\n",
      "784/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.7ms\n",
      "Speed: 4.3ms preprocess, 165.7ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5679977\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 154.6ms\n",
      "Speed: 4.7ms preprocess, 154.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/1162\n",
      "aspect_ratio: 3.3156211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 154.0ms\n",
      "Speed: 4.5ms preprocess, 154.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.97\n",
      "786/1162\n",
      "aspect_ratio: 3.5788114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.4ms preprocess, 163.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.97\n",
      "787/1162\n",
      "aspect_ratio: 3.517517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.3ms preprocess, 163.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.91\n",
      "788/1162\n",
      "aspect_ratio: 3.3366332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.1ms preprocess, 164.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.946\n",
      "789/1162\n",
      "aspect_ratio: 3.4085748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 157.0ms\n",
      "Speed: 4.8ms preprocess, 157.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "790/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3598733\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.969\n",
      "791/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4474857\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.938\n",
      "792/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 146.1ms\n",
      "Speed: 4.6ms preprocess, 146.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4866838\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.935\n",
      "793/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.7ms\n",
      "Speed: 5.7ms preprocess, 167.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4325845\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.953\n",
      "794/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.8ms preprocess, 164.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5807483\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 170.3ms\n",
      "Speed: 4.7ms preprocess, 170.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795/1162\n",
      "aspect_ratio: 3.4235163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.976\n",
      "796/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.3ms preprocess, 163.9ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5368752\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.953\n",
      "797/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.8ms preprocess, 163.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4659028\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.952\n",
      "798/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3713531\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.962\n",
      "799/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.4ms preprocess, 163.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4932594\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.936\n",
      "800/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.3ms\n",
      "Speed: 6.6ms preprocess, 165.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3819873\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.951\n",
      "801/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.4ms preprocess, 163.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2389748\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.889\n",
      "802/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.5ms\n",
      "Speed: 4.5ms preprocess, 160.5ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4194138\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.918\n",
      "803/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 141.0ms\n",
      "Speed: 4.5ms preprocess, 141.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.6404836\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.967\n",
      "804/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5670989\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.962\n",
      "805/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.9ms preprocess, 164.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5015147\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.97\n",
      "806/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 5.0ms preprocess, 163.9ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3368518\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.893\n",
      "807/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5819964\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.95\n",
      "808/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 129.9ms\n",
      "Speed: 4.5ms preprocess, 129.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.465564\n",
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.907\n",
      "809/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.6ms preprocess, 163.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4923935\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.949\n",
      "810/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.7ms preprocess, 164.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.5613315\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 153.1ms\n",
      "Speed: 4.6ms preprocess, 153.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811/1162\n",
      "aspect_ratio: 3.467534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 129.6ms\n",
      "Speed: 5.9ms preprocess, 129.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.939\n",
      "812/1162\n",
      "aspect_ratio: 3.6658604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.0ms preprocess, 163.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.961\n",
      "813/1162\n",
      "aspect_ratio: 3.5538573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.969\n",
      "814/1162\n",
      "aspect_ratio: 3.5219176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 129.1ms\n",
      "Speed: 4.4ms preprocess, 129.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n",
      "815/1162\n",
      "aspect_ratio: 3.4849272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.4ms preprocess, 163.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.974\n",
      "816/1162\n",
      "aspect_ratio: 3.565928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.6ms preprocess, 163.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.967\n",
      "817/1162\n",
      "aspect_ratio: 3.7728863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 133.7ms\n",
      "Speed: 5.3ms preprocess, 133.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.971\n",
      "818/1162\n",
      "aspect_ratio: 3.5005088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.5ms\n",
      "Speed: 5.5ms preprocess, 163.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "819/1162\n",
      "aspect_ratio: 3.5329392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 150.5ms\n",
      "Speed: 4.4ms preprocess, 150.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.974\n",
      "820/1162\n",
      "aspect_ratio: 3.5862856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.968\n",
      "821/1162\n",
      "aspect_ratio: 3.5736308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n",
      "822/1162\n",
      "aspect_ratio: 3.454538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.2ms preprocess, 163.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.958\n",
      "823/1162\n",
      "aspect_ratio: 3.4188035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 134.1ms\n",
      "Speed: 4.5ms preprocess, 134.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.972\n",
      "824/1162\n",
      "aspect_ratio: 3.312815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.951\n",
      "825/1162\n",
      "aspect_ratio: 3.4633527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.5ms preprocess, 163.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.949\n",
      "826/1162\n",
      "aspect_ratio: 3.323441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 134.5ms\n",
      "Speed: 5.1ms preprocess, 134.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.962\n",
      "827/1162\n",
      "aspect_ratio: 3.385066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.5ms preprocess, 163.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.952\n",
      "828/1162\n",
      "aspect_ratio: 3.4594493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 162.8ms\n",
      "Speed: 4.5ms preprocess, 162.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.956\n",
      "829/1162\n",
      "aspect_ratio: 3.2451606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.7ms preprocess, 163.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.926\n",
      "830/1162\n",
      "aspect_ratio: 3.4828348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.961\n",
      "831/1162\n",
      "aspect_ratio: 3.3842633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 147.1ms\n",
      "Speed: 4.7ms preprocess, 147.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.97\n",
      "832/1162\n",
      "aspect_ratio: 3.4717634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.965\n",
      "833/1162\n",
      "aspect_ratio: 3.3725042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.3ms preprocess, 163.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.973\n",
      "834/1162\n",
      "aspect_ratio: 3.4500995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.967\n",
      "835/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 171.5ms\n",
      "Speed: 4.8ms preprocess, 171.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2699854\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.941\n",
      "836/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 5.1ms preprocess, 164.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.196252\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.945\n",
      "837/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.3ms preprocess, 164.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2395349\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.955\n",
      "838/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 127.2ms\n",
      "Speed: 4.2ms preprocess, 127.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.064001\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.965\n",
      "839/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.7ms preprocess, 164.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.167176\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.924\n",
      "840/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.7ms preprocess, 164.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1267257\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.961\n",
      "841/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 159.8ms\n",
      "Speed: 4.8ms preprocess, 159.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2444866\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.941\n",
      "842/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.0ms\n",
      "Speed: 8.8ms preprocess, 160.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2793603\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.965\n",
      "843/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.9ms preprocess, 163.9ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2250996\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.972\n",
      "844/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.3ms preprocess, 163.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.189175\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.905\n",
      "845/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 131.4ms\n",
      "Speed: 4.5ms preprocess, 131.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4319472\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.972\n",
      "846/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1727064\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.972\n",
      "847/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.4ms preprocess, 164.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.386355\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.2ms preprocess, 163.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848/1162\n",
      "aspect_ratio: 3.302493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 11.2ms preprocess, 163.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.973\n",
      "849/1162\n",
      "aspect_ratio: 3.1566958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.5ms\n",
      "Speed: 4.9ms preprocess, 160.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.959\n",
      "850/1162\n",
      "aspect_ratio: 3.058669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 144.3ms\n",
      "Speed: 4.3ms preprocess, 144.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n",
      "851/1162\n",
      "aspect_ratio: 3.0867565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "852/1162\n",
      "aspect_ratio: 3.0579135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.6ms preprocess, 163.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.884\n",
      "853/1162\n",
      "aspect_ratio: 3.146758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 133.4ms\n",
      "Speed: 5.3ms preprocess, 133.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.958\n",
      "854/1162\n",
      "aspect_ratio: 3.0197842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.939\n",
      "855/1162\n",
      "aspect_ratio: 3.0843012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.7ms preprocess, 163.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.959\n",
      "856/1162\n",
      "aspect_ratio: 3.2262352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.0ms\n",
      "Speed: 4.6ms preprocess, 161.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "857/1162\n",
      "aspect_ratio: 2.8558135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.6ms preprocess, 163.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.921\n",
      "858/1162\n",
      "aspect_ratio: 3.1361477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 5.4ms preprocess, 163.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.964\n",
      "859/1162\n",
      "aspect_ratio: 3.203119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 11.4ms preprocess, 163.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.95\n",
      "860/1162\n",
      "aspect_ratio: 3.1588602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.4ms\n",
      "Speed: 4.4ms preprocess, 160.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.968\n",
      "861/1162\n",
      "aspect_ratio: 3.0486095\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 141.8ms\n",
      "Speed: 4.5ms preprocess, 141.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/1162\n",
      "aspect_ratio: 2.8796637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.6ms preprocess, 163.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.946\n",
      "863/1162\n",
      "aspect_ratio: 2.9477227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.977\n",
      "864/1162\n",
      "aspect_ratio: 2.8983467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.971\n",
      "865/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 144.4ms\n",
      "Speed: 5.1ms preprocess, 144.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.084463\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.974\n",
      "866/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1608865\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n",
      "867/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.3ms\n",
      "Speed: 4.5ms preprocess, 165.3ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8758016\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.961\n",
      "868/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 134.0ms\n",
      "Speed: 4.3ms preprocess, 134.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9923742\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.947\n",
      "869/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.9ms\n",
      "Speed: 4.3ms preprocess, 163.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.746509\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.946\n",
      "870/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0254693\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.969\n",
      "871/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 129.6ms\n",
      "Speed: 4.6ms preprocess, 129.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.141988\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.957\n",
      "872/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.3ms\n",
      "Speed: 4.4ms preprocess, 163.3ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0505118\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.964\n",
      "873/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.3ms preprocess, 163.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2357435\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.975\n",
      "874/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 136.1ms\n",
      "Speed: 4.3ms preprocess, 136.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.312399\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.975\n",
      "875/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4617686\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.977\n",
      "876/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.5ms preprocess, 164.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4848626\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.968\n",
      "877/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 134.4ms\n",
      "Speed: 4.6ms preprocess, 134.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.511161\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.97\n",
      "878/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 5.3ms preprocess, 164.2ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.4687424\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.969\n",
      "879/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3877583\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.974\n",
      "880/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.2ms\n",
      "Speed: 4.5ms preprocess, 164.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.31344\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.979\n",
      "881/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 131.5ms\n",
      "Speed: 4.5ms preprocess, 131.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2545877\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.984\n",
      "882/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.6ms\n",
      "Speed: 4.6ms preprocess, 164.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.246117\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.976\n",
      "883/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3273644\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.968\n",
      "884/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.4ms preprocess, 163.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1201575\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.938\n",
      "885/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1952596\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.976\n",
      "886/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 132.6ms\n",
      "Speed: 4.4ms preprocess, 132.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.119482\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.975\n",
      "887/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.474964\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.964\n",
      "888/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.5ms preprocess, 164.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.983717\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.937\n",
      "889/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0856361\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.972\n",
      "890/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 133.6ms\n",
      "Speed: 4.6ms preprocess, 133.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.221173\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.948\n",
      "891/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.1ms\n",
      "Speed: 4.8ms preprocess, 164.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1362574\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.953\n",
      "892/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 163.8ms\n",
      "Speed: 5.1ms preprocess, 163.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8923764\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.975\n",
      "893/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 plates, 161.3ms\n",
      "Speed: 4.0ms preprocess, 161.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8402007\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.971\n",
      "894/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 144.0ms\n",
      "Speed: 4.2ms preprocess, 144.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6908445\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.974\n",
      "895/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.2ms\n",
      "Speed: 4.2ms preprocess, 164.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.756198\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.938\n",
      "896/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7313294\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.963\n",
      "897/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 165.3ms\n",
      "Speed: 4.5ms preprocess, 165.3ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.857028\n",
      "recognized_text:  S0F-276.23\n",
      "ocr_conf:  0.839\n",
      "898/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.1ms\n",
      "Speed: 4.6ms preprocess, 139.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.049327\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.915\n",
      "899/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.1ms preprocess, 163.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.335371\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n",
      "900/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.1ms preprocess, 163.8ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6449873\n",
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 158.8ms\n",
      "Speed: 4.5ms preprocess, 158.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/1162\n",
      "aspect_ratio: 2.5591817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-276.23\n",
      "ocr_conf:  0.908\n",
      "902/1162\n",
      "aspect_ratio: 2.1094773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-27623\n",
      "ocr_conf:  0.983\n",
      "903/1162\n",
      "aspect_ratio: 2.162037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30F-2762\n",
      "ocr_conf:  0.927\n",
      "904/1162\n",
      "aspect_ratio: 1.7533426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 126.5ms\n",
      "Speed: 4.4ms preprocess, 126.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  FE3\n",
      "ocr_conf:  0.299\n",
      "905/1162\n",
      "aspect_ratio: 1.3833249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 13.0ms preprocess, 163.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  REB\n",
      "ocr_conf:  0.483\n",
      "906/1162\n",
      "aspect_ratio: 1.0230733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.3ms preprocess, 163.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  RECF\n",
      "ocr_conf:  0.464\n",
      "907/1162\n",
      "aspect_ratio: 0.6803077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.0ms\n",
      "Speed: 5.9ms preprocess, 164.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  RO\n",
      "ocr_conf:  0.361\n",
      "908/1162\n",
      "909/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 74.5ms\n",
      "Speed: 4.2ms preprocess, 74.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0695655\n",
      "recognized_text:  Jo\n",
      "ocr_conf:  0.25\n",
      "910/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 165.1ms\n",
      "Speed: 4.7ms preprocess, 165.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 4.8ms preprocess, 27.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 2.6ms preprocess, 26.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911/1162\n",
      "912/1162\n",
      "913/1162\n",
      "aspect_ratio: 2.8870797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  Drm\n",
      "ocr_conf:  0.3\n",
      "914/1162\n",
      "915/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 96.3ms\n",
      "Speed: 4.8ms preprocess, 96.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9588459\n",
      "recognized_text:  Dam\n",
      "ocr_conf:  0.627\n",
      "916/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 164.4ms\n",
      "Speed: 4.4ms preprocess, 164.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.5ms\n",
      "Speed: 4.5ms preprocess, 49.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917/1162\n",
      "918/1162\n",
      "919/1162\n",
      "920/1162\n",
      "aspect_ratio: 1.7842261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.3ms\n",
      "Speed: 4.2ms preprocess, 163.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  INTFRT\n",
      "ocr_conf:  0.364\n",
      "921/1162\n",
      "922/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 4.3ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.0ms\n",
      "Speed: 2.9ms preprocess, 32.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 7.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923/1162\n",
      "924/1162\n",
      "925/1162\n",
      "926/1162\n",
      "927/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.7ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.6ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/1162\n",
      "929/1162\n",
      "930/1162\n",
      "931/1162\n",
      "932/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.6ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.6ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.8ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933/1162\n",
      "934/1162\n",
      "935/1162\n",
      "936/1162\n",
      "937/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.5ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.6ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/1162\n",
      "939/1162\n",
      "940/1162\n",
      "941/1162\n",
      "942/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 10.3ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943/1162\n",
      "944/1162\n",
      "945/1162\n",
      "946/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 2.9ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.6ms preprocess, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 3.1ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 2.7ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947/1162\n",
      "948/1162\n",
      "949/1162\n",
      "950/1162\n",
      "951/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.3ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.3ms\n",
      "Speed: 2.5ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.6ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 2.6ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.7ms preprocess, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952/1162\n",
      "953/1162\n",
      "954/1162\n",
      "955/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 150.4ms\n",
      "Speed: 4.6ms preprocess, 150.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956/1162\n",
      "aspect_ratio: 3.6301236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.7ms preprocess, 163.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.778\n",
      "957/1162\n",
      "aspect_ratio: 3.3970947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  301-54829\n",
      "ocr_conf:  0.786\n",
      "958/1162\n",
      "aspect_ratio: 3.625845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.8ms preprocess, 163.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30\n",
      "ocr_conf:  0.662\n",
      "959/1162\n",
      "aspect_ratio: 3.594876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 147.1ms\n",
      "Speed: 4.9ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30\n",
      "ocr_conf:  0.473\n",
      "960/1162\n",
      "961/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.5ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 34.9ms\n",
      "Speed: 2.7ms preprocess, 34.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962/1162\n",
      "963/1162\n",
      "964/1162\n",
      "965/1162\n",
      "aspect_ratio: 3.534248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.7ms preprocess, 163.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  E23\n",
      "ocr_conf:  0.273\n",
      "966/1162\n",
      "aspect_ratio: 3.188592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 144.2ms\n",
      "Speed: 4.4ms preprocess, 144.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  562\n",
      "ocr_conf:  0.382\n",
      "967/1162\n",
      "aspect_ratio: 3.255441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.3ms preprocess, 163.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  5E73\n",
      "ocr_conf:  0.341\n",
      "968/1162\n",
      "aspect_ratio: 3.5356581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  04-54572)\n",
      "ocr_conf:  0.55\n",
      "969/1162\n",
      "aspect_ratio: 3.2341568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.7ms preprocess, 164.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  015482\n",
      "ocr_conf:  0.489\n",
      "970/1162\n",
      "aspect_ratio: 3.0839305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 166.0ms\n",
      "Speed: 4.8ms preprocess, 166.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "971/1162\n",
      "aspect_ratio: 3.0729463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 151.8ms\n",
      "Speed: 4.9ms preprocess, 151.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  O0A-64E23\n",
      "ocr_conf:  0.55\n",
      "972/1162\n",
      "aspect_ratio: 2.772258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  (0A-64823\n",
      "ocr_conf:  0.614\n",
      "973/1162\n",
      "aspect_ratio: 3.2764323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  CCASLEZ\n",
      "ocr_conf:  0.541\n",
      "974/1162\n",
      "aspect_ratio: 2.9724276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823)\n",
      "ocr_conf:  0.794\n",
      "975/1162\n",
      "aspect_ratio: 3.1401494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.6ms preprocess, 163.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.905\n",
      "976/1162\n",
      "aspect_ratio: 3.1464496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  (30A-64823\n",
      "ocr_conf:  0.897\n",
      "977/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.2ms preprocess, 163.8ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.876651\n",
      "recognized_text:  (30A-64823\n",
      "ocr_conf:  0.81\n",
      "978/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.6ms preprocess, 164.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0789587\n",
      "recognized_text:  (30A-648.23\n",
      "ocr_conf:  0.831\n",
      "979/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.7ms preprocess, 164.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8729343\n",
      "recognized_text:  CODRAD\n",
      "ocr_conf:  0.363\n",
      "980/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.7ms preprocess, 163.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0850048\n",
      "recognized_text:  0\n",
      "ocr_conf:  0.149\n",
      "981/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 150.8ms\n",
      "Speed: 4.7ms preprocess, 150.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1501808\n",
      "recognized_text:  30A-04823\n",
      "ocr_conf:  0.787\n",
      "982/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.7ms preprocess, 163.8ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9155424\n",
      "recognized_text:  30A-0(833\n",
      "ocr_conf:  0.678\n",
      "983/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.4ms preprocess, 163.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9632957\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.755\n",
      "984/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.3ms preprocess, 163.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.04833\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.915\n",
      "985/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.2ms\n",
      "Speed: 4.5ms preprocess, 139.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1775432\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.865\n",
      "986/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0144763\n",
      "recognized_text:  30-64823\n",
      "ocr_conf:  0.899\n",
      "987/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.2ms preprocess, 163.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.181663\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.905\n",
      "988/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2473757\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.936\n",
      "989/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.4ms preprocess, 160.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3687794\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.934\n",
      "990/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 135.3ms\n",
      "Speed: 4.9ms preprocess, 135.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9445968\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.942\n",
      "991/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.3ms preprocess, 164.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.183222\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.925\n",
      "992/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0110881\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.912\n",
      "993/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.7ms preprocess, 160.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1795647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 157.5ms\n",
      "Speed: 4.1ms preprocess, 157.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.94\n",
      "994/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9256313\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.539\n",
      "995/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.4ms\n",
      "Speed: 4.6ms preprocess, 139.4ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7920055\n",
      "recognized_text:  007\n",
      "ocr_conf:  0.348\n",
      "996/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 151.3ms\n",
      "Speed: 4.5ms preprocess, 151.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0377777\n",
      "recognized_text:  3\n",
      "ocr_conf:  0.447\n",
      "997/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2443862\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.94\n",
      "998/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.5ms preprocess, 163.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1748087\n",
      "recognized_text:  30-5482\n",
      "ocr_conf:  0.703\n",
      "999/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 141.2ms\n",
      "Speed: 4.4ms preprocess, 141.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1706302\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "1000/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.4ms preprocess, 164.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.064577\n",
      "recognized_text:  \n",
      "ocr_conf:  0.0\n",
      "1001/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.983819\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.892\n",
      "1002/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.7ms preprocess, 163.7ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.028279\n",
      "recognized_text:  3-6023\n",
      "ocr_conf:  0.564\n",
      "1003/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 136.1ms\n",
      "Speed: 6.9ms preprocess, 136.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9363177\n",
      "recognized_text:  S01-8828\n",
      "ocr_conf:  0.439\n",
      "1004/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.000749\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.921\n",
      "1005/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0768833\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.899\n",
      "1006/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.828524\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.956\n",
      "1007/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 139.8ms\n",
      "Speed: 4.6ms preprocess, 139.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8089306\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.944\n",
      "1008/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1260128\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.962\n",
      "1009/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.4ms preprocess, 164.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1935947\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.882\n",
      "1010/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.3ms preprocess, 164.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.986371\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.917\n",
      "1011/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 148.9ms\n",
      "Speed: 4.5ms preprocess, 148.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.897719\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.937\n",
      "1012/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.3ms preprocess, 163.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0607877\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.946\n",
      "1013/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 5.5ms preprocess, 164.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0626664\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.6ms preprocess, 163.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014/1162\n",
      "aspect_ratio: 3.0620859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.5ms preprocess, 160.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30-5823\n",
      "ocr_conf:  0.544\n",
      "1015/1162\n",
      "aspect_ratio: 3.0786996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.8ms\n",
      "Speed: 4.6ms preprocess, 159.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.913\n",
      "1016/1162\n",
      "aspect_ratio: 3.0685298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.4ms preprocess, 163.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.888\n",
      "1017/1162\n",
      "aspect_ratio: 3.2714837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.904\n",
      "1018/1162\n",
      "aspect_ratio: 2.9252143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.4ms preprocess, 163.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.946\n",
      "1019/1162\n",
      "aspect_ratio: 2.9570737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.2ms\n",
      "Speed: 4.8ms preprocess, 159.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.951\n",
      "1020/1162\n",
      "aspect_ratio: 3.0773895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 162.9ms\n",
      "Speed: 4.3ms preprocess, 162.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.943\n",
      "1021/1162\n",
      "aspect_ratio: 3.078147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 141.5ms\n",
      "Speed: 4.8ms preprocess, 141.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.951\n",
      "1022/1162\n",
      "aspect_ratio: 2.9889295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 151.7ms\n",
      "Speed: 4.5ms preprocess, 151.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.949\n",
      "1023/1162\n",
      "aspect_ratio: 2.9232867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.7ms\n",
      "Speed: 4.5ms preprocess, 165.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.882\n",
      "1024/1162\n",
      "aspect_ratio: 2.9411702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.0ms preprocess, 163.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.908\n",
      "1025/1162\n",
      "aspect_ratio: 3.079136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 158.4ms\n",
      "Speed: 4.5ms preprocess, 158.4ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.949\n",
      "1026/1162\n",
      "aspect_ratio: 3.1073747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 143.4ms\n",
      "Speed: 4.3ms preprocess, 143.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.884\n",
      "1027/1162\n",
      "aspect_ratio: 3.0808039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.956\n",
      "1028/1162\n",
      "aspect_ratio: 3.133019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.4ms preprocess, 163.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.954\n",
      "1029/1162\n",
      "aspect_ratio: 3.1549377\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 172.8ms\n",
      "Speed: 4.7ms preprocess, 172.8ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1162\n",
      "aspect_ratio: 3.189317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.2ms\n",
      "Speed: 4.5ms preprocess, 160.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.867\n",
      "1031/1162\n",
      "aspect_ratio: 2.925702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.889\n",
      "1032/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.4ms preprocess, 163.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.999322\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.944\n",
      "1033/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.919345\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.922\n",
      "1034/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2580593\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.965\n",
      "1035/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.4ms preprocess, 163.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.243159\n",
      "recognized_text:  30L54020\n",
      "ocr_conf:  0.418\n",
      "1036/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.6ms preprocess, 164.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2397494\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.945\n",
      "1037/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.0ms preprocess, 163.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.223938\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1038/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.5ms preprocess, 164.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.253067\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.953\n",
      "1039/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 159.5ms\n",
      "Speed: 4.6ms preprocess, 159.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1671677\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.923\n",
      "1040/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 132.8ms\n",
      "Speed: 4.8ms preprocess, 132.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1327443\n",
      "recognized_text:  (30A-64R23\n",
      "ocr_conf:  0.773\n",
      "1041/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 166.3ms\n",
      "Speed: 4.7ms preprocess, 166.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0887277\n",
      "recognized_text:  (30A-64823\n",
      "ocr_conf:  0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 143.4ms\n",
      "Speed: 4.2ms preprocess, 143.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042/1162\n",
      "aspect_ratio: 3.168905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 5.5ms preprocess, 163.3ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  (30A-64823\n",
      "ocr_conf:  0.903\n",
      "1043/1162\n",
      "aspect_ratio: 3.0933013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.3ms preprocess, 163.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  (30-64823\n",
      "ocr_conf:  0.865\n",
      "1044/1162\n",
      "aspect_ratio: 3.0138283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.908\n",
      "1045/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 168.0ms\n",
      "Speed: 6.7ms preprocess, 168.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0404181\n",
      "recognized_text:  A-64823\n",
      "ocr_conf:  0.719\n",
      "1046/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.6ms preprocess, 164.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0794113\n",
      "recognized_text:  A8823\n",
      "ocr_conf:  0.332\n",
      "1047/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 143.7ms\n",
      "Speed: 5.3ms preprocess, 143.7ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1234531\n",
      "recognized_text:  R453\n",
      "ocr_conf:  0.42\n",
      "1048/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.4ms preprocess, 163.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.946472\n",
      "recognized_text:  623\n",
      "ocr_conf:  0.367\n",
      "1049/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.4ms preprocess, 163.0ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7381828\n",
      "recognized_text:  EMREAR\n",
      "ocr_conf:  0.337\n",
      "1050/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.948562\n",
      "recognized_text:  EEEA\n",
      "ocr_conf:  0.3\n",
      "1051/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.8ms\n",
      "Speed: 4.9ms preprocess, 167.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0055866\n",
      "recognized_text:  EEA\n",
      "ocr_conf:  0.447\n",
      "1052/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 149.6ms\n",
      "Speed: 4.6ms preprocess, 149.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1623933\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.944\n",
      "1053/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.8ms preprocess, 163.4ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1193678\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.868\n",
      "1054/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.274112\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.95\n",
      "1055/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2914732\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.957\n",
      "1056/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 5.2ms preprocess, 163.8ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2833529\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.95\n",
      "1057/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 127.3ms\n",
      "Speed: 4.5ms preprocess, 127.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.252106\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.952\n",
      "1058/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 153.8ms\n",
      "Speed: 4.6ms preprocess, 153.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3312118\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.97\n",
      "1059/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.3ms preprocess, 163.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.3496783\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.925\n",
      "1060/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2713647\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.958\n",
      "1061/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.3ms\n",
      "Speed: 4.5ms preprocess, 167.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2911122\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.931\n",
      "1062/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.6ms\n",
      "Speed: 4.4ms preprocess, 161.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2559862\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.968\n",
      "1063/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.0ms\n",
      "Speed: 4.5ms preprocess, 165.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.265366\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.959\n",
      "1064/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 146.7ms\n",
      "Speed: 4.4ms preprocess, 146.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0029664\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.944\n",
      "1065/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 168.1ms\n",
      "Speed: 4.8ms preprocess, 168.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.8854678\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.968\n",
      "1066/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 plates, 164.1ms\n",
      "Speed: 4.6ms preprocess, 164.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0986755\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.95\n",
      "1067/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 169.0ms\n",
      "Speed: 4.4ms preprocess, 169.0ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.061249\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.969\n",
      "1068/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 152.7ms\n",
      "Speed: 4.6ms preprocess, 152.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1239738\n",
      "recognized_text:  30A-64923\n",
      "ocr_conf:  0.887\n",
      "1069/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 166.0ms\n",
      "Speed: 4.4ms preprocess, 166.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0575254\n",
      "recognized_text:  54823\n",
      "ocr_conf:  0.477\n",
      "1070/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.4ms preprocess, 164.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0676854\n",
      "recognized_text:  3064823)\n",
      "ocr_conf:  0.719\n",
      "1071/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 168.5ms\n",
      "Speed: 4.6ms preprocess, 168.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1611693\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.964\n",
      "1072/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2167253\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.967\n",
      "1073/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.6ms\n",
      "Speed: 4.9ms preprocess, 162.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1912568\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.978\n",
      "1074/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 153.8ms\n",
      "Speed: 4.7ms preprocess, 153.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.32436\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.97\n",
      "1075/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.418735\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.963\n",
      "1076/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.3ms preprocess, 164.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2270546\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1077/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2466557\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.968\n",
      "1078/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.5ms preprocess, 163.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1400657\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.93\n",
      "1079/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 156.6ms\n",
      "Speed: 4.7ms preprocess, 156.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.103695\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.943\n",
      "1080/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.6ms preprocess, 163.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.260248\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.961\n",
      "1081/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2185957\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.963\n",
      "1082/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.8ms preprocess, 163.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0862055\n",
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.856\n",
      "1083/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 172.0ms\n",
      "Speed: 4.4ms preprocess, 172.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0947814\n",
      "recognized_text:  (30A-648.23\n",
      "ocr_conf:  0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.4ms preprocess, 163.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084/1162\n",
      "aspect_ratio: 3.1102676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.5ms preprocess, 163.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-64823\n",
      "ocr_conf:  0.96\n",
      "1085/1162\n",
      "aspect_ratio: 3.194223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.5ms preprocess, 163.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.971\n",
      "1086/1162\n",
      "aspect_ratio: 3.2613082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1087/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.5ms preprocess, 163.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.238158\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.974\n",
      "1088/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.7ms\n",
      "Speed: 4.6ms preprocess, 161.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.266847\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1089/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 143.6ms\n",
      "Speed: 4.7ms preprocess, 143.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.165989\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.929\n",
      "1090/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2514982\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.969\n",
      "1091/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.4ms preprocess, 163.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2145464\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.975\n",
      "1092/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 133.7ms\n",
      "Speed: 4.8ms preprocess, 133.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2155828\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.97\n",
      "1093/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 172.6ms\n",
      "Speed: 4.4ms preprocess, 172.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1464074\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.965\n",
      "1094/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.113459\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.957\n",
      "1095/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 166.7ms\n",
      "Speed: 4.5ms preprocess, 166.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.107127\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.93\n",
      "1096/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 159.4ms\n",
      "Speed: 4.5ms preprocess, 159.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.16111\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1097/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 167.1ms\n",
      "Speed: 5.2ms preprocess, 167.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.212741\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.9\n",
      "1098/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.5ms preprocess, 164.5ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1602628\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.97\n",
      "1099/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1612408\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1100/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.4ms preprocess, 164.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1507447\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.951\n",
      "1101/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9309864\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.957\n",
      "1102/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 138.4ms\n",
      "Speed: 4.3ms preprocess, 138.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0702846\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.964\n",
      "1103/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.7ms preprocess, 164.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9949112\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.973\n",
      "1104/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.9ms preprocess, 164.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0577626\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1105/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.6ms preprocess, 164.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.055751\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.977\n",
      "1106/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.7ms preprocess, 163.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0198696\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.975\n",
      "1107/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 159.2ms\n",
      "Speed: 4.5ms preprocess, 159.2ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0241766\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.962\n",
      "1108/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 144.1ms\n",
      "Speed: 4.4ms preprocess, 144.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9244382\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.965\n",
      "1109/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 170.4ms\n",
      "Speed: 4.4ms preprocess, 170.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1656044\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.973\n",
      "1110/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.4ms preprocess, 163.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.9742036\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.973\n",
      "1111/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1594722\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.969\n",
      "1112/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 132.3ms\n",
      "Speed: 4.4ms preprocess, 132.3ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0746007\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.974\n",
      "1113/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 169.6ms\n",
      "Speed: 4.4ms preprocess, 169.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0010211\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1114/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1508584\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.898\n",
      "1115/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 169.1ms\n",
      "Speed: 4.5ms preprocess, 169.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.110578\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.974\n",
      "1116/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.4ms preprocess, 163.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0518053\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.972\n",
      "1117/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.100041\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.968\n",
      "1118/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.8ms preprocess, 164.3ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.051477\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.97\n",
      "1119/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 12.6ms preprocess, 163.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1577892\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.954\n",
      "1120/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 130.1ms\n",
      "Speed: 4.5ms preprocess, 130.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1430438\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.892\n",
      "1121/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.163637\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.945\n",
      "1122/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1570883\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.968\n",
      "1123/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.2435882\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.964\n",
      "1124/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 135.9ms\n",
      "Speed: 4.6ms preprocess, 135.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.1308339\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1125/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.1ms\n",
      "Speed: 4.8ms preprocess, 164.1ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.138791\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.882\n",
      "1126/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.6ms preprocess, 163.7ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.147398\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.965\n",
      "1127/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.5ms preprocess, 163.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0943847\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.952\n",
      "1128/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.5ms\n",
      "Speed: 4.6ms preprocess, 161.5ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.02138\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.971\n",
      "1129/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 156.8ms\n",
      "Speed: 5.0ms preprocess, 156.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0568671\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.967\n",
      "1130/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.9ms\n",
      "Speed: 4.6ms preprocess, 164.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.009143\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.958\n",
      "1131/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.3ms preprocess, 164.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 3.0499678\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1132/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7664406\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.931\n",
      "1133/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 4.4ms preprocess, 164.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.769296\n",
      "recognized_text:  30A-64923\n",
      "ocr_conf:  0.923\n",
      "1134/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.5ms preprocess, 163.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7625942\n",
      "recognized_text:  30A-648.23)\n",
      "ocr_conf:  0.861\n",
      "1135/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 145.0ms\n",
      "Speed: 4.9ms preprocess, 145.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.7297826\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.923\n",
      "1136/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.7ms\n",
      "Speed: 4.5ms preprocess, 164.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.774938\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.965\n",
      "1137/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6594815\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.959\n",
      "1138/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.5ms preprocess, 164.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6992104\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.957\n",
      "1139/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.8ms preprocess, 160.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.6578119\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.968\n",
      "1140/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.2ms preprocess, 163.5ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5981855\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.934\n",
      "1141/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 147.5ms\n",
      "Speed: 5.2ms preprocess, 147.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5866456\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.956\n",
      "1142/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 156.4ms\n",
      "Speed: 4.8ms preprocess, 156.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5752003\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.926\n",
      "1143/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.5ms preprocess, 163.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.5865433\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.966\n",
      "1144/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 5.1ms preprocess, 164.0ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4447865\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.951\n",
      "1145/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 5.5ms preprocess, 164.4ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_ratio: 2.4863815\n",
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.9ms preprocess, 163.5ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1162\n",
      "aspect_ratio: 2.5809183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.951\n",
      "1147/1162\n",
      "aspect_ratio: 2.5842428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.2ms\n",
      "Speed: 4.6ms preprocess, 161.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.971\n",
      "1148/1162\n",
      "aspect_ratio: 2.8017688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 156.7ms\n",
      "Speed: 4.6ms preprocess, 156.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.23\n",
      "ocr_conf:  0.977\n",
      "1149/1162\n",
      "aspect_ratio: 2.337107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.3ms\n",
      "Speed: 5.0ms preprocess, 164.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  30A-648.\n",
      "ocr_conf:  0.919\n",
      "1150/1162\n",
      "aspect_ratio: 1.7822965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.5ms preprocess, 163.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  GOLE3UA-0\n",
      "ocr_conf:  0.68\n",
      "1151/1162\n",
      "aspect_ratio: 1.1895442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.4ms preprocess, 163.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  G3UA\n",
      "ocr_conf:  0.677\n",
      "1152/1162\n",
      "aspect_ratio: 0.5779664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 166.4ms\n",
      "Speed: 4.7ms preprocess, 166.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognized_text:  53\n",
      "ocr_conf:  0.583\n",
      "1153/1162\n",
      "1154/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 99.1ms\n",
      "Speed: 4.1ms preprocess, 99.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.7ms preprocess, 26.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.4ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1162\n",
      "1156/1162\n",
      "1157/1162\n",
      "1158/1162\n",
      "1159/1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.6ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.6ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160/1162\n",
      "1161/1162\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'test_video/test_5.mp4'\n",
    "out_path = 'results/test_5.avi'\n",
    "test_vid_yolov8(input_dir, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4ZI0l7Sv-Nq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Function for integrating Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_apN7fTvNQo"
   },
   "source": [
    "Download pretrained deep association metric model called `mars-small128.pb`, can be downloaded from [here](https://drive.google.com/drive/folders/1n0jB3zwJysi6YDi4n0HVKz5yOZ0eNA2B?usp=sharing) and put under ./model_data/mars-small128.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "\n",
    "def tracker_test_vid(vid_dir, out_path):\n",
    "    # Declaring variables for video processing.\n",
    "    cap = cv2.VideoCapture(vid_dir)\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    file_name = os.path.join(out_path, 'out_' + vid_dir.split('/')[-1])\n",
    "\n",
    "    out = cv2.VideoWriter(file_name, codec, fps, (width, height))\n",
    "\n",
    "    # Declaring variables for tracker.\n",
    "    max_cosine_distance = 0.4\n",
    "    nn_budget = None\n",
    "\n",
    "    # Intializing tracker\n",
    "    model_filename = 'model_data/mars-small128.pb'\n",
    "    encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "    tracker = Tracker(metric)\n",
    "\n",
    "    # Initializing some helper variables.\n",
    "    ct = 0\n",
    "    preds = []\n",
    "    total_obj = 0\n",
    "    rec_tot_time = 1\n",
    "    alpha = 0.5\n",
    "\n",
    "    # Reading video frame by frame.\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        if ret == True:\n",
    "\n",
    "            h, w = img.shape[:2]\n",
    "            print(ct)\n",
    "\n",
    "            w_scale = w / 1.55\n",
    "            h_scale = h / 17\n",
    "\n",
    "            # Method to blend two images, here used to make the information box transparent.\n",
    "            overlay_img = img.copy()\n",
    "            cv2.rectangle(img, (int(w_scale), 0), (w, int(h_scale * 3.4)), (0, 0, 0), -1)\n",
    "            cv2.addWeighted(img, alpha, overlay_img, 1 - alpha, 0, overlay_img)\n",
    "\n",
    "            # Noting time for calculating FPS.\n",
    "            prev_time = time.time()\n",
    "\n",
    "            # Use the model\n",
    "            results = model(img)  # predict on an image\n",
    "\n",
    "            for result in results:\n",
    "                print(\"result\", result)\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    # Get the bounding boxes and image for each result\n",
    "                    bboxes = result.boxes[0].cpu().numpy()\n",
    "                    if len(bboxes) > 0:\n",
    "                        bboxes_np = []\n",
    "                        for i in bboxes:\n",
    "                            bbox = i.xyxy\n",
    "                            bboxes_np.append(bbox)\n",
    "                    # Convert the list of bounding boxes to a NumPy array\n",
    "                    bboxes_np = np.array(bboxes_np)\n",
    "                    print(\"bboxes_np\", bboxes_np)\n",
    "                    #     # Chuyển đổi bbox thành mảng NumPy\n",
    "                    #     bbox = np.array(bbox)\n",
    "                    # Getting appearence features of the object.\n",
    "                    features = encoder(img, bboxes_np[0])\n",
    "                    print(\"features\", features)\n",
    "                    # Storing all the required info in a list.\n",
    "                    detections = [Detection(bbox, feature) for bbox, feature in\n",
    "                                zip(bboxes_np, features)]\n",
    "\n",
    "                    # Applying tracker.\n",
    "                    # The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\n",
    "                    tracker.predict()\n",
    "                    tracker.update(detections)\n",
    "                    track_time = time.time() - prev_time\n",
    "\n",
    "                    # Checking if tracks exist.\n",
    "                    for track in tracker.tracks:\n",
    "                        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                            continue\n",
    "\n",
    "                        # Changing track bbox to top left, bottom right coordinates\n",
    "                        \n",
    "                        # bbox = np.array(list(track.to_tlbr()))\n",
    "\n",
    "                        # for i in range(len(bbox)):\n",
    "                        #     if bbox[i] < 0:\n",
    "                        #         bbox[i] = 0\n",
    "                        bbox = [list(track.to_tlbr()) for track in tracker.tracks]\n",
    "                        for i in range(len(bbox)):\n",
    "                            for j in range(4):\n",
    "                                if bbox[i][j] < 0:\n",
    "                                    bbox[i][j] = 0\n",
    "                        bbox = np.array(bbox)\n",
    "                        # Extracting or cropping the license plate and applying the OCR.\n",
    "                        cr_img = crop(img, bbox)\n",
    "\n",
    "                        rec_pre_time = time.time()\n",
    "                        result_ocr = ocr.ocr(cr_img, cls=False, det=False)\n",
    "                        rec_tot_time = time.time() - rec_pre_time\n",
    "\n",
    "                        ocr_res = result_ocr[0][0]\n",
    "                        print(result_ocr)\n",
    "                        rec_conf = result_ocr[0][1]\n",
    "\n",
    "                        if rec_conf == 'nan':\n",
    "                            rec_conf = 0\n",
    "\n",
    "                        # Storing the ocr output for corresponding track id.\n",
    "                        output_frame = {\"track_id\": track.track_id, \"ocr_txt\": ocr_res, \"ocr_conf\": rec_conf}\n",
    "\n",
    "                        # Appending track_id to list only if it does not exist in the list.\n",
    "                        if track.track_id not in list(set(ele['track_id'] for ele in preds)):\n",
    "                            total_obj = total_obj + 1\n",
    "                            preds.append(output_frame)\n",
    "                        # Looking for the current track in the list and updating the highest confidence of it.\n",
    "                        else:\n",
    "                            preds, rec_conf, ocr_res = get_best_ocr(preds, rec_conf, ocr_res, track.track_id)\n",
    "\n",
    "                        # Plotting the predictions using OpenCV.\n",
    "                        txt = str(track.track_id) + '. ' + ocr_res\n",
    "                        (label_width, label_height), baseline = cv2.getTextSize(txt, font, 2, 3)\n",
    "                        top_left = tuple(map(int, [int(bbox[0]), int(bbox[1]) - (label_height + baseline)]))\n",
    "                        top_right = tuple(map(int, [int(bbox[0]) + label_width, int(bbox[1])]))\n",
    "                        org = tuple(map(int, [int(bbox[0]), int(bbox[1]) - baseline]))\n",
    "\n",
    "                        cv2.rectangle(overlay_img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), blue_color, 2)\n",
    "                        cv2.rectangle(overlay_img, top_left, top_right, blue_color, -1)\n",
    "                        cv2.putText(overlay_img, txt, org, font, 2, white_color, 3)\n",
    "                        #cv2.imwrite('/content/{}.jpg'.format(ct), img)\n",
    "                    #cv2.imwrite('/content/{}.jpg'.format(ct), img)\n",
    "\n",
    "            # Calculating time taken and FPS for the whole process.\n",
    "            tot_time = time.time() - prev_time\n",
    "            fps = 1 / tot_time\n",
    "\n",
    "            # Writing information onto the frame and saving the frame to be processed into a video with title and values of different colors.\n",
    "            if w < 2000:\n",
    "                size = 1\n",
    "            else:\n",
    "                size = 2\n",
    "\n",
    "            # Plotting frame count information on the frame.\n",
    "            (label_width,label_height), baseline = cv2.getTextSize('Frame count:' , font,size,2)\n",
    "            top_left = (int(w_scale) + 10, int(h_scale))\n",
    "            cv2.putText(overlay_img, 'Frame count:', top_left, font, size, green_color, thickness=2)\n",
    "            \n",
    "            top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "            cv2.putText(overlay_img,'%d ' % (ct), top_left_r1, font, size, yellow_color, thickness=2)\n",
    "            \n",
    "            (label_width,label_height), baseline = cv2.getTextSize('Frame count:' + ' ' + str(ct) , font, size,2)\n",
    "            top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "            cv2.putText(overlay_img, 'Total FPS:' , top_left_r1, font, size, green_color, thickness=2)\n",
    "            \n",
    "            (label_width,label_height), baseline = cv2.getTextSize('Frame count:' + ' ' + str(ct) + 'Total FPS:' , font, size,2)\n",
    "            top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "            cv2.putText(overlay_img, '%s' % (int(fps)), top_left_r1, font, size, yellow_color, thickness=2)\n",
    "\n",
    "            # Plotting Total FPS of ANPR information on the frame.\n",
    "            cv2.putText(overlay_img, 'Detection FPS:', (top_left[0], int(h_scale * 1.7)), font, size, green_color, thickness=2)\n",
    "            (label_width, label_height), baseline = cv2.getTextSize('Detection FPS:', font, size, 2)\n",
    "            cv2.putText(overlay_img, '%d' % ((int(1 / det_time))), (top_left[0] + label_width, int(h_scale * 1.7)),\n",
    "                        font, size, yellow_color, thickness=2)\n",
    "\n",
    "            # Plotting Recognition/OCR FPS of ANPR on the frame.\n",
    "            cv2.putText(overlay_img, 'Recognition FPS:', (top_left[0], int(h_scale * 2.42)), font, size, green_color,\n",
    "                        thickness=2)\n",
    "            (label_width, label_height), baseline = cv2.getTextSize('Recognition FPS:', font, size, 2)\n",
    "            cv2.putText(overlay_img, '%s' % ((int(1 / rec_tot_time))), (top_left[0] + label_width, int(h_scale * 2.42)),\n",
    "                        font, size, yellow_color, thickness=2)\n",
    "            cv2.imwrite('/content/{}.jpg'.format(ct), overlay_img)\n",
    "            out.write(overlay_img)\n",
    "\n",
    "            # Increasing frame count.\n",
    "            ct = ct + 1\n",
    "        else:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ZN0oaVZhXMLg"
   },
   "outputs": [],
   "source": [
    "# def tracker_test_vid(vid_dir, config_file, weights,out_path):\n",
    "#   # Declaring variables for video processing.\n",
    "#   cap = cv2.VideoCapture(vid_dir)\n",
    "#   codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#   width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#   height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#   fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#   file_name = os.path.join(out_path, 'out_' + vid_dir.split('/')[-1])\n",
    "\n",
    "#   out = cv2.VideoWriter(file_name, codec, fps, (width, height))\n",
    "\n",
    "#   # Declaring variables for tracker.\n",
    "#   max_cosine_distance = 0.4\n",
    "#   nn_budget = None\n",
    "\n",
    "#   # Intializing tracker\n",
    "#   model_filename = './model_data/mars-small128.pb'\n",
    "#   encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "#   metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "#   tracker = Tracker(metric)\n",
    "\n",
    "#   # Initializing some helper variables.\n",
    "#   ct = 0\n",
    "#   preds = []\n",
    "#   total_obj = 0\n",
    "#   rec_tot_time = 1\n",
    "#   alpha = 0.5\n",
    "\n",
    "#   # Reading video frame by frame.\n",
    "#   while(cap.isOpened()):\n",
    "#     ret, img = cap.read()\n",
    "#     if ret == True:\n",
    "\n",
    "#         h, w = img.shape[:2]\n",
    "#         print(ct)\n",
    "\n",
    "#         w_scale = w/1.55\n",
    "#         h_scale = h/17\n",
    "\n",
    "#         # Method to blend two images, here used to make the information box transparent.\n",
    "#         overlay_img = img.copy()\n",
    "#         cv2.rectangle(img, (int(w_scale), 0), (w, int(h_scale*3.4)), (0,0,0), -1)\n",
    "#         cv2.addWeighted(img, alpha, overlay_img, 1 - alpha, 0, overlay_img)\n",
    "\n",
    "#         # Noting time for calculating FPS.\n",
    "#         prev_time = time.time()\n",
    "\n",
    "        # # Performing the YOLOv4 detection.\n",
    "        # bboxes, scores, det_time = yolo_det(img, config_file, data_file, batch_size, weights, thresh, out_path, network, class_names, class_colors)\n",
    "\n",
    "        # if list(bboxes):\n",
    "        #   # Getting appearence features of the object.\n",
    "        #   features = encoder(img, bboxes)\n",
    "        #   # Storing all the required info in a list.\n",
    "        #   detections = [Detection(bbox, score, feature) for bbox, score, feature in zip(bboxes, scores, features)]\n",
    "\n",
    "#           # Applying tracker.\n",
    "#           # The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\n",
    "#           tracker.predict()\n",
    "#           tracker.update(detections)\n",
    "#           track_time = time.time() - prev_time\n",
    "\n",
    "#           # Checking if tracks exist.\n",
    "#           for track in tracker.tracks:\n",
    "#             if not track.is_confirmed() or track.time_since_update > 1:\n",
    "#                 continue\n",
    "\n",
    "#             # Changing track bbox to top left, bottom right coordinates\n",
    "#             bbox = list(track.to_tlbr())\n",
    "\n",
    "#             for i in range(len(bbox)):\n",
    "#               if bbox[i] < 0:\n",
    "#                 bbox[i] = 0\n",
    "\n",
    "#             # Extracting or cropping the license plate and applying the OCR.\n",
    "#             cr_img = crop(img, bbox)\n",
    "\n",
    "#             rec_pre_time = time.time()\n",
    "#             result = ocr.ocr(cr_img, cls=False, det=False)\n",
    "#             rec_tot_time = time.time() - rec_pre_time\n",
    "\n",
    "#             ocr_res = result[0][0]\n",
    "#             print(result)\n",
    "#             rec_conf = result[0][1]\n",
    "\n",
    "#             if rec_conf == 'nan':\n",
    "#               rec_conf = 0\n",
    "\n",
    "#             # Storing the ocr output for corresponding track id.\n",
    "#             output_frame = {\"track_id\":track.track_id, \"ocr_txt\":ocr_res, \"ocr_conf\":rec_conf}\n",
    "\n",
    "#             # Appending track_id to list only if it does not exist in the list.\n",
    "#             if track.track_id not in list(set(ele['track_id'] for ele in preds)):\n",
    "#               total_obj = total_obj + 1\n",
    "#               preds.append(output_frame)\n",
    "#             # Looking for the current track in the list and updating the highest confidence of it.\n",
    "#             else:\n",
    "#               preds, rec_conf, ocr_res = get_best_ocr(preds, rec_conf, ocr_res, track.track_id)\n",
    "\n",
    "#             # Plotting the predictions using OpenCV.\n",
    "#             txt = str(track.track_id) + '. ' + ocr_res\n",
    "#             (label_width,label_height), baseline = cv2.getTextSize(txt , font,2,3)\n",
    "#             top_left = tuple(map(int,[int(bbox[0]),int(bbox[1])-(label_height+baseline)]))\n",
    "#             top_right = tuple(map(int,[int(bbox[0])+label_width,int(bbox[1])]))\n",
    "#             org = tuple(map(int,[int(bbox[0]),int(bbox[1])-baseline]))\n",
    "\n",
    "#             cv2.rectangle(overlay_img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), blue_color, 2)\n",
    "#             cv2.rectangle(overlay_img, top_left, top_right, blue_color, -1)\n",
    "#             cv2.putText(overlay_img,txt, org, font, 2, white_color, 3)\n",
    "#             #cv2.imwrite('/content/{}.jpg'.format(ct), img)\n",
    "\n",
    "#           # Calculating time taken and FPS for the whole process.\n",
    "#           tot_time = time.time() - prev_time\n",
    "#           fps = 1/tot_time\n",
    "\n",
    "#           # Writing information onto the frame and saving the frame to be processed into a video with title and values of different colors.\n",
    "#           if w < 2000:\n",
    "#             size = 1\n",
    "#           else:\n",
    "#             size = 2\n",
    "\n",
    "#           # Plotting frame count information on the frame.\n",
    "#           (label_width,label_height), baseline = cv2.getTextSize('Frame count:' , font,size,2)\n",
    "#           top_left = (int(w_scale) + 10, int(h_scale))\n",
    "#           cv2.putText(overlay_img, 'Frame count:', top_left, font, size, green_color, thickness=2)\n",
    "\n",
    "#           top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "#           cv2.putText(overlay_img,'%d ' % (ct), top_left_r1, font, size, yellow_color, thickness=2)\n",
    "\n",
    "#           (label_width,label_height), baseline = cv2.getTextSize('Frame count:' + ' ' + str(ct) , font, size,2)\n",
    "#           top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "#           cv2.putText(overlay_img, 'Total FPS:' , top_left_r1, font, size, green_color, thickness=2)\n",
    "\n",
    "#           (label_width,label_height), baseline = cv2.getTextSize('Frame count:' + ' ' + str(ct) + 'Total FPS:' , font, size,2)\n",
    "#           top_left_r1 = (int(w_scale) + 10 + label_width, int(h_scale))\n",
    "#           cv2.putText(overlay_img, '%s' % (int(fps)), top_left_r1, font, size, yellow_color, thickness=2)\n",
    "\n",
    "#           # Plotting Total FPS of ANPR information on the frame.\n",
    "#           cv2.putText(overlay_img, 'Detection FPS:' ,(top_left[0], int(h_scale*1.7)), font, size, green_color, thickness=2)\n",
    "#           (label_width,label_height), baseline = cv2.getTextSize('Detection FPS:', font,size,2)\n",
    "#           cv2.putText(overlay_img, '%d' % ((int(1/det_time))),(top_left[0] + label_width, int(h_scale*1.7)), font, size, yellow_color, thickness=2)\n",
    "\n",
    "#           # Plotting Recognition/OCR FPS of ANPR on the frame.\n",
    "#           cv2.putText(overlay_img, 'Recognition FPS:',(top_left[0], int(h_scale*2.42)), font, size, green_color, thickness=2)\n",
    "#           (label_width,label_height), baseline = cv2.getTextSize('Recognition FPS:', font,size,2)\n",
    "#           cv2.putText(overlay_img, '%s' % ((int(1/rec_tot_time))),(top_left[0] + label_width, int(h_scale*2.42)), font, size, yellow_color, thickness=2)\n",
    "#           cv2.imwrite('/content/{}.jpg'.format(ct), overlay_img)\n",
    "#           out.write(overlay_img)\n",
    "\n",
    "#         # Increasing frame count.\n",
    "#         ct = ct + 1\n",
    "#     else:\n",
    "#       break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceaYktcyat_1"
   },
   "source": [
    "**Test Vid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5_i7Ncvv13r",
    "outputId": "206ce84e-f199-456c-8a1c-f013dc725258"
   },
   "outputs": [],
   "source": [
    "input_dir = 'test_video/test_2.mp4'\n",
    "out_path = 'results/test_2.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "cB8hq7dFkgsk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 78.1ms\n",
      "Speed: 306.4ms preprocess, 78.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result ultralytics.yolo.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.yolo.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'plate'}\n",
      "orig_img: array([[[ 39,  59,  61],\n",
      "        [102, 122, 124],\n",
      "        [ 35,  55,  57],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 82, 102, 104],\n",
      "        [148, 168, 170],\n",
      "        [ 42,  62,  64],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[ 17,  37,  39],\n",
      "        [ 27,  47,  49],\n",
      "        [ 42,  62,  64],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[148, 156, 160],\n",
      "        [214, 222, 226],\n",
      "        [229, 237, 241],\n",
      "        ...,\n",
      "        [ 77,  86,  87],\n",
      "        [ 78,  87,  88],\n",
      "        [ 77,  86,  87]],\n",
      "\n",
      "       [[148, 156, 160],\n",
      "        [214, 222, 226],\n",
      "        [229, 237, 241],\n",
      "        ...,\n",
      "        [ 78,  87,  88],\n",
      "        [ 79,  88,  89],\n",
      "        [ 78,  87,  88]],\n",
      "\n",
      "       [[148, 156, 160],\n",
      "        [214, 222, 226],\n",
      "        [229, 237, 241],\n",
      "        ...,\n",
      "        [ 78,  87,  88],\n",
      "        [ 79,  88,  89],\n",
      "        [ 78,  87,  88]]], dtype=uint8)\n",
      "orig_shape: (480, 848)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 306.44702911376953, 'inference': 78.13358306884766, 'postprocess': 5.245447158813477}\n",
      "bboxes_np [[[     258.75      175.04      384.92      210.76]]]\n",
      "features [[  -0.071263   -0.093201    -0.11417   -0.096898     0.06196   -0.079533   0.0049459    0.087982    0.083268   -0.074851     0.17308    -0.12541   -0.088049   0.0051923   -0.060921    -0.12944     0.16462    0.055859   -0.094402   -0.099543      0.2086     0.18769    0.063308    0.014692     0.24803   -0.063559\n",
      "    -0.037368   -0.040763   0.0068898    0.046049    0.033642   -0.062265   -0.029752    0.091587   -0.057829    -0.06782    0.099084   -0.015188     0.16418    0.013941   -0.090322   -0.064908   -0.013626   -0.040203    0.011193   -0.093343   0.0061275   -0.074099    0.014998     0.12071   -0.042448    -0.10027\n",
      "      0.21392    0.040277   -0.027066    0.061957    -0.13385    0.047505   -0.031649   -0.097322    0.011676    0.037994     0.22009   -0.076541   -0.053346     0.26256    -0.10254   -0.052491   -0.095942     0.11239   0.0044531   0.0068693   -0.032559   -0.077868    0.045652   -0.022305    0.052543     0.08756\n",
      "     0.055685    -0.05344     0.15813    0.046417   -0.068016   -0.070332    0.053151    -0.12449   -0.092379     0.11144     0.16413   -0.048371    0.080044     0.07912     0.10929    -0.09592    0.078358    0.021125   -0.039938   -0.092105   -0.021081    0.046653   -0.036864    0.017052   -0.032091   -0.047557\n",
      "   -0.0058703    -0.10083   -0.010264     0.12727   -0.036038    0.048808   -0.044252    0.077464   -0.019477   0.0065005  -0.0055803    0.085533   -0.028613    0.055442    -0.10565    0.029706     0.18223    0.092003   0.0071504    -0.01488   -0.037539    0.012567    0.042358   0.0021763]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Detection.__init__() missing 1 required positional argument: 'feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtracker_test_vid\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 73\u001b[0m, in \u001b[0;36mtracker_test_vid\u001b[0;34m(vid_dir, out_path)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Storing all the required info in a list.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m detections \u001b[38;5;241m=\u001b[39m [Detection(bbox, feature) \u001b[38;5;28;01mfor\u001b[39;00m bbox, feature \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;28mzip\u001b[39m(bboxes_np, features)]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Applying tracker.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m tracker\u001b[38;5;241m.\u001b[39mpredict()\n",
      "Cell \u001b[0;32mIn[75], line 73\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Storing all the required info in a list.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m detections \u001b[38;5;241m=\u001b[39m [\u001b[43mDetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bbox, feature \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;28mzip\u001b[39m(bboxes_np, features)]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Applying tracker.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# The tracker code flow: kalman filter -> target association(using hungarian algorithm) and appearance descriptor.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m tracker\u001b[38;5;241m.\u001b[39mpredict()\n",
      "\u001b[0;31mTypeError\u001b[0m: Detection.__init__() missing 1 required positional argument: 'feature'"
     ]
    }
   ],
   "source": [
    "tracker_test_vid(input_dir, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/BKHN/alpr_project/learnopencv/deep_sort\n"
     ]
    }
   ],
   "source": [
    "# DeepSORT imports.\n",
    "%cd ./deep_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 12:58:17.993153: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-24 12:58:18.063267: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-24 12:58:18.064564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-24 12:58:19.183524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from application_util import preprocessing\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools_deepsort import generate_detections as gdet\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/BKHN/alpr_project/learnopencv\n"
     ]
    }
   ],
   "source": [
    "# DeepSORT imports.\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Qs8tyRNKXK16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/09/24 13:12:29] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='CRNN', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR(lang='en',rec_algorithm='CRNN')\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8/alpr_yolov8n_8000img_100epochs.pt\") \n",
    "\n",
    "# Initialize DeepSORT tracker\n",
    "max_cosine_distance = 0.4\n",
    "nn_budget = None\n",
    "model_filename = './model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "def test_video_yolov8(input, out_path):\n",
    "    # Declaring variables for video processing.\n",
    "    cap = cv2.VideoCapture(input_dir)\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(out_path, codec, fps, (width, height))\n",
    "\n",
    "    # Frame count variable.\n",
    "    ct = 0\n",
    "\n",
    "    # Initialize DeepSORT tracker\n",
    "    max_cosine_distance = 0.4\n",
    "    nn_budget = None\n",
    "    model_filename = './model_data/mars-small128.pb'\n",
    "    encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "    tracker = Tracker(metric)\n",
    "    \n",
    "    # Reading video frame by frame.\n",
    "    while(cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        if ret == True:\n",
    "            print(ct)\n",
    "\n",
    "            # Noting time for calculating FPS.\n",
    "            prev_time = time.time()\n",
    "\n",
    "            # Use the model\n",
    "            results = model(img)  # predict on an image\n",
    "\n",
    "            bboxes_np = []  # List to store bounding boxes\n",
    "            # Filter out low-confidence OCR results\n",
    "            detections = []\n",
    "            for result in results:\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    # Get the bounding boxes for each result\n",
    "                    bboxes = result.boxes[0].cpu().numpy()\n",
    "                    for bbox in bboxes:\n",
    "                        xyxy = bbox.xyxy[0]\n",
    "                        x1, y1, x2, y2 = xyxy\n",
    "                        \n",
    "                        # Crop license plate region\n",
    "                        cr_img = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "                        \n",
    "                        # Perform OCR (you'll need to add your OCR code here)\n",
    "                        ocr_res = perform_ocr(cr_img)\n",
    "                        \n",
    "\n",
    "                        if ocr_res and ocr_res[0][0][1] > 0.6:\n",
    "                            # Append bounding box to the list\n",
    "                            bboxes_np.append(xyxy)\n",
    "                            bboxes_np = np.array(bboxes_np)\n",
    "                            # Get appearance feature for this bounding box\n",
    "                            confidence = ocr_res[0][0][1] \n",
    "                            feature = encoder(img, [xyxy])[0]\n",
    "                            # Create a Detection object with both bbox and feature\n",
    "                            detection = Detection(xyxy, confidence, feature)\n",
    "                            \n",
    "                            # Append the detection to your list of detections or use it as needed\n",
    "                            detections.append(detection)\n",
    "            # if len(bboxes_np) > 0:\n",
    "                # # Convert the list of bounding boxes to a NumPy array\n",
    "                # bboxes_np = np.array(bboxes_np)\n",
    "                # print(\"bboxes_np:\", bboxes_np)\n",
    "                # # Get appearance features of the objects\n",
    "                # features = encoder(img, bboxes_np)\n",
    "                # print(\"features:\", features)\n",
    "                # # Create a list of Detection objects\n",
    "                # detections = [Detection(bbox, feature) for bbox, feature in zip(bboxes_np, features)]\n",
    "    \n",
    "                # Apply the tracker\n",
    "                tracker.predict()\n",
    "                tracker.update(detections)\n",
    "    \n",
    "                # Loop through the tracked objects\n",
    "                for track in tracker.tracks:\n",
    "                    if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                        continue\n",
    "    \n",
    "                    # Get the track's bounding box\n",
    "                    bbox = track.to_tlbr()\n",
    "                    x1, y1, x2, y2 = bbox.astype(int)\n",
    "    \n",
    "                    # Crop license plate region\n",
    "                    cr_img = img[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # Check if the cropped image is empty or invalid\n",
    "                    if cr_img is None or cr_img.size == 0:\n",
    "                        continue\n",
    "    \n",
    "                    # Perform OCR (you'll need to add your OCR code here)\n",
    "                    ocr_res = perform_ocr(cr_img)\n",
    "    \n",
    "                    recognized_text = ocr_res[0][0][0] if ocr_res else \"No Text\"\n",
    "                    ocr_conf = ocr_res[0][0][1] if ocr_res else \"No Conf\"\n",
    "                    ocr_conf = round(ocr_conf, 3)\n",
    "    \n",
    "                    # Draw on the image\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red bounding box\n",
    "                    cv2.putText(img, recognized_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    cv2.putText(img, str(ocr_conf), (x1 + 100, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "                # Calculating time taken and FPS for the whole process.\n",
    "                tot_time = time.time() - prev_time\n",
    "                fps = round(1 / tot_time, 2)\n",
    "    \n",
    "                # Writing information onto the frame and saving it to be processed in a video.\n",
    "                cv2.putText(img, 'frame: %d fps: %s' % (ct, fps),\n",
    "                            (0, int(100 * 1)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)\n",
    "                out.write(img)\n",
    "    \n",
    "                ct = ct + 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "def perform_ocr(image):\n",
    "    ocr_res = ocr.ocr(image, cls=False, det=False)\n",
    "    return ocr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 79.2ms\n",
      "Speed: 3.9ms preprocess, 79.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 plates, 163.1ms\n",
      "Speed: 4.4ms preprocess, 163.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 5.6ms preprocess, 164.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 133.1ms\n",
      "Speed: 4.5ms preprocess, 133.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.3ms\n",
      "Speed: 4.7ms preprocess, 163.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 139.6ms\n",
      "Speed: 4.8ms preprocess, 139.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.6ms preprocess, 160.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.2ms\n",
      "Speed: 5.3ms preprocess, 163.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.5ms\n",
      "Speed: 4.3ms preprocess, 163.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 132.6ms\n",
      "Speed: 4.8ms preprocess, 132.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.8ms preprocess, 163.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.7ms preprocess, 163.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.8ms preprocess, 163.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.9ms preprocess, 163.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 152.3ms\n",
      "Speed: 4.8ms preprocess, 152.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.9ms\n",
      "Speed: 4.7ms preprocess, 160.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 165.2ms\n",
      "Speed: 4.6ms preprocess, 165.2ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.8ms preprocess, 163.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 158.5ms\n",
      "Speed: 4.8ms preprocess, 158.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 137.7ms\n",
      "Speed: 4.7ms preprocess, 137.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.6ms preprocess, 160.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.3ms\n",
      "Speed: 5.0ms preprocess, 163.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.4ms\n",
      "Speed: 4.8ms preprocess, 160.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.2ms\n",
      "Speed: 4.8ms preprocess, 160.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.4ms\n",
      "Speed: 4.9ms preprocess, 159.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.5ms\n",
      "Speed: 5.4ms preprocess, 163.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 5.0ms preprocess, 163.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 151.2ms\n",
      "Speed: 4.8ms preprocess, 151.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.2ms preprocess, 163.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.7ms\n",
      "Speed: 4.6ms preprocess, 161.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.8ms\n",
      "Speed: 5.0ms preprocess, 160.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 5.1ms preprocess, 163.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 154.3ms\n",
      "Speed: 4.9ms preprocess, 154.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.5ms preprocess, 163.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.8ms preprocess, 163.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 152.2ms\n",
      "Speed: 4.7ms preprocess, 152.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.5ms preprocess, 160.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 5.0ms preprocess, 163.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     556.26      175.83      707.93      222.24].\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 5.4ms preprocess, 160.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     565.74       177.4      716.49      223.21].\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 165.2ms\n",
      "Speed: 4.8ms preprocess, 165.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     575.09      175.14      730.13      220.92].\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.5ms preprocess, 163.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     588.33      170.69      746.75      219.58].\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 162.6ms\n",
      "Speed: 4.9ms preprocess, 162.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     597.84      163.25      757.58         212].\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 161.0ms\n",
      "Speed: 4.8ms preprocess, 161.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     604.82      160.97       764.5      209.41].\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.8ms preprocess, 163.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [      614.2      161.28      776.13      214.47].\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.7ms preprocess, 164.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     615.48      161.81       778.8      215.11].\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 131.8ms\n",
      "Speed: 4.7ms preprocess, 131.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     615.04      158.46      778.03      209.58].\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.8ms preprocess, 160.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     612.99      158.68      772.01      205.16].\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 164.4ms\n",
      "Speed: 4.8ms preprocess, 164.4ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 164.5ms\n",
      "Speed: 4.7ms preprocess, 164.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.4ms preprocess, 163.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.7ms preprocess, 164.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 5.6ms preprocess, 163.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 138.0ms\n",
      "Speed: 4.7ms preprocess, 138.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.7ms preprocess, 163.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 130.3ms\n",
      "Speed: 4.6ms preprocess, 130.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 141.6ms\n",
      "Speed: 4.8ms preprocess, 141.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.0ms\n",
      "Speed: 4.9ms preprocess, 163.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.9ms\n",
      "Speed: 4.7ms preprocess, 163.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 136.8ms\n",
      "Speed: 4.7ms preprocess, 136.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.8ms preprocess, 163.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 142.7ms\n",
      "Speed: 4.5ms preprocess, 142.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.8ms preprocess, 160.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.5ms preprocess, 163.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 159.7ms\n",
      "Speed: 4.7ms preprocess, 159.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.7ms\n",
      "Speed: 4.6ms preprocess, 160.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.7ms preprocess, 163.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.3ms preprocess, 163.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 158.7ms\n",
      "Speed: 4.9ms preprocess, 158.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.8ms preprocess, 163.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.6ms preprocess, 163.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 137.4ms\n",
      "Speed: 4.7ms preprocess, 137.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.6ms preprocess, 163.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.2ms preprocess, 163.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 157.3ms\n",
      "Speed: 4.6ms preprocess, 157.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.2ms\n",
      "Speed: 5.0ms preprocess, 160.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.7ms preprocess, 163.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 4.9ms preprocess, 163.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.4ms\n",
      "Speed: 4.7ms preprocess, 160.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 162.7ms\n",
      "Speed: 4.8ms preprocess, 162.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 161.2ms\n",
      "Speed: 5.4ms preprocess, 161.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.0ms\n",
      "Speed: 4.7ms preprocess, 160.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 4.8ms preprocess, 163.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.3ms\n",
      "Speed: 4.8ms preprocess, 160.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.6ms preprocess, 163.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.4ms preprocess, 163.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.3ms\n",
      "Speed: 4.8ms preprocess, 160.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.6ms preprocess, 163.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.7ms preprocess, 163.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.9ms\n",
      "Speed: 4.7ms preprocess, 160.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.6ms preprocess, 163.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 128.3ms\n",
      "Speed: 4.8ms preprocess, 128.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.2ms\n",
      "Speed: 4.5ms preprocess, 163.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 147.9ms\n",
      "Speed: 4.8ms preprocess, 147.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.7ms preprocess, 163.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 143.3ms\n",
      "Speed: 4.6ms preprocess, 143.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.2ms\n",
      "Speed: 4.8ms preprocess, 160.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.7ms preprocess, 163.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 162.3ms\n",
      "Speed: 4.7ms preprocess, 162.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.1ms\n",
      "Speed: 4.7ms preprocess, 160.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     570.41      182.35      744.89      239.42].\n",
      "117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.1ms\n",
      "Speed: 4.5ms preprocess, 163.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     603.65      176.37      782.79      236.12].\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 148.3ms\n",
      "Speed: 4.8ms preprocess, 148.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     639.85       170.7      825.48      235.73].\n",
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 160.9ms\n",
      "Speed: 4.8ms preprocess, 160.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     679.01      161.04      847.93      233.66].\n",
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.7ms preprocess, 163.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     723.43      154.45      847.85      224.53].\n",
      "121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 157.5ms\n",
      "Speed: 4.5ms preprocess, 157.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 163.7ms\n",
      "Speed: 4.9ms preprocess, 163.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to extract image patch: [     770.67      151.19         848      225.94].\n",
      "122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.8ms\n",
      "Speed: 5.5ms preprocess, 163.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 76.9ms\n",
      "Speed: 5.0ms preprocess, 76.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.3ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 4.0ms preprocess, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 4.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.2ms preprocess, 26.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.2ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.9ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.0ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.8ms preprocess, 28.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.3ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 3.2ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.8ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.0ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 2.8ms preprocess, 27.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.1ms preprocess, 26.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 28.0ms\n",
      "Speed: 2.6ms preprocess, 28.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 163.5ms\n",
      "Speed: 4.6ms preprocess, 163.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 5.2ms preprocess, 28.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.5ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 5.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.6ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 3.2ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.4ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 4.4ms preprocess, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.1ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.9ms preprocess, 27.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 3.5ms preprocess, 28.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.3ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.9ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.2ms\n",
      "Speed: 3.0ms preprocess, 32.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.7ms preprocess, 30.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.7ms preprocess, 27.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 4.2ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 6.2ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.2ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.8ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 7.9ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.3ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.8ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 4.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.5ms preprocess, 27.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.2ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.3ms preprocess, 26.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.7ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.9ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.1ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.3ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.0ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.0ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.1ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.5ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.7ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.6ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.3ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.5ms preprocess, 28.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 3.1ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.7ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.4ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 3.0ms preprocess, 26.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.8ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.9ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.5ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 3.0ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.1ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.5ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.3ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.1ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.9ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.8ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.6ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.6ms preprocess, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 3.2ms preprocess, 27.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 3.8ms preprocess, 27.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.2ms\n",
      "Speed: 3.6ms preprocess, 26.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "273\n",
      "274\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.3ms\n",
      "Speed: 5.1ms preprocess, 163.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 129.8ms\n",
      "Speed: 4.7ms preprocess, 129.8ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 4.8ms preprocess, 163.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 164.3ms\n",
      "Speed: 4.6ms preprocess, 164.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.1ms\n",
      "Speed: 4.6ms preprocess, 163.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.2ms\n",
      "Speed: 8.1ms preprocess, 163.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.0ms\n",
      "Speed: 4.8ms preprocess, 163.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 138.5ms\n",
      "Speed: 4.5ms preprocess, 138.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.0ms\n",
      "Speed: 4.6ms preprocess, 163.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 147.3ms\n",
      "Speed: 4.6ms preprocess, 147.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.4ms\n",
      "Speed: 4.6ms preprocess, 163.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.5ms\n",
      "Speed: 5.1ms preprocess, 163.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 165.1ms\n",
      "Speed: 4.8ms preprocess, 165.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 5.1ms preprocess, 163.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 148.1ms\n",
      "Speed: 5.0ms preprocess, 148.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.6ms\n",
      "Speed: 5.1ms preprocess, 163.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.6ms preprocess, 163.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 160.6ms\n",
      "Speed: 4.6ms preprocess, 160.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.5ms\n",
      "Speed: 4.9ms preprocess, 163.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n",
      "297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 3.1ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.7ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 3.0ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 3.5ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 6.6ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.8ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 35.3ms\n",
      "Speed: 2.8ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.8ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.6ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.7ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.0ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 3.1ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.4ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 4.8ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 2.8ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.3ms\n",
      "Speed: 3.0ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "324\n",
      "325\n",
      "326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.7ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.6ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.1ms preprocess, 26.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.1ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.5ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.3ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 3.3ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.1ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.0ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.7ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 4.2ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.1ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.8ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.4ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.8ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n",
      "368\n",
      "369\n",
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 164.2ms\n",
      "Speed: 4.8ms preprocess, 164.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n",
      "372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 56.9ms\n",
      "Speed: 4.6ms preprocess, 56.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.1ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.9ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 26.1ms\n",
      "Speed: 3.4ms preprocess, 26.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "389\n",
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 137.5ms\n",
      "Speed: 4.8ms preprocess, 137.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 plate, 163.5ms\n",
      "Speed: 5.3ms preprocess, 163.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.8ms\n",
      "Speed: 4.7ms preprocess, 163.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 5.2ms preprocess, 163.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 134.5ms\n",
      "Speed: 5.0ms preprocess, 134.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 plates, 163.6ms\n",
      "Speed: 4.8ms preprocess, 163.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 163.3ms\n",
      "Speed: 4.8ms preprocess, 163.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 plate, 144.9ms\n",
      "Speed: 5.0ms preprocess, 144.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 163.6ms\n",
      "Speed: 4.7ms preprocess, 163.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 5.1ms preprocess, 49.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.2ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.3ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 3.4ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.1ms preprocess, 26.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 3.1ms preprocess, 27.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.3ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.4ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.4ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 5.0ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.9ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.1ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.3ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 4.2ms preprocess, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.1ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.0ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.7ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 4.5ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.3ms preprocess, 26.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.4ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 3.1ms preprocess, 26.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 3.4ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.6ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "441\n",
      "442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 148.0ms\n",
      "Speed: 4.8ms preprocess, 148.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n",
      "444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.2ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 2.8ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.8ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.3ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.2ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.9ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.1ms preprocess, 26.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.6ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.9ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 4.2ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 4.4ms preprocess, 25.9ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.7ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.1ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "466\n",
      "467\n",
      "468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.3ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.8ms preprocess, 28.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.5ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.8ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.1ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.7ms preprocess, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.1ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.6ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.4ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.4ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.7ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 3.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 3.0ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 5.8ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.9ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.7ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.2ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 4.1ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 3.4ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 plate, 27.5ms\n",
      "Speed: 2.6ms preprocess, 27.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 161.7ms\n",
      "Speed: 5.1ms preprocess, 161.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.3ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.9ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 2.8ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.7ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 3.4ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 3.7ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.4ms preprocess, 25.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.0ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.1ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.9ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.0ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.0ms preprocess, 26.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.1ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 3.2ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.1ms preprocess, 26.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 3.3ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.1ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536\n",
      "537\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'test_video/test_2.mp4'\n",
    "out_path = 'results/test_2.avi'\n",
    "test_video_yolov8(input_dir, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "ALPR_inference",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
